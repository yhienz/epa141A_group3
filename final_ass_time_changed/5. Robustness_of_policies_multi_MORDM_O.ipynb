{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Robustness of founded policies\n",
    "\n",
    "1) Regret\n",
    "2) satisfying\n",
    "3) signal noise_to_ratio"
   ],
   "id": "5bb551deb3a59b84"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-21T14:38:06.275870Z",
     "start_time": "2024-06-21T14:38:06.226103Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Import general python packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Import functions\n",
    "from dike_model_function import DikeNetwork  # @UnresolvedImport\n",
    "from problem_formulation import get_model_for_problem_formulation\n",
    "from problem_formulation import sum_over,time_step_0,time_step_1, time_step_2, time_step_3, time_step_4\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Loading in the necessary modules for EMA workbench and functions\n",
    "from ema_workbench import (Model, MultiprocessingEvaluator, Scenario,\n",
    "                           Constraint, ScalarOutcome, TimeSeriesOutcome, ArrayOutcome)\n",
    "from ema_workbench.util import ema_logging\n",
    "from ema_workbench import save_results, load_results, Policy\n",
    "from ema_workbench.em_framework.optimization import (EpsilonProgress)\n",
    "from ema_workbench.analysis import parcoords\n",
    "from itertools import cycle"
   ],
   "id": "7a43d7dfaa1f4f09",
   "execution_count": 68,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Initializing model",
   "id": "2b4c20eacefaaeb4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-21T11:37:08.922514Z",
     "start_time": "2024-06-21T11:37:08.168940Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "def initialize_model():\n",
    "    ema_logging.log_to_stderr(ema_logging.INFO)\n",
    "    print(\"Initializing model...\")\n",
    "    dike_model, planning_steps = get_model_for_problem_formulation(7)\n",
    "    print(\"Model initialized.\")\n",
    "    return dike_model, planning_steps\n",
    "\n",
    "# Writing a function to create actor specific problem formulations\n",
    "def problem_formulation_actor(problem_formulation_actor, uncertainties, levers):\n",
    "    # Load the model:\n",
    "    function = DikeNetwork()\n",
    "    # workbench model:\n",
    "    model = Model('dikesnet', function=function)\n",
    "    # Outcomes are all costs, thus they have to minimized:\n",
    "    direction = ScalarOutcome.MINIMIZE\n",
    "\n",
    "    model.uncertainties = uncertainties\n",
    "    model.levers = levers\n",
    "\n",
    "    cost_variables = []\n",
    "    cost_variables.extend(\n",
    "    [\n",
    "        f\"{dike}_{e}\"\n",
    "        for e in [\"Expected Annual Damage\", \"Dike Investment Costs\"]\n",
    "        for dike in function.dikelist\n",
    "    ])\n",
    "    cost_variables.extend([f\"RfR Total Costs\"])\n",
    "    cost_variables.extend([f\"Expected Evacuation Costs\"])\n",
    "\n",
    "    if problem_formulation_actor == 6:  # GELDERLAND\n",
    "        model.outcomes.clear()\n",
    "        model.outcomes = [\n",
    "            ScalarOutcome(f'Total_period_Costs_0',\n",
    "                          variable_name=dike_model.outcomes['Total_period_Costs'].variable_name,\n",
    "                          function=time_step_0, kind=direction),\n",
    "            ScalarOutcome(f'Total_period_Costs_1',\n",
    "                          variable_name=dike_model.outcomes['Total_period_Costs'].variable_name,\n",
    "                          function=time_step_1, kind=direction),\n",
    "            # ScalarOutcome(f'Total_period_Costs_2',\n",
    "            #               variable_name=dike_model.outcomes['Total_period_Costs'].variable_name,\n",
    "            #               function=time_step_2, kind=direction),\n",
    "            # ScalarOutcome(f'Total_period_Costs_3',\n",
    "            #               variable_name=dike_model.outcomes['Total_period_Costs'].variable_name,\n",
    "            #               function=time_step_3, kind=direction),\n",
    "            # ScalarOutcome(f'Total_period_Costs_4',\n",
    "            #               variable_name=dike_model.outcomes['Total_period_Costs'].variable_name,\n",
    "            #               function=time_step_4, kind=direction),\n",
    "            ScalarOutcome('Expected Annual Damage A1_', variable_name='A.1_Expected Annual Damage', function=sum_over,\n",
    "                          kind=direction),\n",
    "            ScalarOutcome('Expected Annual Damage A2_', variable_name='A.2_Expected Annual Damage', function=sum_over,\n",
    "                          kind=direction),\n",
    "            ScalarOutcome('Expected Annual Damage A3_', variable_name='A.3_Expected Annual Damage', function=sum_over,\n",
    "                          kind=direction),\n",
    "            ScalarOutcome('Total Costs', variable_name=cost_variables, function=sum_over, kind=direction),\n",
    "            ScalarOutcome(\"Expected Number of Deaths_\", variable_name=\n",
    "            [f\"{dike}_Expected Number of Deaths\" for dike in function.dikelist], function=sum_over, kind=direction)]\n",
    "\n",
    "\n",
    "    elif problem_formulation_actor == 7:  # OVERIJSSEL\n",
    "        model.outcomes.clear()\n",
    "        model.outcomes = [\n",
    "            ScalarOutcome(f'Total_period_Costs_0',\n",
    "                          variable_name=dike_model.outcomes['Total_period_Costs'].variable_name,\n",
    "                          function=time_step_0, kind=direction),\n",
    "            ScalarOutcome(f'Total_period_Costs_1',\n",
    "                          variable_name=dike_model.outcomes['Total_period_Costs'].variable_name,\n",
    "                          function=time_step_1, kind=direction),\n",
    "            # ScalarOutcome(f'Total_period_Costs_2',\n",
    "            #               variable_name=dike_model.outcomes['Total_period_Costs'].variable_name,\n",
    "            #               function=time_step_2, kind=direction),\n",
    "            # ScalarOutcome(f'Total_period_Costs_3',\n",
    "            #               variable_name=dike_model.outcomes['Total_period_Costs'].variable_name,\n",
    "            #               function=time_step_3, kind=direction),\n",
    "            # # ScalarOutcome(f'Total_period_Costs_4',\n",
    "            #               variable_name=dike_model.outcomes['Total_period_Costs'].variable_name,\n",
    "            #               function=time_step_4, kind=direction),\n",
    "            ScalarOutcome('Expected Annual Damage A4_', variable_name='A.4_Expected Annual Damage', function=sum_over,\n",
    "                          kind=direction),\n",
    "            ScalarOutcome('Expected Annual Damage A5_', variable_name='A.5_Expected Annual Damage', function=sum_over,\n",
    "                          kind=direction),\n",
    "            ScalarOutcome('Total Costs', variable_name=cost_variables, function=sum_over, kind=direction),\n",
    "            ScalarOutcome(\"Expected Number of Deaths_\", variable_name=\n",
    "            [f\"{dike}_Expected Number of Deaths\" for dike in function.dikelist], function=sum_over, kind=direction)]\n",
    "\n",
    "    else:\n",
    "        raise TypeError('unknown identifier')\n",
    "    return model\n",
    "\n",
    "### Overijssel\n",
    "if __name__ == '__main__':\n",
    "    dike_model, planning_steps = initialize_model()\n",
    "\n",
    "    uncertainties = dike_model.uncertainties\n",
    "    levers = dike_model.levers\n",
    "    \n",
    "    model = problem_formulation_actor(7, uncertainties, levers)\n",
    "\n",
    "    # Deepcopying the uncertainties and levers\n",
    "    uncertainties = copy.deepcopy(dike_model.uncertainties)\n",
    "    levers = copy.deepcopy(dike_model.levers)\n",
    "\n",
    "    # Running the optimization for Overijssel\n",
    "    function = DikeNetwork()"
   ],
   "id": "e61ce49f7b3e2ffc",
   "execution_count": 37,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-21T14:38:27.747658Z",
     "start_time": "2024-06-21T14:38:16.765723Z"
    }
   },
   "cell_type": "code",
   "source": [
    "policy_set= pd.read_csv(\"Overijssel Multi MORDM_Policies.csv\")\n",
    "\n",
    "policy_set\n",
    "\n",
    "policy_snip=[]\n",
    "for i in range (2, 8):\n",
    "    policy_snip.append(policy_set.iloc[:,-i].idxmin())\n",
    "    policy_snip.append(policy_set.iloc[:,-i].idxmax())\n",
    "    #print(policy_set.columns[-i])\n",
    "\n",
    "len(policy_snip)\n",
    "\n",
    "pareto_df= policy_set\n",
    "\n",
    "#Selecteer de kolommen met (objectieven)\n",
    "objective_columns = pareto_df.columns[-7:-1]\n",
    "objective_columns\n",
    "\n",
    "#  partition objectives columns in 3 segments and select one solution per segment\n",
    "selected_policies = pd.DataFrame()\n",
    "\n",
    "for objective in objective_columns:\n",
    "    # Sort for based on Pareto outcome\n",
    "    pareto_df_sorted = pareto_df.sort_values(by=objective)\n",
    "\n",
    "    # split in 3 segments\n",
    "    indices = np.linspace(0, len(pareto_df_sorted) - 1, 4, dtype=int)\n",
    "\n",
    "    # set to list of indices\n",
    "    selected_indices = (indices[:-1] + np.diff(indices) // 2).tolist()\n",
    "\n",
    "    # Select rows and add to policies\n",
    "    selected_policies = pd.concat([selected_policies, pareto_df_sorted.iloc[selected_indices]])\n",
    "\n",
    "policy_snip2=  selected_policies.index.tolist()\n",
    "policy_snip2\n",
    "\n",
    "total_snip= policy_snip + policy_snip2\n",
    "len(total_snip) #30 = 12+18 so perfect\n",
    "unique_snip = list(set(total_snip))\n",
    "len(unique_snip)\n",
    "\n",
    "policies = policy_set.loc[unique_snip]\n",
    "policies = policies.iloc[:,1:51]\n",
    "\n",
    "\n",
    "rcase_policies = []\n",
    "for i, policy in policies.iterrows():\n",
    "    rcase_policies.append(Policy(str(i), **policy.to_dict()))\n",
    "\n",
    "n_scenarios = 1000\n",
    "with MultiprocessingEvaluator(model) as evaluator:\n",
    "    reference_policies_results = evaluator.perform_experiments(n_scenarios,\n",
    "                                            rcase_policies)\n",
    "save_results(reference_policies_results, 'MultiMORDM_O.tar.gz')"
   ],
   "id": "b2a4a3e011664e43",
   "execution_count": 69,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Loading in the datasets",
   "id": "284fa151719b118c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-21T16:09:13.547406Z",
     "start_time": "2024-06-21T16:09:12.839456Z"
    }
   },
   "cell_type": "code",
   "source": [
    "experiments, outcomes = load_results('MultiMORDM_O.tar.gz')\n",
    "\n",
    "df_exp = pd.DataFrame.from_dict(experiments)\n",
    "df_out = pd.DataFrame.from_dict(outcomes)"
   ],
   "id": "7cdbe9cf0127d305",
   "execution_count": 82,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-21T16:09:15.222461Z",
     "start_time": "2024-06-21T16:09:15.154865Z"
    }
   },
   "cell_type": "code",
   "source": "experiments",
   "id": "bde9b973f60ab452",
   "execution_count": 83,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-21T16:09:16.724546Z",
     "start_time": "2024-06-21T16:09:16.710349Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for _ in outcomes:\n",
    "    print(_)"
   ],
   "id": "1d078f6a2ebe52ce",
   "execution_count": 84,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-21T16:09:17.001126Z",
     "start_time": "2024-06-21T16:09:16.732076Z"
    }
   },
   "cell_type": "code",
   "source": [
    "policies = experiments.iloc[:,21:]\n",
    "policies"
   ],
   "id": "239a62b774e8b7fc",
   "execution_count": 85,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-21T16:09:17.122254Z",
     "start_time": "2024-06-21T16:09:17.023111Z"
    }
   },
   "cell_type": "code",
   "source": "df_out",
   "id": "b4b91700ff008ce0",
   "execution_count": 86,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 1. Regret",
   "id": "d28cc0953f36366b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-21T16:09:18.826061Z",
     "start_time": "2024-06-21T16:09:18.716916Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def calculate_regret(data, best):\n",
    "    return np.abs(best-data)\n",
    "\n",
    "worstcase_regret = {}\n",
    "worstcase_max_regret = {}\n",
    "\n",
    "for outcome in model.outcomes:\n",
    "    policy_column = experiments['policy']\n",
    "    \n",
    "    # Create a DataFrame with all the relevant information\n",
    "    data = pd.DataFrame({\n",
    "        outcome.name: outcomes[outcome.name], \n",
    "        \"policy\": experiments['policy'],\n",
    "        \"scenario_id\": experiments['scenario']\n",
    "    })\n",
    "    \n",
    "    # Reorient the data by indexing with policy and scenario_id\n",
    "    data = data.pivot(index='scenario_id', columns='policy')\n",
    "    \n",
    "    # Flatten the resulting hierarchical index resulting from pivoting\n",
    "    data.columns = data.columns.get_level_values(1)\n",
    "   \n",
    "    # Control the broadcasting by converting to NumPy arrays\n",
    "    max_values = data.max(axis=1).to_numpy()[:, np.newaxis]\n",
    "    data_values = data.to_numpy()\n",
    "    \n",
    "    # Calculate the outcome regret\n",
    "    outcome_regret = np.abs(max_values - data_values)\n",
    "    \n",
    "    # Store the results\n",
    "    worstcase_regret[outcome.name] = outcome_regret\n",
    "    worstcase_max_regret[outcome.name] = outcome_regret.max(axis=0)\n"
   ],
   "id": "d1f1bc0afc429630",
   "execution_count": 87,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-21T16:09:22.174295Z",
     "start_time": "2024-06-21T16:09:19.208244Z"
    }
   },
   "cell_type": "code",
   "source": [
    "worstcase_max_regret = pd.DataFrame(worstcase_max_regret)\n",
    "sns.heatmap(worstcase_max_regret/worstcase_max_regret.max(), cmap='viridis', annot=True)\n",
    "plt.show()"
   ],
   "id": "932f9f5ffeefd6dd",
   "execution_count": 88,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-21T16:09:27.616508Z",
     "start_time": "2024-06-21T16:09:22.181918Z"
    }
   },
   "cell_type": "code",
   "source": [
    "colors = sns.color_palette()\n",
    "\n",
    "data = worstcase_max_regret\n",
    "\n",
    "# makes it easier to identify the policy associated with each line\n",
    "#in the parcoords plot\n",
    "#data['policy'] = data.index.astype(\"float64\")\n",
    "\n",
    "limits = parcoords.get_limits(data)\n",
    "limits.loc[0, ['Total_period_Costs_0', 'Total_period_Costs_1','Expected Annual Damage A4_', 'Expected Annual Damage A5_', 'Total Costs', 'Expected Number of Deaths_']] = 0\n",
    "\n",
    "palettes = [sns.color_palette(palette, 20) for palette in ['tab20', 'tab20b', 'tab20c']]\n",
    "combined_palette = cycle([color for palette in palettes for color in palette])\n",
    "colors = [next(combined_palette) for _ in range(35)]\n",
    "\n",
    "\n",
    "paraxes = parcoords.ParallelAxes(limits)\n",
    "for i, (index, row) in enumerate(data.iterrows()):\n",
    "    paraxes.plot(row.to_frame().T, label=str(index), color=colors[i])\n",
    "paraxes.legend()\n",
    "    \n",
    "plt.show()"
   ],
   "id": "f818fa495a64bf1b",
   "execution_count": 89,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-21T16:09:27.632650Z",
     "start_time": "2024-06-21T16:09:27.619519Z"
    }
   },
   "cell_type": "code",
   "source": "#no need for distribution as max regret is what we are intrested in especially with deaths and damages.. MAX regret is how good it could have been in a certain scenario if you would have chosen another policy",
   "id": "600a905b86efba8a",
   "execution_count": 90,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 2. Signal to Noise",
   "id": "53738ab5fee56ac"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-21T16:09:27.648307Z",
     "start_time": "2024-06-21T16:09:27.635666Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def signalnoise(data, direction):\n",
    "    mean = np.mean(data)\n",
    "    std = np.std(data)\n",
    "    \n",
    "    #We minimize all objectives therefore a lower mean and lower std is wanted, so we want the outcome to be as small as possible\n",
    "    if direction==ScalarOutcome.MAXIMIZE:\n",
    "        return mean/std\n",
    "    else:\n",
    "        return mean*std"
   ],
   "id": "5012090703b7dfdc",
   "execution_count": 91,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-21T16:09:27.737318Z",
     "start_time": "2024-06-21T16:09:27.658398Z"
    }
   },
   "cell_type": "code",
   "source": [
    "overall_scores = {}\n",
    "for policy in np.unique(experiments['policy']):\n",
    "    scores = {}\n",
    "    \n",
    "    logical = experiments['policy']==policy\n",
    "    \n",
    "    for outcome in model.outcomes:\n",
    "        value  = outcomes[outcome.name][logical]\n",
    "        sn_ratio = signalnoise(value, outcome.kind)\n",
    "        scores[outcome.name] = sn_ratio\n",
    "    overall_scores[policy] = scores\n",
    "scores = pd.DataFrame.from_dict(overall_scores).T\n",
    "scores"
   ],
   "id": "6b85ac5a0ee4b108",
   "execution_count": 92,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-21T16:09:31.702956Z",
     "start_time": "2024-06-21T16:09:27.740330Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from ema_workbench.analysis import parcoords\n",
    "\n",
    "data = scores\n",
    "limits = parcoords.get_limits(data)\n",
    "limits.loc[0, ['Total_period_Costs_0', 'Total_period_Costs_1','Expected Annual Damage A4_', 'Expected Annual Damage A5_', 'Total Costs', 'Expected Number of Deaths_']] = 0\n",
    "\n",
    "paraxes = parcoords.ParallelAxes(limits)\n",
    "\n",
    "for i, (policy, row) in enumerate(data.iterrows()):\n",
    "    paraxes.plot(row.to_frame().T, label=str(i), color=colors[i])\n",
    "paraxes.legend()\n",
    "#paraxes.invert_axis('max_P')\n",
    "plt.show()"
   ],
   "id": "f4bbeaf8ca6bd4a7",
   "execution_count": 93,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-21T16:09:31.712249Z",
     "start_time": "2024-06-21T16:09:31.704973Z"
    }
   },
   "cell_type": "code",
   "source": "#This shows the Signal to Noice, which is expected * standard deviation for our minimization. a lower score is better. This is about over different scenarios the average and standard deviation, punishing for too much deviation over the scenarios.",
   "id": "2a87f165c9a0019e",
   "execution_count": 94,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "916dfe1870079ff9"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##  3. Satisficing",
   "id": "e99e32f61a63fb31"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-21T16:09:32.972591Z",
     "start_time": "2024-06-21T16:09:31.715280Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "thresholds = {'Total_period_Costs_0':2500000000, 'Total_period_Costs_1':2000000000, 'Expected Annual Damage A4_': 2000000, 'Expected Annual Damage A5_': 2000000, 'Total Costs': 7000000000, 'Expected Number of Deaths_': 1}\n",
    "\n",
    "\n",
    "overall_scores = {}\n",
    "for policy in experiments.policy.unique():\n",
    "    logical = experiments.policy == policy\n",
    "    scores = {}\n",
    "    for k, v in outcomes.items():\n",
    "        try:\n",
    "            n = np.sum(v[logical]>=thresholds[k])\n",
    "        except KeyError:\n",
    "            continue\n",
    "        scores[k] = n/100 #set to number of scenarios\n",
    "    overall_scores[policy] = scores\n",
    "        \n",
    "overall_scores = pd.DataFrame(overall_scores).T\n",
    "limits = parcoords.get_limits(overall_scores)\n",
    "paraxes = parcoords.ParallelAxes(limits)\n",
    "\n",
    "for i, (policy, row) in enumerate(overall_scores.iterrows()):\n",
    "    paraxes.plot(row.to_frame().T, label=str(i), color=colors[i])\n",
    "paraxes.legend()\n",
    "plt.show()"
   ],
   "id": "372655f78c4a1656",
   "execution_count": 95,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "execution_count": null,
   "source": "#hoeveel procent van de scenarios gaat een policy over the treshold heen van een bepaalde objective? is heirbovenhet antwoord ",
   "id": "a1130dde6e6057c",
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
