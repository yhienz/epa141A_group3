{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# MORDM",
   "id": "b9f48a3d3a0555c4"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-06-11T05:54:48.728593Z",
     "start_time": "2024-06-11T05:54:41.362582Z"
    }
   },
   "source": [
    "# Import general python packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import copy\n",
    "\n",
    "# Import functions\n",
    "from dike_model_function import DikeNetwork  # @UnresolvedImport\n",
    "from problem_formulation import get_model_for_problem_formulation\n",
    "from problem_formulation import sum_over, sum_over_time\n",
    "\n",
    "# Loading in the necessary modules for EMA workbench and functions\n",
    "from ema_workbench import (Model, MultiprocessingEvaluator, Scenario,\n",
    "                           Constraint, ScalarOutcome)\n",
    "from ema_workbench.util import ema_logging\n",
    "from ema_workbench import save_results, load_results\n",
    "from ema_workbench.em_framework.optimization import (EpsilonProgress)"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-11T05:54:50.128269Z",
     "start_time": "2024-06-11T05:54:48.730592Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Loading in all the 17 objectives via predefined problem formulation 3\n",
    "if __name__ == '__main__':\n",
    "    ema_logging.log_to_stderr(ema_logging.INFO)\n",
    "    dike_model, planning_steps = get_model_for_problem_formulation(6)"
   ],
   "id": "24f4013befc6d19a",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-11T05:54:50.147031Z",
     "start_time": "2024-06-11T05:54:50.130270Z"
    }
   },
   "cell_type": "code",
   "source": "print(planning_steps)",
   "id": "53f3bf3ef5cb4b02",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4]\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "id": "b6b301ac7683c5ee",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-06-11T05:54:52.393099Z",
     "start_time": "2024-06-11T05:54:52.384393Z"
    }
   },
   "source": [
    "# Replicate the objectives\n",
    "for outcome in dike_model.outcomes:\n",
    "    print(repr(outcome))\n",
    "    "
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ArrayOutcome('A.1_Expected Annual Damage')\n",
      "ArrayOutcome('A.1_Expected Number of Deaths')\n",
      "ScalarOutcome('All Costs', variable_name=('A.1_Expected Annual Damage', 'A.2_Expected Annual Damage', 'A.3_Expected Annual Damage', 'A.4_Expected Annual Damage', 'A.5_Expected Annual Damage', 'A.1_Dike Investment Costs', 'A.2_Dike Investment Costs', 'A.3_Dike Investment Costs', 'A.4_Dike Investment Costs', 'A.5_Dike Investment Costs', 'RfR Total Costs', 'Expected Evacuation Costs'), function=<function sum_over at 0x000001F9DF8BE700>)\n",
      "ArrayOutcome('A.2_Expected Annual Damage')\n",
      "ArrayOutcome('A.2_Expected Number of Deaths')\n",
      "ArrayOutcome('A.3_Expected Annual Damage')\n",
      "ArrayOutcome('A.3_Expected Number of Deaths')\n",
      "ArrayOutcome('A.4_Expected Annual Damage')\n",
      "ArrayOutcome('A.4_Expected Number of Deaths')\n",
      "ArrayOutcome('A.5_Expected Annual Damage')\n",
      "ArrayOutcome('A.5_Expected Number of Deaths')\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "id": "277a36e0-e5d8-4d34-9f17-3118ef97a1e3",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-06-11T05:54:52.765844Z",
     "start_time": "2024-06-11T05:54:52.738238Z"
    }
   },
   "source": [
    "# Writing a function to create actor specific problem formulations\n",
    "def problem_formulation_actor(problem_formulation_actor):\n",
    "   \n",
    "    # Load the model:\n",
    "    function = DikeNetwork()\n",
    "    # workbench model:\n",
    "    model = Model('dikesnet', function=function)\n",
    "    # Outcomes are all costs, thus they have to minimized:\n",
    "    direction = ScalarOutcome.MINIMIZE\n",
    "    \n",
    "    model.uncertainties = uncertainties\n",
    "    model.levers = levers\n",
    "    \n",
    "    cost_variables = []\n",
    "    cost_variables.extend(\n",
    "    [\n",
    "        f\"{dike}_{e}\"\n",
    "        for e in [\"Expected Annual Damage\", \"Dike Investment Costs\"]\n",
    "        for dike in function.dikelist\n",
    "    ])\n",
    "    cost_variables.extend([f\"RfR Total Costs\"])\n",
    "    cost_variables.extend([f\"Expected Evacuation Costs\"])\n",
    "\n",
    "\n",
    "    if problem_formulation_actor == 4: #RWS\n",
    "        model.outcomes.clear()\n",
    "        model.outcomes = [\n",
    "            ScalarOutcome('Expected Annual Damage',\n",
    "                            variable_name=['{}_Expected Annual Damage'.format(dike)\n",
    "                                                for dike in function.dikelist],\n",
    "                            function=sum_over, kind=direction),\n",
    "\n",
    "            ScalarOutcome('Total Investment Costs',\n",
    "                            variable_name=['{}_Dike Investment Costs'.format(dike)\n",
    "                                                for dike in function.dikelist] + ['RfR Total Costs'\n",
    "                                                                                ] + ['Expected Evacuation Costs'],\n",
    "                            function=sum_over, kind=direction),\n",
    "\n",
    "            ScalarOutcome('Expected Number of Deaths',\n",
    "                            variable_name=['{}_Expected Number of Deaths'.format(dike)\n",
    "                                                for dike in function.dikelist],\n",
    "                            function=sum_over, kind=direction)] \n",
    "    \n",
    "    elif problem_formulation_actor == 5: # GELDERLAND\n",
    "        model.outcomes.clear()\n",
    "        model.outcomes = [\n",
    "            ScalarOutcome('Expected Annual Damage A1', variable_name='A.1_Expected Annual Damage', function = sum_over, kind=direction),\n",
    "            ScalarOutcome('Expected Annual Damage A2', variable_name='A.2_Expected Annual Damage', function = sum_over, kind=direction),\n",
    "            ScalarOutcome('Expected Annual Damage A3', variable_name='A.3_Expected Annual Damage', function = sum_over, kind=direction),\n",
    "            ScalarOutcome('Expected Number of Deaths in A1', variable_name='A.1_Expected Number of Deaths',function = sum_over, kind=direction),\n",
    "            ScalarOutcome('Expected Number of Deaths in A2', variable_name='A.2_Expected Number of Deaths',function = sum_over, kind=direction),\n",
    "            ScalarOutcome('Expected Number of Deaths in A3', variable_name='A.3_Expected Number of Deaths',function = sum_over, kind=direction),\n",
    "            ScalarOutcome('Total Costs', variable_name=cost_variables, function = sum_over, kind=direction),\n",
    "            ScalarOutcome('Aggregated Expected Number of Deaths A4-A5', variable_name = \n",
    "            ['A.4_Expected Number of Deaths', 'A.5_Expected Number of Deaths'], function = sum_over, kind=direction)]\n",
    "    \n",
    "    elif problem_formulation_actor == 6: # OVERIJSSEL\n",
    "        model.outcomes.clear()\n",
    "        model.outcomes = [\n",
    "            ScalarOutcome('Expected Annual Damage A4', variable_name='A.4_Expected Annual Damage', function = sum_over, kind=direction),\n",
    "            ScalarOutcome('Expected Annual Damage A5', variable_name='A.5_Expected Annual Damage', function = sum_over, kind=direction),            \n",
    "            ScalarOutcome('Expected Number of Deaths in A4', variable_name='A.4_Expected Number of Deaths',function = sum_over, kind=direction),\n",
    "            ScalarOutcome('Expected Number of Deaths in A5', variable_name='A.5_Expected Number of Deaths',function = sum_over, kind=direction),\n",
    "            ScalarOutcome('Total Costs', variable_name=cost_variables, function = sum_over, kind=direction),\n",
    "            ScalarOutcome('Aggregated Expected Number of Deaths A1-A3', variable_name =\n",
    "            ['A.1_Expected Number of Deaths', 'A.2_Expected Number of Deaths', \n",
    "             'A.3_Expected Number of Deaths'], function = sum_over, kind=direction)]\n",
    "    \n",
    "    else:\n",
    "        raise TypeError('unknown identifier')\n",
    "    return model"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "id": "1bfd2ae6-5f22-4449-a17a-d82042a02813",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-06-11T05:54:53.643384Z",
     "start_time": "2024-06-11T05:54:53.618557Z"
    }
   },
   "source": [
    "# Replicate the uncertainties\n",
    "uncertainties = dike_model.uncertainties\n",
    "uncertainties = copy.deepcopy(dike_model.uncertainties)"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "id": "d2c96536-35ba-4172-b925-62abbc885eaa",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-06-11T05:54:54.064532Z",
     "start_time": "2024-06-11T05:54:54.018963Z"
    }
   },
   "source": [
    "levers = dike_model.levers \n",
    "levers = copy.deepcopy(dike_model.levers)"
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "id": "a91639a2468a9adc",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-06-11T05:54:55.123120Z",
     "start_time": "2024-06-11T05:54:54.365975Z"
    }
   },
   "source": [
    "model = problem_formulation_actor(6)\n",
    "for outcome in model.outcomes:\n",
    "    print(repr((outcome)))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ScalarOutcome('Expected Annual Damage A4', variable_name=('A.4_Expected Annual Damage',), function=<function sum_over at 0x000001F9DF8BE700>)\n",
      "ScalarOutcome('Expected Annual Damage A5', variable_name=('A.5_Expected Annual Damage',), function=<function sum_over at 0x000001F9DF8BE700>)\n",
      "ScalarOutcome('Expected Number of Deaths in A4', variable_name=('A.4_Expected Number of Deaths',), function=<function sum_over at 0x000001F9DF8BE700>)\n",
      "ScalarOutcome('Expected Number of Deaths in A5', variable_name=('A.5_Expected Number of Deaths',), function=<function sum_over at 0x000001F9DF8BE700>)\n",
      "ScalarOutcome('Total Costs', variable_name=('A.1_Expected Annual Damage', 'A.2_Expected Annual Damage', 'A.3_Expected Annual Damage', 'A.4_Expected Annual Damage', 'A.5_Expected Annual Damage', 'A.1_Dike Investment Costs', 'A.2_Dike Investment Costs', 'A.3_Dike Investment Costs', 'A.4_Dike Investment Costs', 'A.5_Dike Investment Costs', 'RfR Total Costs', 'Expected Evacuation Costs'), function=<function sum_over at 0x000001F9DF8BE700>)\n",
      "ScalarOutcome('Aggregated Expected Number of Deaths A1-A3', variable_name=('A.1_Expected Number of Deaths', 'A.2_Expected Number of Deaths', 'A.3_Expected Number of Deaths'), function=<function sum_over at 0x000001F9DF8BE700>)\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "id": "adac028e40648723",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "id": "8dc875ff-0e3b-4e4c-81bf-050b8ee99b44",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-06-11T05:55:01.974545Z",
     "start_time": "2024-06-11T05:55:01.966059Z"
    }
   },
   "source": [
    "print(len(model.outcomes))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "id": "c33cfae19ab29a95",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-06-11T05:55:02.217521Z",
     "start_time": "2024-06-11T05:55:02.211019Z"
    }
   },
   "source": [
    "for outcome in dike_model.outcomes:\n",
    "    print(repr(outcome))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ArrayOutcome('A.1_Expected Annual Damage')\n",
      "ArrayOutcome('A.1_Expected Number of Deaths')\n",
      "ScalarOutcome('All Costs', variable_name=('A.1_Expected Annual Damage', 'A.2_Expected Annual Damage', 'A.3_Expected Annual Damage', 'A.4_Expected Annual Damage', 'A.5_Expected Annual Damage', 'A.1_Dike Investment Costs', 'A.2_Dike Investment Costs', 'A.3_Dike Investment Costs', 'A.4_Dike Investment Costs', 'A.5_Dike Investment Costs', 'RfR Total Costs', 'Expected Evacuation Costs'), function=<function sum_over at 0x000001F9DF8BE700>)\n",
      "ArrayOutcome('A.2_Expected Annual Damage')\n",
      "ArrayOutcome('A.2_Expected Number of Deaths')\n",
      "ArrayOutcome('A.3_Expected Annual Damage')\n",
      "ArrayOutcome('A.3_Expected Number of Deaths')\n",
      "ArrayOutcome('A.4_Expected Annual Damage')\n",
      "ArrayOutcome('A.4_Expected Number of Deaths')\n",
      "ArrayOutcome('A.5_Expected Annual Damage')\n",
      "ArrayOutcome('A.5_Expected Number of Deaths')\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "id": "3b5e260bcd0a1bc3",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-06-11T05:55:02.548395Z",
     "start_time": "2024-06-11T05:55:02.538684Z"
    }
   },
   "source": [
    "reference_values = {\n",
    "    \"Bmax\": 175,\n",
    "    \"Brate\": 1.5,\n",
    "    \"pfail\": 0.5,\n",
    "    \"ID flood wave shape\": 4,\n",
    "    \"planning steps\": 2,\n",
    "}\n",
    "reference_values.update({f\"discount rate {n}\": 3.5 for n in planning_steps})\n",
    "refcase_scen = {}\n",
    "\n",
    "for key in dike_model.uncertainties:\n",
    "    name_split = key.name.split('_')\n",
    "    if len(name_split) == 1:\n",
    "\n",
    "        refcase_scen.update({key.name: reference_values[key.name]})\n",
    "    else:\n",
    "        refcase_scen.update({key.name: reference_values[name_split[1]]})\n",
    "            \n",
    "ref_scenario = Scenario('reference', **refcase_scen)"
   ],
   "outputs": [],
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "id": "51aeba8593a9ed87",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-06-10T20:55:18.849703Z",
     "start_time": "2024-06-10T20:52:50.724615Z"
    }
   },
   "source": [
    "convergence_metrics = {EpsilonProgress()}\n",
    "constraint = [Constraint(\"Total Costs\", outcome_names=\"Total Costs\", function=lambda x: max(0, x - 700000000))]\n",
    "\n",
    "results_df = pd.DataFrame()\n",
    "with MultiprocessingEvaluator(model) as evaluator:\n",
    "    for _ in range(2):\n",
    "       results = evaluator.optimize(nfe=2, searchover='levers',\n",
    "                                     convergence=convergence_metrics,\n",
    "                                     epsilons=[1]*len(model.outcomes), reference=ref_scenario,\n",
    "                                     constraints=constraint)\n",
    "        \n",
    "        \n",
    "save_results(results, 'Week23_MORDM_Reference_1000_PD6.tar.gz')\n"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[MainProcess/INFO] pool started with 3 workers\n",
      "100it [01:31,  1.09it/s]                                                       \n",
      "[MainProcess/INFO] optimization completed, found 1 solutions\n",
      "[MainProcess/INFO] terminating pool\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "cannot concatenate object of type '<class 'tuple'>'; only Series and DataFrame objs are valid",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[136], line 11\u001B[0m\n\u001B[0;32m      6\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m _ \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;241m2\u001B[39m):\n\u001B[0;32m      7\u001B[0m        results \u001B[38;5;241m=\u001B[39m evaluator\u001B[38;5;241m.\u001B[39moptimize(nfe\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m2\u001B[39m, searchover\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mlevers\u001B[39m\u001B[38;5;124m'\u001B[39m,\n\u001B[0;32m      8\u001B[0m                                      convergence\u001B[38;5;241m=\u001B[39mconvergence_metrics,\n\u001B[0;32m      9\u001B[0m                                      epsilons\u001B[38;5;241m=\u001B[39m[\u001B[38;5;241m1\u001B[39m]\u001B[38;5;241m*\u001B[39m\u001B[38;5;28mlen\u001B[39m(model\u001B[38;5;241m.\u001B[39moutcomes), reference\u001B[38;5;241m=\u001B[39mref_scenario,\n\u001B[0;32m     10\u001B[0m                                      constraints\u001B[38;5;241m=\u001B[39mconstraint)\n\u001B[1;32m---> 11\u001B[0m        results_df \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mconcat([results_df,results])\n\u001B[0;32m     13\u001B[0m save_results(results_df, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mWeek23_MORDM_Reference_1000_PD6.tar.gz\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\reshape\\concat.py:380\u001B[0m, in \u001B[0;36mconcat\u001B[1;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001B[0m\n\u001B[0;32m    377\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m copy \u001B[38;5;129;01mand\u001B[39;00m using_copy_on_write():\n\u001B[0;32m    378\u001B[0m     copy \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[1;32m--> 380\u001B[0m op \u001B[38;5;241m=\u001B[39m _Concatenator(\n\u001B[0;32m    381\u001B[0m     objs,\n\u001B[0;32m    382\u001B[0m     axis\u001B[38;5;241m=\u001B[39maxis,\n\u001B[0;32m    383\u001B[0m     ignore_index\u001B[38;5;241m=\u001B[39mignore_index,\n\u001B[0;32m    384\u001B[0m     join\u001B[38;5;241m=\u001B[39mjoin,\n\u001B[0;32m    385\u001B[0m     keys\u001B[38;5;241m=\u001B[39mkeys,\n\u001B[0;32m    386\u001B[0m     levels\u001B[38;5;241m=\u001B[39mlevels,\n\u001B[0;32m    387\u001B[0m     names\u001B[38;5;241m=\u001B[39mnames,\n\u001B[0;32m    388\u001B[0m     verify_integrity\u001B[38;5;241m=\u001B[39mverify_integrity,\n\u001B[0;32m    389\u001B[0m     copy\u001B[38;5;241m=\u001B[39mcopy,\n\u001B[0;32m    390\u001B[0m     sort\u001B[38;5;241m=\u001B[39msort,\n\u001B[0;32m    391\u001B[0m )\n\u001B[0;32m    393\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m op\u001B[38;5;241m.\u001B[39mget_result()\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\reshape\\concat.py:446\u001B[0m, in \u001B[0;36m_Concatenator.__init__\u001B[1;34m(self, objs, axis, join, keys, levels, names, ignore_index, verify_integrity, copy, sort)\u001B[0m\n\u001B[0;32m    443\u001B[0m objs, keys \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_clean_keys_and_objs(objs, keys)\n\u001B[0;32m    445\u001B[0m \u001B[38;5;66;03m# figure out what our result ndim is going to be\u001B[39;00m\n\u001B[1;32m--> 446\u001B[0m ndims \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_get_ndims(objs)\n\u001B[0;32m    447\u001B[0m sample, objs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_get_sample_object(objs, ndims, keys, names, levels)\n\u001B[0;32m    449\u001B[0m \u001B[38;5;66;03m# Standardize axis parameter to int\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\reshape\\concat.py:487\u001B[0m, in \u001B[0;36m_Concatenator._get_ndims\u001B[1;34m(self, objs)\u001B[0m\n\u001B[0;32m    482\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(obj, (ABCSeries, ABCDataFrame)):\n\u001B[0;32m    483\u001B[0m         msg \u001B[38;5;241m=\u001B[39m (\n\u001B[0;32m    484\u001B[0m             \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcannot concatenate object of type \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mtype\u001B[39m(obj)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m; \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    485\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124monly Series and DataFrame objs are valid\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    486\u001B[0m         )\n\u001B[1;32m--> 487\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m(msg)\n\u001B[0;32m    489\u001B[0m     ndims\u001B[38;5;241m.\u001B[39madd(obj\u001B[38;5;241m.\u001B[39mndim)\n\u001B[0;32m    490\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m ndims\n",
      "\u001B[1;31mTypeError\u001B[0m: cannot concatenate object of type '<class 'tuple'>'; only Series and DataFrame objs are valid"
     ]
    }
   ],
   "execution_count": 136
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T20:12:46.670115Z",
     "start_time": "2024-06-10T20:12:46.524829Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from ema_workbench.em_framework.optimization import epsilon_nondominated, to_problem\n",
    "\n",
    "problem = to_problem(model, searchover=\"levers\")\n",
    "epsilons = [0.05] * len(model.outcomes)\n",
    "merged_archives = epsilon_nondominated(results_df, epsilons, problem)"
   ],
   "id": "93829dd7a2715d3a",
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "cannot concatenate object of type '<class 'tuple'>'; only Series and DataFrame objs are valid",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[130], line 5\u001B[0m\n\u001B[0;32m      3\u001B[0m problem \u001B[38;5;241m=\u001B[39m to_problem(model, searchover\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mlevers\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m      4\u001B[0m epsilons \u001B[38;5;241m=\u001B[39m [\u001B[38;5;241m0.05\u001B[39m] \u001B[38;5;241m*\u001B[39m \u001B[38;5;28mlen\u001B[39m(model\u001B[38;5;241m.\u001B[39moutcomes)\n\u001B[1;32m----> 5\u001B[0m merged_archives \u001B[38;5;241m=\u001B[39m epsilon_nondominated(results, epsilons, problem)\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\ema_workbench\\em_framework\\optimization.py:786\u001B[0m, in \u001B[0;36mepsilon_nondominated\u001B[1;34m(results, epsilons, problem)\u001B[0m\n\u001B[0;32m    781\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m problem\u001B[38;5;241m.\u001B[39mnobjs \u001B[38;5;241m!=\u001B[39m \u001B[38;5;28mlen\u001B[39m(epsilons):\n\u001B[0;32m    782\u001B[0m     \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m    783\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mThe number of epsilon values (\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mlen\u001B[39m(epsilons)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m) must match the number of objectives \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mproblem\u001B[38;5;241m.\u001B[39mnobjs\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    784\u001B[0m     )\n\u001B[1;32m--> 786\u001B[0m results \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mconcat(results, ignore_index\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[0;32m    787\u001B[0m solutions \u001B[38;5;241m=\u001B[39m rebuild_platypus_population(results, problem)\n\u001B[0;32m    788\u001B[0m archive \u001B[38;5;241m=\u001B[39m EpsilonBoxArchive(epsilons)\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\reshape\\concat.py:380\u001B[0m, in \u001B[0;36mconcat\u001B[1;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001B[0m\n\u001B[0;32m    377\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m copy \u001B[38;5;129;01mand\u001B[39;00m using_copy_on_write():\n\u001B[0;32m    378\u001B[0m     copy \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[1;32m--> 380\u001B[0m op \u001B[38;5;241m=\u001B[39m _Concatenator(\n\u001B[0;32m    381\u001B[0m     objs,\n\u001B[0;32m    382\u001B[0m     axis\u001B[38;5;241m=\u001B[39maxis,\n\u001B[0;32m    383\u001B[0m     ignore_index\u001B[38;5;241m=\u001B[39mignore_index,\n\u001B[0;32m    384\u001B[0m     join\u001B[38;5;241m=\u001B[39mjoin,\n\u001B[0;32m    385\u001B[0m     keys\u001B[38;5;241m=\u001B[39mkeys,\n\u001B[0;32m    386\u001B[0m     levels\u001B[38;5;241m=\u001B[39mlevels,\n\u001B[0;32m    387\u001B[0m     names\u001B[38;5;241m=\u001B[39mnames,\n\u001B[0;32m    388\u001B[0m     verify_integrity\u001B[38;5;241m=\u001B[39mverify_integrity,\n\u001B[0;32m    389\u001B[0m     copy\u001B[38;5;241m=\u001B[39mcopy,\n\u001B[0;32m    390\u001B[0m     sort\u001B[38;5;241m=\u001B[39msort,\n\u001B[0;32m    391\u001B[0m )\n\u001B[0;32m    393\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m op\u001B[38;5;241m.\u001B[39mget_result()\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\reshape\\concat.py:446\u001B[0m, in \u001B[0;36m_Concatenator.__init__\u001B[1;34m(self, objs, axis, join, keys, levels, names, ignore_index, verify_integrity, copy, sort)\u001B[0m\n\u001B[0;32m    443\u001B[0m objs, keys \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_clean_keys_and_objs(objs, keys)\n\u001B[0;32m    445\u001B[0m \u001B[38;5;66;03m# figure out what our result ndim is going to be\u001B[39;00m\n\u001B[1;32m--> 446\u001B[0m ndims \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_get_ndims(objs)\n\u001B[0;32m    447\u001B[0m sample, objs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_get_sample_object(objs, ndims, keys, names, levels)\n\u001B[0;32m    449\u001B[0m \u001B[38;5;66;03m# Standardize axis parameter to int\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\reshape\\concat.py:487\u001B[0m, in \u001B[0;36m_Concatenator._get_ndims\u001B[1;34m(self, objs)\u001B[0m\n\u001B[0;32m    482\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(obj, (ABCSeries, ABCDataFrame)):\n\u001B[0;32m    483\u001B[0m         msg \u001B[38;5;241m=\u001B[39m (\n\u001B[0;32m    484\u001B[0m             \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcannot concatenate object of type \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mtype\u001B[39m(obj)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m; \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    485\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124monly Series and DataFrame objs are valid\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    486\u001B[0m         )\n\u001B[1;32m--> 487\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m(msg)\n\u001B[0;32m    489\u001B[0m     ndims\u001B[38;5;241m.\u001B[39madd(obj\u001B[38;5;241m.\u001B[39mndim)\n\u001B[0;32m    490\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m ndims\n",
      "\u001B[1;31mTypeError\u001B[0m: cannot concatenate object of type '<class 'tuple'>'; only Series and DataFrame objs are valid"
     ]
    }
   ],
   "execution_count": 130
  },
  {
   "cell_type": "code",
   "id": "27ba29de-d899-4ebf-8874-02558697fab7",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-06-10T20:01:00.123980Z",
     "start_time": "2024-06-10T20:01:00.116790Z"
    }
   },
   "source": "(y1,t1) , (y2,t2) = results",
   "outputs": [],
   "execution_count": 121
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T20:03:01.303137Z",
     "start_time": "2024-06-10T20:03:01.281714Z"
    }
   },
   "cell_type": "code",
   "source": "t2",
   "id": "2511e086bbddd695",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   epsilon_progress  nfe\n",
       "0                 0    0\n",
       "1                 3  100"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epsilon_progress</th>\n",
       "      <th>nfe</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 127
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T20:01:10.723485Z",
     "start_time": "2024-06-10T20:01:10.675343Z"
    }
   },
   "cell_type": "code",
   "source": [
    "y = y1+y2\n",
    "y"
   ],
   "id": "9dc0e263c5b34ee3",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   0_RfR 0  0_RfR 1  0_RfR 2  0_RfR 3  0_RfR 4  1_RfR 0  1_RfR 1  1_RfR 2  \\\n",
       "0        1        1        1        0        1        1        1        0   \n",
       "\n",
       "   1_RfR 3  1_RfR 4  ...  A.5_DikeIncrease 1  A.5_DikeIncrease 2  \\\n",
       "0        0        1  ...                  14                  12   \n",
       "\n",
       "   A.5_DikeIncrease 3  A.5_DikeIncrease 4  Expected Annual Damage A4  \\\n",
       "0                  10                  11                        0.0   \n",
       "\n",
       "   Expected Annual Damage A5  Expected Number of Deaths in A4  \\\n",
       "0               3.569558e+06                              0.0   \n",
       "\n",
       "   Expected Number of Deaths in A5   Total Costs  \\\n",
       "0                         0.000581  4.259133e+09   \n",
       "\n",
       "   Aggregated Expected Number of Deaths A1-A3  \n",
       "0                                         0.0  \n",
       "\n",
       "[1 rows x 57 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0_RfR 0</th>\n",
       "      <th>0_RfR 1</th>\n",
       "      <th>0_RfR 2</th>\n",
       "      <th>0_RfR 3</th>\n",
       "      <th>0_RfR 4</th>\n",
       "      <th>1_RfR 0</th>\n",
       "      <th>1_RfR 1</th>\n",
       "      <th>1_RfR 2</th>\n",
       "      <th>1_RfR 3</th>\n",
       "      <th>1_RfR 4</th>\n",
       "      <th>...</th>\n",
       "      <th>A.5_DikeIncrease 1</th>\n",
       "      <th>A.5_DikeIncrease 2</th>\n",
       "      <th>A.5_DikeIncrease 3</th>\n",
       "      <th>A.5_DikeIncrease 4</th>\n",
       "      <th>Expected Annual Damage A4</th>\n",
       "      <th>Expected Annual Damage A5</th>\n",
       "      <th>Expected Number of Deaths in A4</th>\n",
       "      <th>Expected Number of Deaths in A5</th>\n",
       "      <th>Total Costs</th>\n",
       "      <th>Aggregated Expected Number of Deaths A1-A3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>14</td>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.569558e+06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000581</td>\n",
       "      <td>4.259133e+09</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 57 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 123
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T19:52:34.812783Z",
     "start_time": "2024-06-10T19:52:32.951445Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from ema_workbench.em_framework.optimization import epsilon_nondominated, to_problem\n",
    "\n",
    "problem = to_problem(model, searchover=\"levers\")\n",
    "epsilons = [0.05] * len(model.outcomes)\n",
    "merged_archives = epsilon_nondominated(results, epsilons, problem)"
   ],
   "id": "609ad4c2297f73c6",
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "cannot concatenate object of type '<class 'tuple'>'; only Series and DataFrame objs are valid",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[112], line 5\u001B[0m\n\u001B[0;32m      3\u001B[0m problem \u001B[38;5;241m=\u001B[39m to_problem(model, searchover\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mlevers\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m      4\u001B[0m epsilons \u001B[38;5;241m=\u001B[39m [\u001B[38;5;241m0.05\u001B[39m] \u001B[38;5;241m*\u001B[39m \u001B[38;5;28mlen\u001B[39m(model\u001B[38;5;241m.\u001B[39moutcomes)\n\u001B[1;32m----> 5\u001B[0m merged_archives \u001B[38;5;241m=\u001B[39m epsilon_nondominated(results, epsilons, problem)\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\ema_workbench\\em_framework\\optimization.py:786\u001B[0m, in \u001B[0;36mepsilon_nondominated\u001B[1;34m(results, epsilons, problem)\u001B[0m\n\u001B[0;32m    781\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m problem\u001B[38;5;241m.\u001B[39mnobjs \u001B[38;5;241m!=\u001B[39m \u001B[38;5;28mlen\u001B[39m(epsilons):\n\u001B[0;32m    782\u001B[0m     \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m    783\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mThe number of epsilon values (\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mlen\u001B[39m(epsilons)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m) must match the number of objectives \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mproblem\u001B[38;5;241m.\u001B[39mnobjs\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    784\u001B[0m     )\n\u001B[1;32m--> 786\u001B[0m results \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mconcat(results, ignore_index\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[0;32m    787\u001B[0m solutions \u001B[38;5;241m=\u001B[39m rebuild_platypus_population(results, problem)\n\u001B[0;32m    788\u001B[0m archive \u001B[38;5;241m=\u001B[39m EpsilonBoxArchive(epsilons)\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\reshape\\concat.py:380\u001B[0m, in \u001B[0;36mconcat\u001B[1;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001B[0m\n\u001B[0;32m    377\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m copy \u001B[38;5;129;01mand\u001B[39;00m using_copy_on_write():\n\u001B[0;32m    378\u001B[0m     copy \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[1;32m--> 380\u001B[0m op \u001B[38;5;241m=\u001B[39m _Concatenator(\n\u001B[0;32m    381\u001B[0m     objs,\n\u001B[0;32m    382\u001B[0m     axis\u001B[38;5;241m=\u001B[39maxis,\n\u001B[0;32m    383\u001B[0m     ignore_index\u001B[38;5;241m=\u001B[39mignore_index,\n\u001B[0;32m    384\u001B[0m     join\u001B[38;5;241m=\u001B[39mjoin,\n\u001B[0;32m    385\u001B[0m     keys\u001B[38;5;241m=\u001B[39mkeys,\n\u001B[0;32m    386\u001B[0m     levels\u001B[38;5;241m=\u001B[39mlevels,\n\u001B[0;32m    387\u001B[0m     names\u001B[38;5;241m=\u001B[39mnames,\n\u001B[0;32m    388\u001B[0m     verify_integrity\u001B[38;5;241m=\u001B[39mverify_integrity,\n\u001B[0;32m    389\u001B[0m     copy\u001B[38;5;241m=\u001B[39mcopy,\n\u001B[0;32m    390\u001B[0m     sort\u001B[38;5;241m=\u001B[39msort,\n\u001B[0;32m    391\u001B[0m )\n\u001B[0;32m    393\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m op\u001B[38;5;241m.\u001B[39mget_result()\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\reshape\\concat.py:446\u001B[0m, in \u001B[0;36m_Concatenator.__init__\u001B[1;34m(self, objs, axis, join, keys, levels, names, ignore_index, verify_integrity, copy, sort)\u001B[0m\n\u001B[0;32m    443\u001B[0m objs, keys \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_clean_keys_and_objs(objs, keys)\n\u001B[0;32m    445\u001B[0m \u001B[38;5;66;03m# figure out what our result ndim is going to be\u001B[39;00m\n\u001B[1;32m--> 446\u001B[0m ndims \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_get_ndims(objs)\n\u001B[0;32m    447\u001B[0m sample, objs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_get_sample_object(objs, ndims, keys, names, levels)\n\u001B[0;32m    449\u001B[0m \u001B[38;5;66;03m# Standardize axis parameter to int\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\reshape\\concat.py:487\u001B[0m, in \u001B[0;36m_Concatenator._get_ndims\u001B[1;34m(self, objs)\u001B[0m\n\u001B[0;32m    482\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(obj, (ABCSeries, ABCDataFrame)):\n\u001B[0;32m    483\u001B[0m         msg \u001B[38;5;241m=\u001B[39m (\n\u001B[0;32m    484\u001B[0m             \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcannot concatenate object of type \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mtype\u001B[39m(obj)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m; \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    485\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124monly Series and DataFrame objs are valid\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    486\u001B[0m         )\n\u001B[1;32m--> 487\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m(msg)\n\u001B[0;32m    489\u001B[0m     ndims\u001B[38;5;241m.\u001B[39madd(obj\u001B[38;5;241m.\u001B[39mndim)\n\u001B[0;32m    490\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m ndims\n",
      "\u001B[1;31mTypeError\u001B[0m: cannot concatenate object of type '<class 'tuple'>'; only Series and DataFrame objs are valid"
     ]
    }
   ],
   "execution_count": 112
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Gelderland\n",
   "id": "f104ee039321b72"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-11T05:48:38.864386Z",
     "start_time": "2024-06-11T05:48:38.558731Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = problem_formulation_actor(5)\n",
    "for outcome in model.outcomes:\n",
    "    print(repr((outcome)))"
   ],
   "id": "2286227eebd36278",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ScalarOutcome('Expected Annual Damage A1-4', variable_name=('A.1_Expected Annual Damage', 'A.2_Expected Annual Damage', 'A.3_Expected Annual Damage', 'A.4_Expected Annual Damage'), function=<function sum_over at 0x000001F1775E7BA0>)\n",
      "ScalarOutcome('Investment Costs A1-4', variable_name=('A.1_Dike Investment Costs', 'A.2_Dike Investment Costs', 'A.3_Dike Investment Costs', 'A.4_Dike Investment Costs'), function=<function sum_over at 0x000001F1775E7BA0>)\n",
      "ScalarOutcome('Expected Number of Deaths in A1-4', variable_name=('A.1_Expected Number of Deaths', 'A.2_Expected Number of Deaths', 'A.3_Expected Number of Deaths', 'A.4_Expected Number of Deaths'), function=<function sum_over at 0x000001F1775E7BA0>)\n"
     ]
    }
   ],
   "execution_count": 139
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "convergence_metrics = {EpsilonProgress()}\n",
    "constraint = [Constraint(\"Total Costs\", outcome_names=\"Total Costs\", function=lambda x: max(0, x - 700000000))]\n",
    "\n",
    "results_df = pd.DataFrame()\n",
    "with MultiprocessingEvaluator(model) as evaluator:\n",
    "    for _ in range(2):\n",
    "       results = evaluator.optimize(nfe=2, searchover='levers',\n",
    "                                     convergence=convergence_metrics,\n",
    "                                     epsilons=[1]*len(model.outcomes), reference=ref_scenario,\n",
    "                                     constraints=constraint)\n",
    "        \n",
    "        \n",
    "save_results(results, 'Week23_MORDM_Reference_1000_PD6.tar.gz')\n"
   ],
   "id": "b6b9fdf3b1c5eac6"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
