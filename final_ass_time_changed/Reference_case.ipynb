{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d461b0ee-63ce-4fa7-95cc-f8916b56fb1a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-04T16:38:53.585960Z",
     "start_time": "2024-06-04T16:38:40.328401Z"
    },
    "tags": []
   },
   "source": [
    "import pandas as pd"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "initial_id",
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "tags": []
   },
   "source": [
    "from dike_model_function import DikeNetwork  # @UnresolvedImport\n",
    "# Loading in the necessary modules for EMA workbench and functions\n",
    "from ema_workbench import (Model, MultiprocessingEvaluator, Policy, Scenario, ScalarOutcome)\n",
    "\n",
    "from ema_workbench.em_framework.evaluators import perform_experiments\n",
    "from ema_workbench.em_framework.samplers import sample_uncertainties\n",
    "from ema_workbench.util import ema_logging\n",
    "import time\n",
    "from problem_formulation import get_model_for_problem_formulation\n",
    "from problem_formulation import sum_over, sum_over_time\n",
    "from ema_workbench import save_results, load_results\n",
    "import numpy as np\n",
    "import copy\n",
    "\n",
    "# Loading in all the 17 objectives via predefined problem formulation 3\n",
    "if __name__ == '__main__':\n",
    "    ema_logging.log_to_stderr(ema_logging.INFO)\n",
    "\n",
    "    dike_model, planning_steps = get_model_for_problem_formulation(3)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b6b301ac7683c5ee",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-04T16:39:07.959113Z",
     "start_time": "2024-06-04T16:39:07.918594Z"
    },
    "tags": []
   },
   "source": [
    "# Replicate the objectives\n",
    "for outcome in dike_model.outcomes:\n",
    "    print(repr(type(outcome)))\n",
    "    "
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "277a36e0-e5d8-4d34-9f17-3118ef97a1e3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-04T16:39:08.322746Z",
     "start_time": "2024-06-04T16:39:08.005704Z"
    },
    "tags": []
   },
   "source": [
    "# Writing a function to create actor specific problem formulations\n",
    "def problem_formulation_actor(problem_formulation_actor):\n",
    "   \n",
    "    # Load the model:\n",
    "    function = DikeNetwork()\n",
    "    # workbench model:\n",
    "    model = Model('dikesnet', function=function)\n",
    "    # Outcomes are all costs, thus they have to minimized:\n",
    "    direction = ScalarOutcome.MINIMIZE\n",
    "    \n",
    "    model.uncertainties = uncertainties\n",
    "    model.levers = levers\n",
    "    \n",
    "    cost_variables = []\n",
    "    cost_variables.extend(\n",
    "    [\n",
    "        f\"{dike}_{e}\"\n",
    "        for e in [\"Expected Annual Damage\", \"Dike Investment Costs\"]\n",
    "        for dike in function.dikelist\n",
    "    ])\n",
    "    cost_variables.extend([f\"RfR Total Costs\"])\n",
    "    cost_variables.extend([f\"Expected Evacuation Costs\"])\n",
    "\n",
    "\n",
    "    if problem_formulation_actor == 4: #RWS\n",
    "        model.outcomes.clear()\n",
    "        model.outcomes = [\n",
    "            ScalarOutcome('Expected Annual Damage',\n",
    "                            variable_name=['{}_Expected Annual Damage'.format(dike)\n",
    "                                                for dike in function.dikelist],\n",
    "                            function=sum_over, kind=direction),\n",
    "\n",
    "            ScalarOutcome('Total Investment Costs',\n",
    "                            variable_name=['{}_Dike Investment Costs'.format(dike)\n",
    "                                                for dike in function.dikelist] + ['RfR Total Costs'\n",
    "                                                                                ] + ['Expected Evacuation Costs'],\n",
    "                            function=sum_over, kind=direction),\n",
    "\n",
    "            ScalarOutcome('Expected Number of Deaths',\n",
    "                            variable_name=['{}_Expected Number of Deaths'.format(dike)\n",
    "                                                for dike in function.dikelist],\n",
    "                            function=sum_over, kind=direction)] \n",
    "    \n",
    "    elif problem_formulation_actor == 5: # GELDERLAND\n",
    "        model.outcomes.clear()\n",
    "        model.outcomes = [\n",
    "            ScalarOutcome('Expected Annual Damage A1-4',\n",
    "                            variable_name=['A.1_Expected Annual Damage' ,'A.2_Expected Annual Damage', 'A.3_Expected Annual Damage', 'A.4_Expected Annual Damage'], function=sum_over, kind=direction),\n",
    "\n",
    "            ScalarOutcome('Investment Costs A1-4',\n",
    "                            variable_name=['A.1_Dike Investment Costs', 'A.2_Dike Investment Costs', 'A.3_Dike Investment Costs', 'A.4_Dike Investment Costs'], function=sum_over, kind=direction),\n",
    "\n",
    "            ScalarOutcome('Expected Number of Deaths in A1-4',\n",
    "                            variable_name=['A.1_Expected Number of Deaths', 'A.2_Expected Number of Deaths', 'A.3_Expected Number of Deaths', 'A.4_Expected Number of Deaths'], function=sum_over, kind=direction)]\n",
    "    \n",
    "    elif problem_formulation_actor == 6: # OVERIJSSEL\n",
    "        model.outcomes.clear()\n",
    "        model.outcomes = [\n",
    "            ScalarOutcome('Expected Annual Damage A4', variable_name='A.4_Expected Annual Damage', function = sum_over, kind=direction),\n",
    "            ScalarOutcome('Expected Annual Damage A5', variable_name='A.5_Expected Annual Damage', function = sum_over, kind=direction),            \n",
    "            ScalarOutcome('Expected Number of Deaths in A4', variable_name='A.4_Expected Number of Deaths',function = sum_over, kind=direction),\n",
    "            ScalarOutcome('Expected Number of Deaths in A5', variable_name='A.5_Expected Number of Deaths',function = sum_over, kind=direction),\n",
    "            ScalarOutcome('Total Costs', variable_name=cost_variables, function = sum_over, kind=direction)]\n",
    "    \n",
    "    else:\n",
    "        raise TypeError('unknown identifier')\n",
    "    return model"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1bfd2ae6-5f22-4449-a17a-d82042a02813",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-04T16:39:08.558348Z",
     "start_time": "2024-06-04T16:39:08.332809Z"
    },
    "tags": []
   },
   "source": [
    "# Replicate the uncertainties\n",
    "uncertainties = dike_model.uncertainties\n",
    "uncertainties = copy.deepcopy(dike_model.uncertainties)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d2c96536-35ba-4172-b925-62abbc885eaa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-04T16:39:08.762876Z",
     "start_time": "2024-06-04T16:39:08.566695Z"
    },
    "tags": []
   },
   "source": [
    "levers = dike_model.levers \n",
    "levers = copy.deepcopy(dike_model.levers)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "a91639a2468a9adc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-04T16:39:12.130290Z",
     "start_time": "2024-06-04T16:39:10.571017Z"
    },
    "tags": []
   },
   "source": [
    "model = problem_formulation_actor(6)\n",
    "for outcome in model.outcomes:\n",
    "    print(repr((outcome)))"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "adac028e40648723",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8dc875ff-0e3b-4e4c-81bf-050b8ee99b44",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-04T16:39:12.146680Z",
     "start_time": "2024-06-04T16:39:12.135662Z"
    },
    "tags": []
   },
   "source": [
    "print(len(model.outcomes))"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3347b377161d722f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-04T16:39:12.220600Z",
     "start_time": "2024-06-04T16:39:12.152432Z"
    },
    "tags": []
   },
   "source": [
    "print(sum_over_time(0.0, 0.0, 0.9))  # Expected output: 0.0"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9f39c8db-6f38-4efa-868e-004bd149c4ef",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-04T16:39:13.106376Z",
     "start_time": "2024-06-04T16:39:13.096476Z"
    },
    "tags": []
   },
   "source": [
    "for outcome in model.outcomes:\n",
    "    print(repr(outcome))"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c33cfae19ab29a95",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-04T16:39:14.726799Z",
     "start_time": "2024-06-04T16:39:14.718190Z"
    },
    "tags": []
   },
   "source": [
    "for outcome in dike_model.outcomes:\n",
    "    print(repr(outcome))"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3b5e260bcd0a1bc3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-04T16:39:16.091674Z",
     "start_time": "2024-06-04T16:39:16.076765Z"
    },
    "tags": []
   },
   "source": [
    "reference_values = {\n",
    "    \"Bmax\": 175,\n",
    "    \"Brate\": 1.5,\n",
    "    \"pfail\": 0.5,\n",
    "    \"ID flood wave shape\": 4,\n",
    "    \"planning steps\": 2,\n",
    "}\n",
    "reference_values.update({f\"discount rate {n}\": 3.5 for n in planning_steps})\n",
    "refcase_scen = {}\n",
    "\n",
    "for key in dike_model.uncertainties:\n",
    "    name_split = key.name.split('_')\n",
    "    if len(name_split) == 1:\n",
    "\n",
    "        refcase_scen.update({key.name: reference_values[key.name]})\n",
    "    else:\n",
    "        refcase_scen.update({key.name: reference_values[name_split[1]]})\n",
    "            \n",
    "ref_scenario = Scenario('reference', **refcase_scen)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "599901d1-250d-4153-afdb-481704103558",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-04T16:39:17.078601Z",
     "start_time": "2024-06-04T16:39:17.062275Z"
    },
    "tags": []
   },
   "source": [
    "# Loading in the right packages for running the optimization\n",
    "from ema_workbench.em_framework.optimization import (EpsilonProgress)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "51aeba8593a9ed87",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-06-04T16:39:20.495278Z"
    },
    "jupyter": {
     "is_executing": true
    },
    "tags": []
   },
   "source": [
    "#convergence_metrics = {EpsilonProgress()}\n",
    "\n",
    "#with MultiprocessingEvaluator(model,n_processes=-1) as evaluator:\n",
    " #   results2 = evaluator.optimize(nfe=5000, searchover='levers',\n",
    "                                 #convergence=convergence_metrics,\n",
    "                                 #epsilons=[0.01]*len(model.outcomes), reference=ref_scenario)\n",
    "\n",
    "#save_results(results2, 'Experiments/Week23_MORDM_Reference_1000_PD6.tar.gz')\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c0607a53-4224-462e-b88c-b188a3f129db",
   "metadata": {
    "tags": []
   },
   "source": [
    "\n",
    "y,t = results2"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "27ba29de-d899-4ebf-8874-02558697fab7",
   "metadata": {
    "tags": []
   },
   "source": [
    "y"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "b8152c46-e1d4-4eac-84be-cb06bdeb7e22",
   "metadata": {},
   "source": [
    "### Worst Case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a02d93cb-e5c4-4858-a172-1262f4a5eea3",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Worst case specification\n",
    "worstcase_values ={\n",
    "    \"Bmax\": 175,\n",
    "    \"Brate\": 1.5,\n",
    "    \"pfail\": 0.9,\n",
    "    \"ID flood wave shape\": 4,\n",
    "    \"planning steps\": 2,\n",
    "}\n",
    "worstcase_values.update({f\"discount rate {n}\": 3.5 for n in planning_steps})\n",
    "\n",
    "worstcase_scen = {}\n",
    "\n",
    "for key in dike_model.uncertainties:\n",
    "    name_split = key.name.split('_')\n",
    "    if len(name_split) == 1:\n",
    "\n",
    "        worstcase_scen.update({key.name: worstcase_values[key.name]})\n",
    "    else:\n",
    "        worstcase_scen.update({key.name: worstcase_values[name_split[1]]})\n",
    "            \n",
    "worst_scenario = Scenario('reference', **worstcase_scen)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3eee8846-13bc-45bf-8f70-0afd4d6a12db",
   "metadata": {
    "tags": []
   },
   "source": [
    "#convergence_metrics = {EpsilonProgress()}\n",
    "\n",
    "#with MultiprocessingEvaluator(model,n_processes=-1) as evaluator:\n",
    "  #  results3 = evaluator.optimize(nfe=4000, searchover='levers',\n",
    "     #                            convergence=convergence_metrics,\n",
    "      #                           epsilons=[0.01]*len(model.outcomes), reference=worst_scenario)\n",
    "\n",
    "#save_results(results2, 'Experiments/Week23_MORDM_Reference_1000_PD6.tar.gz')\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9392a969-675b-4798-aaae-2c20e9dabdf8",
   "metadata": {
    "tags": []
   },
   "source": [
    "worst_case.to_csv('MODRM_WC.csv')"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7ac27e4f-3a71-4f33-aba7-bfe8c980bf6b",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Selecting the policies that are proposed as solutions for further robustness tests\n",
    "from ema_workbench import Policy\n",
    "\n",
    "worstcase_policies_to_evaluate = []\n",
    "\n",
    "for i, policy in import_worst_case.iterrows():\n",
    "    worstcase_policies_to_evaluate.append(Policy(str(i), **policy.to_dict()))"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3065333a-f7f9-4489-8910-65ce256bec4a",
   "metadata": {
    "tags": []
   },
   "source": [
    "n_scenarios = 2000\n",
    "#with MultiprocessingEvaluator(model) as evaluator:\n",
    " #   worst_results = evaluator.perform_experiments(n_scenarios,\n",
    "  #                                          worstcase_policies_to_evaluate)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "238143e8-e9fe-4eb2-a9f4-6c6352a31829",
   "metadata": {
    "tags": []
   },
   "source": [
    "save_results(worst_results, 'Week23_worst_case_2000_4.tar.gz')"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "dccaaf26-6045-404a-bcf5-2de52622cca5",
   "metadata": {},
   "source": [
    "### reference case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "79f610a9-0759-4267-988f-6b6efcd7f219",
   "metadata": {
    "tags": []
   },
   "source": [
    "reference_case_re = pd.read_csv('MODRM_DF.csv')"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cc27b2e1-3694-4e30-8a98-f5be13968a7b",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Selecting the policies that are proposed as solutions for further robustness tests\n",
    "from ema_workbench import Policy\n",
    "\n",
    "refercase_policies_to_evaluate = []\n",
    "\n",
    "for i, policy in reference_case_re.iterrows():\n",
    "    refercase_policies_to_evaluate.append(Policy(str(i), **policy.to_dict()))"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2c5d3fdb-a091-40c8-9fb1-57027005e6e6",
   "metadata": {
    "tags": []
   },
   "source": [
    "n_scenarios = 2000\n",
    "with MultiprocessingEvaluator(model) as evaluator:\n",
    "    reference_policies_results = evaluator.perform_experiments(n_scenarios,\n",
    "                                            refercase_policies_to_evaluate)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fd8b8755-6ff4-4cfc-bb55-b39b518f2efe",
   "metadata": {
    "tags": []
   },
   "source": [
    "save_results(reference_policies_results, 'Week23_reference_case_2000_6.tar.gz')"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19e77fe7-4e5d-45be-b719-844a5ca4c3eb",
   "metadata": {},
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "c71d4857-f0d9-4d15-b528-0aabc7fe0bf8",
   "metadata": {},
   "source": [
    "# MODRM GRAPHS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "13831fcf-71a2-487d-9a18-534d8c869b6f",
   "metadata": {
    "tags": []
   },
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Correct way to read a CSV file into a DataFrame\n",
    "rf_policy_set= pd.read_csv('MODRM_DF.csv')\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "f88610e9-8cf1-4fb3-91c4-f5b0089630b8",
   "metadata": {
    "tags": []
   },
   "source": [
    "rf_policy_set"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "2e0c9d0e-05e1-4413-985f-f4487d757c2e",
   "metadata": {
    "tags": []
   },
   "source": [
    "from ema_workbench.analysis import parcoords\n",
    "\n",
    "ref_data = rf_policy_set.loc[:, [o.name for o in model.outcomes]]\n",
    "ref_limits = parcoords.get_limits(ref_data)\n",
    "ref_limits.loc[0, ['Expected Annual Damage A4', 'Expected Annual Damage A5','Expected Number of Deaths in A5', 'Expected Number of Deaths in A4', 'Total Costs']] = 0\n",
    "\n",
    "paraxes = parcoords.ParallelAxes(ref_limits)\n",
    "paraxes.plot(ref_data)\n",
    "plt.title('Trade-offs in Reference case scenario')\n",
    "\n",
    "# Set figure size\n",
    "# Run this twice, to get a nice broad view\n",
    "fig_size = plt.rcParams[\"figure.figsize\"]\n",
    "\n",
    "fig_size[0] = 12\n",
    "fig_size[1] = 12\n",
    "plt.rcParams[\"figure.figsize\"] = fig_size\n",
    "plt.show()\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "b7aa963f-5691-4aa4-97d3-73425c62fcad",
   "metadata": {
    "tags": []
   },
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from ema_workbench.analysis import parcoords\n",
    "\n",
    "# Assuming WC_policy_set and model are already defined\n",
    "ref_data = rf_policy_set.loc[:, [o.name for o in model.outcomes]]\n",
    "ref_limits = parcoords.get_limits(ref_data)\n",
    "ref_limits.loc[0, ['Expected Annual Damage A4', 'Expected Annual Damage A5',\n",
    "                   'Expected Number of Deaths in A5', 'Expected Number of Deaths in A4', 'Total Costs']] = 0\n",
    "\n",
    "# Create a ParallelAxes object\n",
    "paraxes = parcoords.ParallelAxes(ref_limits)\n",
    "\n",
    "# Generate a color palette\n",
    "colors = sns.color_palette('husl', len(rf_policy_set))\n",
    "\n",
    "# Plot each policy individually with a corresponding color and label\n",
    "for i, (index, row) in enumerate(rf_policy_set.iterrows()):\n",
    "    outcomes = row.loc[['Expected Annual Damage A4', 'Expected Annual Damage A5',\n",
    "                        'Expected Number of Deaths in A5', 'Expected Number of Deaths in A4', 'Total Costs']]\n",
    "    paraxes.plot(outcomes.to_frame().T, color=colors[i], label=f'Policy {index}')\n",
    "\n",
    "# Add a legend to the plot\n",
    "paraxes.legend()\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "61da1a99-3d64-41f4-bfa6-2c80fbbe3e24",
   "metadata": {
    "tags": []
   },
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Correct way to read a CSV file into a DataFrame\n",
    "WC_policy_set= pd.read_csv('MODRM_WC.csv')\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "4529ddef-b00f-44ff-9602-211eb319f291",
   "metadata": {
    "tags": []
   },
   "source": [
    "WC_policy_set"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "ba14c010-31b4-4fe3-a714-dcd164858ce6",
   "metadata": {
    "tags": []
   },
   "source": [
    "from ema_workbench.analysis import parcoords\n",
    "\n",
    "ref_data = WC_policy_set.loc[:, [o.name for o in model.outcomes]]\n",
    "ref_limits = parcoords.get_limits(ref_data)\n",
    "ref_limits.loc[0, ['Expected Annual Damage A4', 'Expected Annual Damage A5','Expected Number of Deaths in A5', 'Expected Number of Deaths in A4', 'Total Costs']] = 0\n",
    "\n",
    "paraxes = parcoords.ParallelAxes(ref_limits)\n",
    "paraxes.plot(ref_data)\n",
    "plt.title('Trade-offs in Worst case scenario')\n",
    "paraxes.legend()\n",
    "# Set figure size\n",
    "# Run this twice, to get a nice broad view\n",
    "fig_size = plt.rcParams[\"figure.figsize\"]\n",
    "fig_size[0] = 12\n",
    "fig_size[1] = 12\n",
    "plt.rcParams[\"figure.figsize\"] = fig_size\n",
    "plt.show()\n",
    "\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "b2524d00-93f0-4426-98e2-c71693a3c71c",
   "metadata": {
    "tags": []
   },
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from ema_workbench.analysis import parcoords\n",
    "\n",
    "# Assuming WC_policy_set and model are already defined\n",
    "ref_data = WC_policy_set.loc[:, [o.name for o in model.outcomes]]\n",
    "ref_limits = parcoords.get_limits(ref_data)\n",
    "ref_limits.loc[0, ['Expected Annual Damage A4', 'Expected Annual Damage A5',\n",
    "                   'Expected Number of Deaths in A5', 'Expected Number of Deaths in A4', 'Total Costs']] = 0\n",
    "\n",
    "# Create a ParallelAxes object\n",
    "paraxes = parcoords.ParallelAxes(ref_limits)\n",
    "\n",
    "# Generate a color palette\n",
    "colors = sns.color_palette('husl', len(WC_policy_set))\n",
    "\n",
    "# Plot each policy individually with a corresponding color and label\n",
    "for i, (index, row) in enumerate(WC_policy_set.iterrows()):\n",
    "    outcomes = row.loc[['Expected Annual Damage A4', 'Expected Annual Damage A5',\n",
    "                        'Expected Number of Deaths in A5', 'Expected Number of Deaths in A4', 'Total Costs']]\n",
    "    paraxes.plot(outcomes.to_frame().T, color=colors[i], label=f'Policy {index}')\n",
    "\n",
    "# Add a legend to the plot\n",
    "paraxes.legend()\n",
    "\n",
    "# Set the figure size\n",
    "plt.figure(figsize=(12, 12))\n",
    "\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "0741ec9b-975f-49f0-9ed6-e6164761a9c5",
   "metadata": {},
   "source": [
    "# PRIM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "ddfffbd3-ab8c-48a2-8ba7-1209975bb60d",
   "metadata": {
    "tags": []
   },
   "source": [
    "rf_em = load_results('Week23_reference_case_2000_6.tar.gz')"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "8a3585d9-7a1d-4089-a42d-88bc84184c45",
   "metadata": {
    "tags": []
   },
   "source": [
    "experiments_rfem, outcomes_rfem = rf_em"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "b50dd6f0-165f-4319-86b9-bc6353378e70",
   "metadata": {
    "tags": []
   },
   "source": [
    "experiments_rfem[:, "
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "c239158e-0c86-40fb-9e5e-ab3bfc7d45e9",
   "metadata": {
    "tags": []
   },
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming outcomes_rfem is a tuple containing a DataFrame and a dictionary\n",
    "experiments_df, outcomes_dict = rf_em\n",
    "\n",
    "# Extract the policy data\n",
    "policies = experiments_df['policy']\n",
    "\n",
    "# Create a DataFrame from the outcomes dictionary and add the policy column\n",
    "outcomes_df = pd.DataFrame(outcomes_dict)\n",
    "outcomes_df['policy'] = policies.values\n",
    "\n",
    "# Calculate the mean of each outcome for each policy\n",
    "mean_outcomes = outcomes_df.groupby('policy').mean()\n",
    "\n",
    "# Plot the mean outcomes against the policies\n",
    "mean_outcomes.plot(kind='bar', figsize=(12, 8))\n",
    "plt.title('Mean Outcomes by Policy')\n",
    "plt.xlabel('Policy')\n",
    "plt.ylabel('Mean Value')\n",
    "plt.legend(title='Outcomes')\n",
    "plt.show()\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "880610ea-9c9d-427c-b1be-fce4f52dba3b",
   "metadata": {
    "tags": []
   },
   "source": [
    "policiess = experiments_rfem.iloc[:,19:]\n",
    "policiess"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "dc8a374b-77bc-4be9-81de-dca169403d35",
   "metadata": {
    "tags": []
   },
   "source": [
    "scenaaa =experiments_rfem.iloc[:,:19]\n",
    "scenaaa"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "397eaf35-d9d7-4f74-8fd7-ee22b51b10ba",
   "metadata": {
    "tags": []
   },
   "source": [
    "outcomes_rfem['Expected Annual Damage A4']"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "3976c2c6-033c-4ce2-8753-878d8c04bb94",
   "metadata": {
    "tags": []
   },
   "source": [
    "outcomes_rfem"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "cb5666c4-a939-4c55-8e99-4b3e5a6690f2",
   "metadata": {
    "tags": []
   },
   "source": [
    "from ema_workbench.analysis import prim\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data = outcomes_rfem['Total Costs']\n",
    "\n",
    "# With continious outcomes, probably the only way to prim is throufh percentile??\n",
    "\n",
    "y = data < np.percentile(data, 10)\n",
    "\n",
    "# Initialize PRIM algorithm with the appropriate mode\n",
    "prim_alg = prim.Prim(experiments_rfem, y, threshold=0.7)\n",
    "box1 = prim_alg.find_box()\n",
    "\n",
    "box1.show_tradeoff(annotated=True)\n",
    "plt.show()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "c3780d39-819d-4d73-8be4-7da57896f42e",
   "metadata": {
    "tags": []
   },
   "source": [
    "point = 52\n",
    "box1.inspect(point)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "3fc89567-f7c2-449f-a689-07cfe934c82c",
   "metadata": {
    "tags": []
   },
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Assuming outcomes_rfem is a tuple containing a DataFrame and a dictionary\n",
    "experiments_df, outcomes_dict = rf_em\n",
    "\n",
    "# Extract the policy data\n",
    "policies = experiments_df['policy']\n",
    "\n",
    "# Create a DataFrame from the outcomes dictionary and add the policy column\n",
    "outcomes_df = pd.DataFrame(outcomes_dict)\n",
    "outcomes_df['policy'] = policies.values\n",
    "\n",
    "# Calculate the mean and standard deviation of each outcome for each policy\n",
    "mean_outcomes = outcomes_df.groupby('policy').mean()\n",
    "std_outcomes = outcomes_df.groupby('policy').std()\n",
    "\n",
    "# Plot the mean outcomes against the policies\n",
    "mean_outcomes.plot(kind='bar', figsize=(14, 8))\n",
    "plt.title('Mean Outcomes by Policy')\n",
    "plt.xlabel('Policy')\n",
    "plt.ylabel('Mean Value')\n",
    "plt.legend(title='Outcomes')\n",
    "plt.show()\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "3fc77e0e-66c2-4483-91c0-302302bf78e3",
   "metadata": {
    "tags": []
   },
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Assuming outcomes_rfem is a tuple containing a DataFrame and a dictionary\n",
    "experiments_df, outcomes_dict = rf_em\n",
    "\n",
    "# Extract the policy data\n",
    "policies = experiments_df['policy']\n",
    "\n",
    "# Create a DataFrame from the outcomes dictionary and add the policy column\n",
    "outcomes_df = pd.DataFrame(outcomes_dict)\n",
    "outcomes_df['policy'] = policies.values\n",
    "\n",
    "# Calculate the mean and standard deviation of each outcome for each policy\n",
    "mean_outcomes = outcomes_df.groupby('policy').mean()\n",
    "std_outcomes = outcomes_df.groupby('policy').std()\n",
    "\n",
    "# Plot the mean outcomes for each policy separately\n",
    "for outcome in mean_outcomes.columns:\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    mean_outcomes[outcome].plot(kind='bar')\n",
    "    plt.title(f'Mean {outcome} by Policy')\n",
    "    plt.xlabel('Policy')\n",
    "    plt.ylabel(f'Mean {outcome}')\n",
    "    plt.show()\n",
    "\n",
    "# Plot the standard deviation outcomes for each policy separately\n",
    "for outcome in std_outcomes.columns:\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    std_outcomes[outcome].plot(kind='bar')\n",
    "    plt.title(f'Standard Deviation of {outcome} by Policy')\n",
    "    plt.xlabel('Policy')\n",
    "    plt.ylabel(f'Standard Deviation of {outcome}')\n",
    "    plt.show()\n",
    "\n",
    "# Plot boxplots for each outcome grouped by policy\n",
    "for outcome in outcomes_df.columns[:-1]:  # Exclude the 'policy' column\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.boxplot(x='policy', y=outcome, data=outcomes_df)\n",
    "    plt.title(f'Boxplot of {outcome} by Policy')\n",
    "    plt.xlabel('Policy')\n",
    "    plt.ylabel(outcome)\n",
    "    plt.show()\n",
    "\n",
    "# Plot histograms for each outcome grouped by policy\n",
    "for outcome in outcomes_df.columns[:-1]:  # Exclude the 'policy' column\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    for policy in outcomes_df['policy'].unique():\n",
    "        subset = outcomes_df[outcome][outcomes_df['policy'] == policy]\n",
    "        sns.histplot(subset, kde=True, label=f'Policy\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a308637f-c19d-469b-8fe8-3b205482e45b",
   "metadata": {},
   "source": [],
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
