{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Robustness of founded policies\n",
    "\n",
    "1) Regret\n",
    "2) satisfying\n",
    "3) signal noise_to_ratio"
   ],
   "id": "5bb551deb3a59b84"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-20T12:44:32.001463Z",
     "start_time": "2024-06-20T12:44:16.054379Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Import general python packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Import functions\n",
    "from dike_model_function import DikeNetwork  # @UnresolvedImport\n",
    "from problem_formulation import get_model_for_problem_formulation\n",
    "from problem_formulation import sum_over,time_step_0,time_step_1, time_step_2, time_step_3, time_step_4\n",
    "\n",
    "# Loading in the necessary modules for EMA workbench and functions\n",
    "from ema_workbench import (Model, MultiprocessingEvaluator, Scenario,\n",
    "                           Constraint, ScalarOutcome, TimeSeriesOutcome, ArrayOutcome)\n",
    "from ema_workbench.util import ema_logging\n",
    "from ema_workbench import save_results, load_results\n",
    "from ema_workbench.em_framework.optimization import (EpsilonProgress)\n",
    "from ema_workbench.analysis import parcoords"
   ],
   "id": "7a43d7dfaa1f4f09",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Initializing model",
   "id": "2b4c20eacefaaeb4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-20T12:44:39.413005Z",
     "start_time": "2024-06-20T12:44:34.184979Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "def initialize_model():\n",
    "    ema_logging.log_to_stderr(ema_logging.INFO)\n",
    "    print(\"Initializing model...\")\n",
    "    dike_model, planning_steps = get_model_for_problem_formulation(7)\n",
    "    print(\"Model initialized.\")\n",
    "    return dike_model, planning_steps\n",
    "\n",
    "# Writing a function to create actor specific problem formulations\n",
    "def problem_formulation_actor(problem_formulation_actor, uncertainties, levers):\n",
    "    # Load the model:\n",
    "    function = DikeNetwork()\n",
    "    # workbench model:\n",
    "    model = Model('dikesnet', function=function)\n",
    "    # Outcomes are all costs, thus they have to minimized:\n",
    "    direction = ScalarOutcome.MINIMIZE\n",
    "\n",
    "    model.uncertainties = uncertainties\n",
    "    model.levers = levers\n",
    "\n",
    "    cost_variables = []\n",
    "    cost_variables.extend(\n",
    "    [\n",
    "        f\"{dike}_{e}\"\n",
    "        for e in [\"Expected Annual Damage\", \"Dike Investment Costs\"]\n",
    "        for dike in function.dikelist\n",
    "    ])\n",
    "    cost_variables.extend([f\"RfR Total Costs\"])\n",
    "    cost_variables.extend([f\"Expected Evacuation Costs\"])\n",
    "\n",
    "    if problem_formulation_actor == 6:  # GELDERLAND\n",
    "        model.outcomes.clear()\n",
    "        model.outcomes = [\n",
    "            ScalarOutcome(f'Total_period_Costs_0',\n",
    "                          variable_name=dike_model.outcomes['Total_period_Costs'].variable_name,\n",
    "                          function=time_step_0, kind=direction),\n",
    "            ScalarOutcome(f'Total_period_Costs_1',\n",
    "                          variable_name=dike_model.outcomes['Total_period_Costs'].variable_name,\n",
    "                          function=time_step_1, kind=direction),\n",
    "            ScalarOutcome(f'Total_period_Costs_2',\n",
    "                          variable_name=dike_model.outcomes['Total_period_Costs'].variable_name,\n",
    "                          function=time_step_2, kind=direction),\n",
    "            # ScalarOutcome(f'Total_period_Costs_3',\n",
    "            #               variable_name=dike_model.outcomes['Total_period_Costs'].variable_name,\n",
    "            #               function=time_step_3, kind=direction),\n",
    "            # ScalarOutcome(f'Total_period_Costs_4',\n",
    "            #               variable_name=dike_model.outcomes['Total_period_Costs'].variable_name,\n",
    "            #               function=time_step_4, kind=direction),\n",
    "            ScalarOutcome('Expected Annual Damage A1_', variable_name='A.1_Expected Annual Damage', function=sum_over,\n",
    "                          kind=direction),\n",
    "            ScalarOutcome('Expected Annual Damage A2_', variable_name='A.2_Expected Annual Damage', function=sum_over,\n",
    "                          kind=direction),\n",
    "            ScalarOutcome('Expected Annual Damage A3_', variable_name='A.3_Expected Annual Damage', function=sum_over,\n",
    "                          kind=direction),\n",
    "            ScalarOutcome('Total Costs', variable_name=cost_variables, function=sum_over, kind=direction),\n",
    "            ScalarOutcome(\"Expected Number of Deaths_\", variable_name=\n",
    "            [f\"{dike}_Expected Number of Deaths\" for dike in function.dikelist], function=sum_over, kind=direction)]\n",
    "\n",
    "\n",
    "    elif problem_formulation_actor == 7:  # OVERIJSSEL\n",
    "        model.outcomes.clear()\n",
    "        model.outcomes = [\n",
    "            ScalarOutcome(f'Total_period_Costs_0',\n",
    "                          variable_name=dike_model.outcomes['Total_period_Costs'].variable_name,\n",
    "                          function=time_step_0, kind=direction),\n",
    "            ScalarOutcome(f'Total_period_Costs_1',\n",
    "                          variable_name=dike_model.outcomes['Total_period_Costs'].variable_name,\n",
    "                          function=time_step_1, kind=direction),\n",
    "            ScalarOutcome(f'Total_period_Costs_2',\n",
    "                          variable_name=dike_model.outcomes['Total_period_Costs'].variable_name,\n",
    "                          function=time_step_2, kind=direction),\n",
    "            # ScalarOutcome(f'Total_period_Costs_3',\n",
    "            #               variable_name=dike_model.outcomes['Total_period_Costs'].variable_name,\n",
    "            #               function=time_step_3, kind=direction),\n",
    "            # # ScalarOutcome(f'Total_period_Costs_4',\n",
    "            #               variable_name=dike_model.outcomes['Total_period_Costs'].variable_name,\n",
    "            #               function=time_step_4, kind=direction),\n",
    "            ScalarOutcome('Expected Annual Damage A4_', variable_name='A.4_Expected Annual Damage', function=sum_over,\n",
    "                          kind=direction),\n",
    "            ScalarOutcome('Expected Annual Damage A5_', variable_name='A.5_Expected Annual Damage', function=sum_over,\n",
    "                          kind=direction),\n",
    "            ScalarOutcome('Total Costs', variable_name=cost_variables, function=sum_over, kind=direction),\n",
    "            ScalarOutcome(\"Expected Number of Deaths_\", variable_name=\n",
    "            [f\"{dike}_Expected Number of Deaths\" for dike in function.dikelist], function=sum_over, kind=direction)]\n",
    "\n",
    "    else:\n",
    "        raise TypeError('unknown identifier')\n",
    "    return model\n",
    "\n",
    "### Overijssel\n",
    "if __name__ == '__main__':\n",
    "    dike_model, planning_steps = initialize_model()\n",
    "\n",
    "    uncertainties = dike_model.uncertainties\n",
    "    levers = dike_model.levers\n",
    "    \n",
    "    model = problem_formulation_actor(7, uncertainties, levers)\n",
    "\n",
    "    # Deepcopying the uncertainties and levers\n",
    "    uncertainties = copy.deepcopy(dike_model.uncertainties)\n",
    "    levers = copy.deepcopy(dike_model.levers)\n",
    "\n",
    "    # Running the optimization for Overijssel\n",
    "    function = DikeNetwork()"
   ],
   "id": "e61ce49f7b3e2ffc",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing model...\n",
      "Model initialized.\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Loading in the datasets",
   "id": "284fa151719b118c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-20T12:49:17.802786Z",
     "start_time": "2024-06-20T12:49:17.524572Z"
    }
   },
   "cell_type": "code",
   "source": [
    "experiments, outcomes = load_results( 'Week23_reference_case_2000_6.tar.gz')\n",
    "\n",
    "df_exp = pd.DataFrame.from_dict(experiments)\n",
    "df_out = pd.DataFrame.from_dict(outcomes)"
   ],
   "id": "7cdbe9cf0127d305",
   "outputs": [
    {
     "ename": "ReadError",
     "evalue": "not a gzip file",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mBadGzipFile\u001B[0m                               Traceback (most recent call last)",
      "File \u001B[1;32m~\\anaconda3\\Lib\\tarfile.py:1870\u001B[0m, in \u001B[0;36mTarFile.gzopen\u001B[1;34m(cls, name, mode, fileobj, compresslevel, **kwargs)\u001B[0m\n\u001B[0;32m   1869\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m-> 1870\u001B[0m     t \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mcls\u001B[39m\u001B[38;5;241m.\u001B[39mtaropen(name, mode, fileobj, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1871\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mOSError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\tarfile.py:1847\u001B[0m, in \u001B[0;36mTarFile.taropen\u001B[1;34m(cls, name, mode, fileobj, **kwargs)\u001B[0m\n\u001B[0;32m   1846\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmode must be \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mr\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m, \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124ma\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m, \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mw\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m or \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mx\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m-> 1847\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mcls\u001B[39m(name, mode, fileobj, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\tarfile.py:1707\u001B[0m, in \u001B[0;36mTarFile.__init__\u001B[1;34m(self, name, mode, fileobj, format, tarinfo, dereference, ignore_zeros, encoding, errors, pax_headers, debug, errorlevel, copybufsize)\u001B[0m\n\u001B[0;32m   1706\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfirstmember \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m-> 1707\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfirstmember \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnext()\n\u001B[0;32m   1709\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmode \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124ma\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[0;32m   1710\u001B[0m     \u001B[38;5;66;03m# Move to the end of the archive,\u001B[39;00m\n\u001B[0;32m   1711\u001B[0m     \u001B[38;5;66;03m# before the first empty block.\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\tarfile.py:2624\u001B[0m, in \u001B[0;36mTarFile.next\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   2623\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 2624\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m e\n\u001B[0;32m   2625\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mImportError\u001B[39;00m:\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\tarfile.py:2597\u001B[0m, in \u001B[0;36mTarFile.next\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   2596\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m-> 2597\u001B[0m     tarinfo \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtarinfo\u001B[38;5;241m.\u001B[39mfromtarfile(\u001B[38;5;28mself\u001B[39m)\n\u001B[0;32m   2598\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m EOFHeaderError \u001B[38;5;28;01mas\u001B[39;00m e:\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\tarfile.py:1285\u001B[0m, in \u001B[0;36mTarInfo.fromtarfile\u001B[1;34m(cls, tarfile)\u001B[0m\n\u001B[0;32m   1282\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Return the next TarInfo object from TarFile object\u001B[39;00m\n\u001B[0;32m   1283\u001B[0m \u001B[38;5;124;03m   tarfile.\u001B[39;00m\n\u001B[0;32m   1284\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m-> 1285\u001B[0m buf \u001B[38;5;241m=\u001B[39m tarfile\u001B[38;5;241m.\u001B[39mfileobj\u001B[38;5;241m.\u001B[39mread(BLOCKSIZE)\n\u001B[0;32m   1286\u001B[0m obj \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mcls\u001B[39m\u001B[38;5;241m.\u001B[39mfrombuf(buf, tarfile\u001B[38;5;241m.\u001B[39mencoding, tarfile\u001B[38;5;241m.\u001B[39merrors)\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\gzip.py:301\u001B[0m, in \u001B[0;36mGzipFile.read\u001B[1;34m(self, size)\u001B[0m\n\u001B[0;32m    300\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mOSError\u001B[39;00m(errno\u001B[38;5;241m.\u001B[39mEBADF, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mread() on write-only GzipFile object\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m--> 301\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_buffer\u001B[38;5;241m.\u001B[39mread(size)\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\_compression.py:68\u001B[0m, in \u001B[0;36mDecompressReader.readinto\u001B[1;34m(self, b)\u001B[0m\n\u001B[0;32m     67\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mmemoryview\u001B[39m(b) \u001B[38;5;28;01mas\u001B[39;00m view, view\u001B[38;5;241m.\u001B[39mcast(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mB\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;28;01mas\u001B[39;00m byte_view:\n\u001B[1;32m---> 68\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mread(\u001B[38;5;28mlen\u001B[39m(byte_view))\n\u001B[0;32m     69\u001B[0m     byte_view[:\u001B[38;5;28mlen\u001B[39m(data)] \u001B[38;5;241m=\u001B[39m data\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\gzip.py:499\u001B[0m, in \u001B[0;36m_GzipReader.read\u001B[1;34m(self, size)\u001B[0m\n\u001B[0;32m    498\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_init_read()\n\u001B[1;32m--> 499\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_read_gzip_header():\n\u001B[0;32m    500\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_size \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pos\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\gzip.py:468\u001B[0m, in \u001B[0;36m_GzipReader._read_gzip_header\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    467\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_read_gzip_header\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m--> 468\u001B[0m     last_mtime \u001B[38;5;241m=\u001B[39m _read_gzip_header(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_fp)\n\u001B[0;32m    469\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m last_mtime \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\gzip.py:428\u001B[0m, in \u001B[0;36m_read_gzip_header\u001B[1;34m(fp)\u001B[0m\n\u001B[0;32m    427\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m magic \u001B[38;5;241m!=\u001B[39m \u001B[38;5;124mb\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;130;01m\\037\u001B[39;00m\u001B[38;5;130;01m\\213\u001B[39;00m\u001B[38;5;124m'\u001B[39m:\n\u001B[1;32m--> 428\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m BadGzipFile(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mNot a gzipped file (\u001B[39m\u001B[38;5;132;01m%r\u001B[39;00m\u001B[38;5;124m)\u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;241m%\u001B[39m magic)\n\u001B[0;32m    430\u001B[0m (method, flag, last_mtime) \u001B[38;5;241m=\u001B[39m struct\u001B[38;5;241m.\u001B[39munpack(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m<BBIxx\u001B[39m\u001B[38;5;124m\"\u001B[39m, _read_exact(fp, \u001B[38;5;241m8\u001B[39m))\n",
      "\u001B[1;31mBadGzipFile\u001B[0m: Not a gzipped file (b'\\x1f\\xef')",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[1;31mReadError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[5], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m experiments, outcomes \u001B[38;5;241m=\u001B[39m load_results( \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mWeek23_reference_case_2000_6.tar.gz\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m      3\u001B[0m df_exp \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mDataFrame\u001B[38;5;241m.\u001B[39mfrom_dict(experiments)\n\u001B[0;32m      4\u001B[0m df_out \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mDataFrame\u001B[38;5;241m.\u001B[39mfrom_dict(outcomes)\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\ema_workbench\\util\\utilities.py:46\u001B[0m, in \u001B[0;36mload_results\u001B[1;34m(file_name)\u001B[0m\n\u001B[0;32m     42\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mem_framework\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01moutcomes\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m AbstractOutcome, register\n\u001B[0;32m     44\u001B[0m file_name \u001B[38;5;241m=\u001B[39m os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mabspath(file_name)\n\u001B[1;32m---> 46\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m tarfile\u001B[38;5;241m.\u001B[39mopen(file_name, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mr:gz\u001B[39m\u001B[38;5;124m\"\u001B[39m, encoding\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mUTF8\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;28;01mas\u001B[39;00m archive:\n\u001B[0;32m     47\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m     48\u001B[0m         f \u001B[38;5;241m=\u001B[39m archive\u001B[38;5;241m.\u001B[39mextractfile(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmetadata.json\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\tarfile.py:1817\u001B[0m, in \u001B[0;36mTarFile.open\u001B[1;34m(cls, name, mode, fileobj, bufsize, **kwargs)\u001B[0m\n\u001B[0;32m   1815\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   1816\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m CompressionError(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124munknown compression type \u001B[39m\u001B[38;5;132;01m%r\u001B[39;00m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m%\u001B[39m comptype)\n\u001B[1;32m-> 1817\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m func(name, filemode, fileobj, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1819\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m|\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01min\u001B[39;00m mode:\n\u001B[0;32m   1820\u001B[0m     filemode, comptype \u001B[38;5;241m=\u001B[39m mode\u001B[38;5;241m.\u001B[39msplit(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m|\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;241m1\u001B[39m)\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\tarfile.py:1874\u001B[0m, in \u001B[0;36mTarFile.gzopen\u001B[1;34m(cls, name, mode, fileobj, compresslevel, **kwargs)\u001B[0m\n\u001B[0;32m   1872\u001B[0m     fileobj\u001B[38;5;241m.\u001B[39mclose()\n\u001B[0;32m   1873\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m mode \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mr\u001B[39m\u001B[38;5;124m'\u001B[39m:\n\u001B[1;32m-> 1874\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m ReadError(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnot a gzip file\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01me\u001B[39;00m\n\u001B[0;32m   1875\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m\n\u001B[0;32m   1876\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m:\n",
      "\u001B[1;31mReadError\u001B[0m: not a gzip file"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 1. Regret",
   "id": "d28cc0953f36366b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-20T12:39:12.976135Z",
     "start_time": "2024-06-20T12:39:12.976135Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "d1f1bc0afc429630",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 2. Satisfying",
   "id": "1070a1ffaef5d5de"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "3872ce5f6ac83dd3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 3. Signal to Noise",
   "id": "53738ab5fee56ac"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-20T12:38:37.429504Z",
     "start_time": "2024-06-20T12:38:37.030570Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def s_to_n(worst_data, direction):\n",
    "    mean = np.mean(worst_data)\n",
    "    std = np.std(worst_data)\n",
    "    \n",
    "    if direction==ScalarOutcome.MAXIMIZE:\n",
    "        return mean/std\n",
    "    else:\n",
    "        return mean*std"
   ],
   "id": "5012090703b7dfdc",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-20T12:38:46.487268Z",
     "start_time": "2024-06-20T12:38:45.490945Z"
    }
   },
   "cell_type": "code",
   "source": [
    "overall_scores = {}\n",
    "for policy in np.unique(experiments['policy']):\n",
    "    scores = {}\n",
    "    \n",
    "    logical = experiments['policy']==policy\n",
    "    \n",
    "    for outcome in model.outcomes:\n",
    "        value  = outcomes[outcome.name][logical]\n",
    "        sn_ratio = s_to_n(value, outcome.kind)\n",
    "        scores[outcome.name] = sn_ratio\n",
    "    overall_scores[policy] = scores\n",
    "scores = pd.DataFrame.from_dict(overall_scores).T\n",
    "scores"
   ],
   "id": "6b85ac5a0ee4b108",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'results_reevaluation_gelderland_worstcase' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[3], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m experiments, outcomes \u001B[38;5;241m=\u001B[39m results_reevaluation_gelderland_worstcase\n\u001B[0;32m      3\u001B[0m overall_scores \u001B[38;5;241m=\u001B[39m {}\n\u001B[0;32m      4\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m policy \u001B[38;5;129;01min\u001B[39;00m np\u001B[38;5;241m.\u001B[39munique(experiments[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mpolicy\u001B[39m\u001B[38;5;124m'\u001B[39m]):\n",
      "\u001B[1;31mNameError\u001B[0m: name 'results_reevaluation_gelderland_worstcase' is not defined"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "f4bbeaf8ca6bd4a7"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
