{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Convergence Metrics\n",
    "\n",
    "- (1) Import and loading the model \n",
    "- (2) Convergence Metrics Overijssel\n",
    "- (3) Convergence Metrics Gelderland"
   ],
   "id": "f5dfb6bcbb9caa93"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### (1) Import and loading the model",
   "id": "bf96aaa1d39ef9e1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-21T09:46:16.331953Z",
     "start_time": "2024-06-21T09:45:52.100403Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Import general python packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "# Import functions\n",
    "from dike_model_function import DikeNetwork  # @UnresolvedImport\n",
    "from problem_formulation import get_model_for_problem_formulation\n",
    "from problem_formulation import sum_over,time_step_0,time_step_1\n",
    "\n",
    "# Loading in the necessary modules for EMA workbench and functions\n",
    "from ema_workbench import (Model, Scenario, Constraint, ScalarOutcome)\n",
    "from ema_workbench.util import ema_logging\n",
    "from ema_workbench.em_framework.optimization import ArchiveLogger, EpsilonProgress\n",
    "from ema_workbench import save_results, load_results\n",
    "from ema_workbench.analysis import feature_scoring\n",
    "from ema_workbench.analysis import parcoords"
   ],
   "id": "467287c940f399c7",
   "execution_count": 1,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-21T09:46:19.768938Z",
     "start_time": "2024-06-21T09:46:16.334926Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "def initialize_model():\n",
    "    ema_logging.log_to_stderr(ema_logging.INFO)\n",
    "    print(\"Initializing model...\")\n",
    "    dike_model, planning_steps = get_model_for_problem_formulation(7)\n",
    "    print(\"Model initialized.\")\n",
    "    return dike_model, planning_steps\n",
    "\n",
    "# Writing a function to create actor specific problem formulations\n",
    "def problem_formulation_actor(problem_formulation_actor, uncertainties, levers):\n",
    "    # Load the model:\n",
    "    function = DikeNetwork()\n",
    "    # workbench model:\n",
    "    model = Model('dikesnet', function=function)\n",
    "    # Outcomes are all costs, thus they have to minimized:\n",
    "    direction = ScalarOutcome.MINIMIZE\n",
    "\n",
    "    model.uncertainties = uncertainties\n",
    "    model.levers = levers\n",
    "\n",
    "    cost_variables = []\n",
    "    cost_variables.extend(\n",
    "    [\n",
    "        f\"{dike}_{e}\"\n",
    "        for e in [\"Expected Annual Damage\", \"Dike Investment Costs\"]\n",
    "        for dike in function.dikelist\n",
    "    ])\n",
    "    cost_variables.extend([f\"RfR Total Costs\"])\n",
    "    cost_variables.extend([f\"Expected Evacuation Costs\"])\n",
    "\n",
    "    if problem_formulation_actor == 6:  # GELDERLAND\n",
    "        model.outcomes.clear()\n",
    "        model.outcomes = [\n",
    "            ScalarOutcome(f'Total_period_Costs_0',\n",
    "                          variable_name=dike_model.outcomes['Total_period_Costs'].variable_name,\n",
    "                          function=time_step_0, kind=direction),\n",
    "            ScalarOutcome(f'Total_period_Costs_1',\n",
    "                          variable_name=dike_model.outcomes['Total_period_Costs'].variable_name,\n",
    "                          function=time_step_1, kind=direction),\n",
    "            # ScalarOutcome(f'Total_period_Costs_2',\n",
    "            #               variable_name=dike_model.outcomes['Total_period_Costs'].variable_name,\n",
    "            #               function=time_step_2, kind=direction),\n",
    "            # ScalarOutcome(f'Total_period_Costs_3',\n",
    "            #               variable_name=dike_model.outcomes['Total_period_Costs'].variable_name,\n",
    "            #               function=time_step_3, kind=direction),\n",
    "            # ScalarOutcome(f'Total_period_Costs_4',\n",
    "            #               variable_name=dike_model.outcomes['Total_period_Costs'].variable_name,\n",
    "            #               function=time_step_4, kind=direction),\n",
    "            ScalarOutcome('Expected Annual Damage A1_', variable_name='A.1_Expected Annual Damage', function=sum_over,\n",
    "                          kind=direction),\n",
    "            ScalarOutcome('Expected Annual Damage A2_', variable_name='A.2_Expected Annual Damage', function=sum_over,\n",
    "                          kind=direction),\n",
    "            ScalarOutcome('Expected Annual Damage A3_', variable_name='A.3_Expected Annual Damage', function=sum_over,\n",
    "                          kind=direction),\n",
    "            ScalarOutcome('Total Costs', variable_name=cost_variables, function=sum_over, kind=direction),\n",
    "            ScalarOutcome(\"Expected Number of Deaths_\", variable_name=\n",
    "            [f\"{dike}_Expected Number of Deaths\" for dike in function.dikelist], function=sum_over, kind=direction)]\n",
    "\n",
    "\n",
    "    elif problem_formulation_actor == 7:  # OVERIJSSEL\n",
    "        model.outcomes.clear()\n",
    "        model.outcomes = [\n",
    "            ScalarOutcome(f'Total_period_Costs_0',\n",
    "                          variable_name=dike_model.outcomes['Total_period_Costs'].variable_name,\n",
    "                          function=time_step_0, kind=direction),\n",
    "            ScalarOutcome(f'Total_period_Costs_1',\n",
    "                          variable_name=dike_model.outcomes['Total_period_Costs'].variable_name,\n",
    "                          function=time_step_1, kind=direction),\n",
    "            # ScalarOutcome(f'Total_period_Costs_2',\n",
    "            #               variable_name=dike_model.outcomes['Total_period_Costs'].variable_name,\n",
    "            #               function=time_step_2, kind=direction),\n",
    "            # # ScalarOutcome(f'Total_period_Costs_3',\n",
    "            #               variable_name=dike_model.outcomes['Total_period_Costs'].variable_name,\n",
    "            #               function=time_step_3, kind=direction),\n",
    "            # # ScalarOutcome(f'Total_period_Costs_4',\n",
    "            #               variable_name=dike_model.outcomes['Total_period_Costs'].variable_name,\n",
    "            #               function=time_step_4, kind=direction),\n",
    "            ScalarOutcome('Expected Annual Damage A4_', variable_name='A.4_Expected Annual Damage', function=sum_over,\n",
    "                          kind=direction),\n",
    "            ScalarOutcome('Expected Annual Damage A5_', variable_name='A.5_Expected Annual Damage', function=sum_over,\n",
    "                          kind=direction),\n",
    "            ScalarOutcome('Total Costs', variable_name=cost_variables, function=sum_over, kind=direction),\n",
    "            ScalarOutcome(\"Expected Number of Deaths_\", variable_name=\n",
    "            [f\"{dike}_Expected Number of Deaths\" for dike in function.dikelist], function=sum_over, kind=direction)]\n",
    "\n",
    "    else:\n",
    "        raise TypeError('unknown identifier')\n",
    "    return model\n",
    "\n",
    "### Overijssel\n",
    "if __name__ == '__main__':\n",
    "    dike_model, planning_steps = initialize_model()\n",
    "\n",
    "    uncertainties = dike_model.uncertainties\n",
    "    levers = dike_model.levers\n",
    "    \n",
    "    model = problem_formulation_actor(6, uncertainties, levers)\n",
    "\n",
    "    # Deepcopying the uncertainties and levers\n",
    "    uncertainties = copy.deepcopy(dike_model.uncertainties)\n",
    "    levers = copy.deepcopy(dike_model.levers)\n",
    "\n",
    "    # Running the optimization for Overijssel\n",
    "    function = DikeNetwork()"
   ],
   "id": "a79b0f9414502a0a",
   "execution_count": 2,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### (1) Convergence Metrics Overijssel",
   "id": "3010a122e238ec4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-21T09:46:19.928195Z",
     "start_time": "2024-06-21T09:46:19.773931Z"
    }
   },
   "cell_type": "code",
   "source": "convergencee = pd.read_csv('Overijssel MORDM_epsilon.csv')",
   "id": "b489a49555ece5b8",
   "execution_count": 3,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-21T09:46:22.593530Z",
     "start_time": "2024-06-21T09:46:19.937177Z"
    }
   },
   "cell_type": "code",
   "source": [
    "plt.plot(convergencee.nfe, convergencee.epsilon_progress)\n",
    "\n",
    "plt.ylabel('$\\epsilon$-progress')\n",
    "plt.xlabel('number of function evaluations')\n",
    "plt.title('Convergence performance')\n",
    "plt.show()\n",
    "#plt.savefig('./figures/Convergence Performance Gelderland.png')"
   ],
   "id": "7f18139b10a14954",
   "execution_count": 4,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-21T14:18:19.613381Z",
     "start_time": "2024-06-21T14:18:19.513647Z"
    }
   },
   "cell_type": "code",
   "source": [
    "metrics_by_seed = pd.read_csv('./Outcomes/metrics_seed_0_archive_0.csv')\n",
    "metrics_by_seed"
   ],
   "id": "340eb504ec49c84",
   "execution_count": 9,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-21T14:20:18.106301Z",
     "start_time": "2024-06-21T14:20:14.779020Z"
    }
   },
   "cell_type": "code",
   "source": [
    "sns.set_style(\"white\")\n",
    "fig, axes = plt.subplots(nrows=6, figsize=(8, 12), sharex=True)\n",
    "\n",
    "ax1, ax2, ax3, ax4, ax5, ax6 = axes\n",
    "convergences = pd.read_csv('./Outcomes/Overijssel Multi MORDM_Epsilon.csv')\n",
    "for metrics, convergence in zip(metrics_by_seed, convergences):\n",
    "    #print(metrics.nfe)\n",
    "    ax1.plot(metrics['nfe'], metrics.hypervolume)\n",
    "    ax1.set_ylabel(\"hypervolume\")\n",
    "\n",
    "#     ax2.plot(convergence.nfe, convergence.epsilon_progress)\n",
    "#     ax2.set_ylabel(\"$\\epsilon$ progress\")\n",
    "# \n",
    "#     ax3.plot(metrics.nfe, metrics.generational_distance)\n",
    "#     ax3.set_ylabel(\"generational distance\")\n",
    "# \n",
    "#     ax4.plot(metrics.nfe, metrics.epsilon_indicator)\n",
    "#     ax4.set_ylabel(\"epsilon indicator\")\n",
    "# \n",
    "#     ax5.plot(metrics.nfe, metrics.inverted_gd)\n",
    "#     ax5.set_ylabel(\"inverted generational\\ndistance\")\n",
    "# \n",
    "#     ax6.plot(metrics.nfe, metrics.spacing)\n",
    "#     ax6.set_ylabel(\"spacing\")\n",
    "# \n",
    "# ax6.set_xlabel(\"nfe\")\n",
    "\n",
    "\n",
    "# sns.despine(fig)\n",
    "\n",
    "# plt.show()"
   ],
   "id": "86e85d11e480e3d3",
   "execution_count": 15,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### (2) Convergence Metrics Gelderland",
   "id": "7a3cd44f4bdb8fa0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-20T19:57:36.123710Z",
     "start_time": "2024-06-20T19:57:36.061391Z"
    }
   },
   "cell_type": "code",
   "source": "convergencee = pd.read_csv('Gelderland_Multi_MORDM_epsilon.csv')",
   "id": "4265ffeb43e848e7",
   "execution_count": 3,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-20T19:57:39.348699Z",
     "start_time": "2024-06-20T19:57:36.673758Z"
    }
   },
   "cell_type": "code",
   "source": [
    "plt.plot(convergencee.nfe, convergencee.epsilon_progress)\n",
    "\n",
    "plt.ylabel('$\\epsilon$-progress')\n",
    "plt.xlabel('number of function evaluations')\n",
    "plt.title('Convergence performance')\n",
    "plt.show()\n",
    "#plt.savefig('./figures/Convergence Performance Gelderland.png')"
   ],
   "id": "f54e654f9a16c010",
   "execution_count": 4,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-20T20:42:12.123970Z",
     "start_time": "2024-06-20T20:42:12.069130Z"
    }
   },
   "cell_type": "code",
   "source": [
    "all_archives = []\n",
    "\n",
    "for i in range(2):\n",
    "    archives = ArchiveLogger.load_archives(f\"./archives/{i}.tar.gz\")\n",
    "    all_archives.append(archives)"
   ],
   "id": "6968a570146a462b",
   "execution_count": 11,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-20T20:49:09.950382Z",
     "start_time": "2024-06-20T20:49:08.508936Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from ema_workbench import (\n",
    "    HypervolumeMetric,\n",
    "    GenerationalDistanceMetric,\n",
    "    EpsilonIndicatorMetric,\n",
    "    InvertedGenerationalDistanceMetric,\n",
    "    SpacingMetric\n",
    ")\n",
    "from ema_workbench.em_framework.optimization import to_problem\n",
    "from ema_workbench.em_framework.optimization import epsilon_nondominated\n",
    "\n",
    "problem = to_problem(model, searchover=\"levers\")\n",
    "outcomes = pd.read_csv('Gelderland_Multi_MORDM_outcomes.csv')\n",
    "results = list(outcomes.loc[:, [o.name for o in model.outcomes]])\n",
    "reference_set = epsilon_nondominated(results, [1] * len(model.outcomes), problem)\n",
    "\n",
    "hv = HypervolumeMetric(reference_set, problem)\n",
    "gd = GenerationalDistanceMetric(reference_set, problem, d=1)\n",
    "ei = EpsilonIndicatorMetric(reference_set, problem)\n",
    "ig = InvertedGenerationalDistanceMetric(reference_set, problem, d=1)\n",
    "sm = SpacingMetric(problem)\n",
    "\n",
    "\n",
    "metrics_by_seed = []\n",
    "for archives in all_archives:\n",
    "    metrics = []\n",
    "    for nfe, archive in archives.items():\n",
    "        scores = {\n",
    "            \"generational_distance\": gd.calculate(archive),\n",
    "            \"hypervolume\": hv.calculate(archive),\n",
    "            \"epsilon_indicator\": ei.calculate(archive),\n",
    "            \"inverted_gd\": ig.calculate(archive),\n",
    "            \"spacing\": sm.calculate(archive),\n",
    "            \"nfe\": int(nfe),\n",
    "        }\n",
    "        metrics.append(scores)\n",
    "    metrics = pd.DataFrame.from_dict(metrics)\n",
    "\n",
    "    # sort metrics by number of function evaluations\n",
    "    metrics.sort_values(by=\"nfe\", inplace=True)\n",
    "    metrics_by_seed.append(metrics)"
   ],
   "id": "75043220df1590ea",
   "execution_count": 22,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "execution_count": null,
   "source": "",
   "id": "26928a598657ff96",
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
