{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# MORDM",
   "id": "b9f48a3d3a0555c4"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-06-10T17:21:46.833405Z",
     "start_time": "2024-06-10T17:21:46.665370Z"
    }
   },
   "source": [
    "# Import general python packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import copy\n",
    "\n",
    "# Import functions\n",
    "from dike_model_function import DikeNetwork  # @UnresolvedImport\n",
    "from problem_formulation import get_model_for_problem_formulation\n",
    "from problem_formulation import sum_over, sum_over_time\n",
    "\n",
    "# Loading in the necessary modules for EMA workbench and functions\n",
    "from ema_workbench import (Model, MultiprocessingEvaluator, Scenario,\n",
    "                           Constraint, ScalarOutcome)\n",
    "from ema_workbench.util import ema_logging\n",
    "from ema_workbench import save_results, load_results\n",
    "from ema_workbench.em_framework.optimization import (EpsilonProgress)"
   ],
   "execution_count": 6,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T17:21:49.069922Z",
     "start_time": "2024-06-10T17:21:46.846371Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Loading in all the 17 objectives via predefined problem formulation 3\n",
    "if __name__ == '__main__':\n",
    "    ema_logging.log_to_stderr(ema_logging.INFO)\n",
    "    dike_model, planning_steps = get_model_for_problem_formulation(6)"
   ],
   "id": "24f4013befc6d19a",
   "execution_count": 7,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T17:21:50.368403Z",
     "start_time": "2024-06-10T17:21:50.359134Z"
    }
   },
   "cell_type": "code",
   "source": "print(planning_steps)",
   "id": "53f3bf3ef5cb4b02",
   "execution_count": 8,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "b6b301ac7683c5ee",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-06-10T16:47:32.240283Z",
     "start_time": "2024-06-10T16:47:32.232967Z"
    }
   },
   "source": [
    "# Replicate the objectives\n",
    "for outcome in dike_model.outcomes:\n",
    "    print(repr(outcome))\n",
    "    "
   ],
   "execution_count": 5,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "277a36e0-e5d8-4d34-9f17-3118ef97a1e3",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-06-10T19:37:38.850477Z",
     "start_time": "2024-06-10T19:37:38.807252Z"
    }
   },
   "source": [
    "# Writing a function to create actor specific problem formulations\n",
    "def problem_formulation_actor(problem_formulation_actor):\n",
    "   \n",
    "    # Load the model:\n",
    "    function = DikeNetwork()\n",
    "    # workbench model:\n",
    "    model = Model('dikesnet', function=function)\n",
    "    # Outcomes are all costs, thus they have to minimized:\n",
    "    direction = ScalarOutcome.MINIMIZE\n",
    "    \n",
    "    model.uncertainties = uncertainties\n",
    "    model.levers = levers\n",
    "    \n",
    "    cost_variables = []\n",
    "    cost_variables.extend(\n",
    "    [\n",
    "        f\"{dike}_{e}\"\n",
    "        for e in [\"Expected Annual Damage\", \"Dike Investment Costs\"]\n",
    "        for dike in function.dikelist\n",
    "    ])\n",
    "    cost_variables.extend([f\"RfR Total Costs\"])\n",
    "    cost_variables.extend([f\"Expected Evacuation Costs\"])\n",
    "\n",
    "\n",
    "    if problem_formulation_actor == 4: #RWS\n",
    "        model.outcomes.clear()\n",
    "        model.outcomes = [\n",
    "            ScalarOutcome('Expected Annual Damage',\n",
    "                            variable_name=['{}_Expected Annual Damage'.format(dike)\n",
    "                                                for dike in function.dikelist],\n",
    "                            function=sum_over, kind=direction),\n",
    "\n",
    "            ScalarOutcome('Total Investment Costs',\n",
    "                            variable_name=['{}_Dike Investment Costs'.format(dike)\n",
    "                                                for dike in function.dikelist] + ['RfR Total Costs'\n",
    "                                                                                ] + ['Expected Evacuation Costs'],\n",
    "                            function=sum_over, kind=direction),\n",
    "\n",
    "            ScalarOutcome('Expected Number of Deaths',\n",
    "                            variable_name=['{}_Expected Number of Deaths'.format(dike)\n",
    "                                                for dike in function.dikelist],\n",
    "                            function=sum_over, kind=direction)] \n",
    "    \n",
    "    elif problem_formulation_actor == 5: # GELDERLAND\n",
    "        model.outcomes.clear()\n",
    "        model.outcomes = [\n",
    "            ScalarOutcome('Expected Annual Damage A1-4',\n",
    "                            variable_name=['A.1_Expected Annual Damage' ,'A.2_Expected Annual Damage', 'A.3_Expected Annual Damage', 'A.4_Expected Annual Damage'], function=sum_over, kind=direction),\n",
    "\n",
    "            ScalarOutcome('Investment Costs A1-4',\n",
    "                            variable_name=['A.1_Dike Investment Costs', 'A.2_Dike Investment Costs', 'A.3_Dike Investment Costs', 'A.4_Dike Investment Costs'], function=sum_over, kind=direction),\n",
    "\n",
    "            ScalarOutcome('Expected Number of Deaths in A1-4',\n",
    "                            variable_name=['A.1_Expected Number of Deaths', 'A.2_Expected Number of Deaths', 'A.3_Expected Number of Deaths', 'A.4_Expected Number of Deaths'], function=sum_over, kind=direction)]\n",
    "    \n",
    "    elif problem_formulation_actor == 6: # OVERIJSSEL\n",
    "        model.outcomes.clear()\n",
    "        model.outcomes = [\n",
    "            ScalarOutcome('Expected Annual Damage A4', variable_name='A.4_Expected Annual Damage', function = sum_over, kind=direction),\n",
    "            ScalarOutcome('Expected Annual Damage A5', variable_name='A.5_Expected Annual Damage', function = sum_over, kind=direction),            \n",
    "            ScalarOutcome('Expected Number of Deaths in A4', variable_name='A.4_Expected Number of Deaths',function = sum_over, kind=direction),\n",
    "            ScalarOutcome('Expected Number of Deaths in A5', variable_name='A.5_Expected Number of Deaths',function = sum_over, kind=direction),\n",
    "            ScalarOutcome('Total Costs', variable_name=cost_variables, function = sum_over, kind=direction),\n",
    "            ScalarOutcome('Aggregated Expected Number of Deaths A1-A3', variable_name =\n",
    "            ['A.1_Expected Number of Deaths', 'A.2_Expected Number of Deaths', \n",
    "             'A.3_Expected Number of Deaths'], function = sum_over, kind=direction)]\n",
    "    \n",
    "    else:\n",
    "        raise TypeError('unknown identifier')\n",
    "    return model"
   ],
   "execution_count": 98,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "1bfd2ae6-5f22-4449-a17a-d82042a02813",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-06-10T19:37:39.972931Z",
     "start_time": "2024-06-10T19:37:39.874100Z"
    }
   },
   "source": [
    "# Replicate the uncertainties\n",
    "uncertainties = dike_model.uncertainties\n",
    "uncertainties = copy.deepcopy(dike_model.uncertainties)"
   ],
   "execution_count": 99,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "d2c96536-35ba-4172-b925-62abbc885eaa",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-06-10T19:37:40.450232Z",
     "start_time": "2024-06-10T19:37:40.337014Z"
    }
   },
   "source": [
    "levers = dike_model.levers \n",
    "levers = copy.deepcopy(dike_model.levers)"
   ],
   "execution_count": 100,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "a91639a2468a9adc",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-06-10T19:37:43.870223Z",
     "start_time": "2024-06-10T19:37:41.278657Z"
    }
   },
   "source": [
    "model = problem_formulation_actor(6)\n",
    "for outcome in model.outcomes:\n",
    "    print(repr((outcome)))"
   ],
   "execution_count": 101,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "adac028e40648723",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "id": "8dc875ff-0e3b-4e4c-81bf-050b8ee99b44",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-06-10T19:37:51.175440Z",
     "start_time": "2024-06-10T19:37:51.167860Z"
    }
   },
   "source": [
    "print(len(model.outcomes))"
   ],
   "execution_count": 102,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "c33cfae19ab29a95",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-06-10T19:37:51.573340Z",
     "start_time": "2024-06-10T19:37:51.563805Z"
    }
   },
   "source": [
    "for outcome in dike_model.outcomes:\n",
    "    print(repr(outcome))"
   ],
   "execution_count": 103,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "3b5e260bcd0a1bc3",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-06-10T19:37:51.871318Z",
     "start_time": "2024-06-10T19:37:51.854197Z"
    }
   },
   "source": [
    "reference_values = {\n",
    "    \"Bmax\": 175,\n",
    "    \"Brate\": 1.5,\n",
    "    \"pfail\": 0.5,\n",
    "    \"ID flood wave shape\": 4,\n",
    "    \"planning steps\": 2,\n",
    "}\n",
    "reference_values.update({f\"discount rate {n}\": 3.5 for n in planning_steps})\n",
    "refcase_scen = {}\n",
    "\n",
    "for key in dike_model.uncertainties:\n",
    "    name_split = key.name.split('_')\n",
    "    if len(name_split) == 1:\n",
    "\n",
    "        refcase_scen.update({key.name: reference_values[key.name]})\n",
    "    else:\n",
    "        refcase_scen.update({key.name: reference_values[name_split[1]]})\n",
    "            \n",
    "ref_scenario = Scenario('reference', **refcase_scen)"
   ],
   "execution_count": 104,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "51aeba8593a9ed87",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-06-10T19:39:41.784886Z",
     "start_time": "2024-06-10T19:37:52.190025Z"
    }
   },
   "source": [
    "convergence_metrics = {EpsilonProgress()}\n",
    "constraint = [Constraint(\"Total Costs\", outcome_names=\"Total Costs\", function=lambda x: max(0, x - 7700000000))]\n",
    "\n",
    "with MultiprocessingEvaluator(model,n_processes=-1) as evaluator:\n",
    "   results2 = evaluator.optimize(nfe=5, searchover='levers',\n",
    "                                 convergence=convergence_metrics,\n",
    "                                 epsilons=[1]*len(model.outcomes), reference=ref_scenario,\n",
    "                                 constraints=constraint)\n",
    "\n",
    "save_results(results2, 'Experiments/Week23_MORDM_Reference_1000_PD6.tar.gz')\n"
   ],
   "execution_count": 105,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "27ba29de-d899-4ebf-8874-02558697fab7",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-06-10T19:40:14.569304Z",
     "start_time": "2024-06-10T19:40:14.562126Z"
    }
   },
   "source": "y,t = results2",
   "execution_count": 106,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T19:40:16.006897Z",
     "start_time": "2024-06-10T19:40:15.971981Z"
    }
   },
   "cell_type": "code",
   "source": "y",
   "id": "9dc0e263c5b34ee3",
   "execution_count": 107,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "b8152c46-e1d4-4eac-84be-cb06bdeb7e22",
   "metadata": {},
   "source": [
    "### Worst Case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a02d93cb-e5c4-4858-a172-1262f4a5eea3",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Worst case specification\n",
    "worstcase_values ={\n",
    "    \"Bmax\": 175,\n",
    "    \"Brate\": 1.5,\n",
    "    \"pfail\": 0.9,\n",
    "    \"ID flood wave shape\": 4,\n",
    "    \"planning steps\": 2,\n",
    "}\n",
    "worstcase_values.update({f\"discount rate {n}\": 3.5 for n in planning_steps})\n",
    "\n",
    "worstcase_scen = {}\n",
    "\n",
    "for key in dike_model.uncertainties:\n",
    "    name_split = key.name.split('_')\n",
    "    if len(name_split) == 1:\n",
    "\n",
    "        worstcase_scen.update({key.name: worstcase_values[key.name]})\n",
    "    else:\n",
    "        worstcase_scen.update({key.name: worstcase_values[name_split[1]]})\n",
    "            \n",
    "worst_scenario = Scenario('reference', **worstcase_scen)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3eee8846-13bc-45bf-8f70-0afd4d6a12db",
   "metadata": {
    "tags": []
   },
   "source": [
    "#convergence_metrics = {EpsilonProgress()}\n",
    "\n",
    "#with MultiprocessingEvaluator(model,n_processes=-1) as evaluator:\n",
    "  #  results3 = evaluator.optimize(nfe=4000, searchover='levers',\n",
    "     #                            convergence=convergence_metrics,\n",
    "      #                           epsilons=[0.01]*len(model.outcomes), reference=worst_scenario)\n",
    "\n",
    "#save_results(results2, 'Experiments/Week23_MORDM_Reference_1000_PD6.tar.gz')\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9392a969-675b-4798-aaae-2c20e9dabdf8",
   "metadata": {
    "tags": []
   },
   "source": [
    "worst_case.to_csv('MODRM_WC.csv')"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7ac27e4f-3a71-4f33-aba7-bfe8c980bf6b",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Selecting the policies that are proposed as solutions for further robustness tests\n",
    "from ema_workbench import Policy\n",
    "\n",
    "worstcase_policies_to_evaluate = []\n",
    "\n",
    "for i, policy in import_worst_case.iterrows():\n",
    "    worstcase_policies_to_evaluate.append(Policy(str(i), **policy.to_dict()))"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3065333a-f7f9-4489-8910-65ce256bec4a",
   "metadata": {
    "tags": []
   },
   "source": [
    "n_scenarios = 2000\n",
    "#with MultiprocessingEvaluator(model) as evaluator:\n",
    " #   worst_results = evaluator.perform_experiments(n_scenarios,\n",
    "  #                                          worstcase_policies_to_evaluate)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "238143e8-e9fe-4eb2-a9f4-6c6352a31829",
   "metadata": {
    "tags": []
   },
   "source": [
    "save_results(worst_results, 'Week23_worst_case_2000_4.tar.gz')"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "dccaaf26-6045-404a-bcf5-2de52622cca5",
   "metadata": {},
   "source": "### Reference case"
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "79f610a9-0759-4267-988f-6b6efcd7f219",
   "metadata": {
    "tags": []
   },
   "source": [
    "reference_case_re = pd.read_csv('MODRM_DF.csv')"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cc27b2e1-3694-4e30-8a98-f5be13968a7b",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Selecting the policies that are proposed as solutions for further robustness tests\n",
    "from ema_workbench import Policy\n",
    "\n",
    "refercase_policies_to_evaluate = []\n",
    "\n",
    "for i, policy in reference_case_re.iterrows():\n",
    "    refercase_policies_to_evaluate.append(Policy(str(i), **policy.to_dict()))"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2c5d3fdb-a091-40c8-9fb1-57027005e6e6",
   "metadata": {
    "tags": []
   },
   "source": [
    "n_scenarios = 2000\n",
    "with MultiprocessingEvaluator(model) as evaluator:\n",
    "    reference_policies_results = evaluator.perform_experiments(n_scenarios,\n",
    "                                            refercase_policies_to_evaluate)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fd8b8755-6ff4-4cfc-bb55-b39b518f2efe",
   "metadata": {
    "tags": []
   },
   "source": [
    "save_results(reference_policies_results, 'Week23_reference_case_2000_6.tar.gz')"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19e77fe7-4e5d-45be-b719-844a5ca4c3eb",
   "metadata": {},
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "c71d4857-f0d9-4d15-b528-0aabc7fe0bf8",
   "metadata": {},
   "source": [
    "# MODRM GRAPHS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "13831fcf-71a2-487d-9a18-534d8c869b6f",
   "metadata": {
    "tags": []
   },
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Correct way to read a CSV file into a DataFrame\n",
    "rf_policy_set= pd.read_csv('MODRM_DF.csv')\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "f88610e9-8cf1-4fb3-91c4-f5b0089630b8",
   "metadata": {
    "tags": []
   },
   "source": [
    "rf_policy_set"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "2e0c9d0e-05e1-4413-985f-f4487d757c2e",
   "metadata": {
    "tags": []
   },
   "source": [
    "from ema_workbench.analysis import parcoords\n",
    "\n",
    "ref_data = rf_policy_set.loc[:, [o.name for o in model.outcomes]]\n",
    "ref_limits = parcoords.get_limits(ref_data)\n",
    "ref_limits.loc[0, ['Expected Annual Damage A4', 'Expected Annual Damage A5','Expected Number of Deaths in A5', 'Expected Number of Deaths in A4', 'Total Costs']] = 0\n",
    "\n",
    "paraxes = parcoords.ParallelAxes(ref_limits)\n",
    "paraxes.plot(ref_data)\n",
    "plt.title('Trade-offs in Reference case scenario')\n",
    "\n",
    "# Set figure size\n",
    "# Run this twice, to get a nice broad view\n",
    "fig_size = plt.rcParams[\"figure.figsize\"]\n",
    "\n",
    "fig_size[0] = 12\n",
    "fig_size[1] = 12\n",
    "plt.rcParams[\"figure.figsize\"] = fig_size\n",
    "plt.show()\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "b7aa963f-5691-4aa4-97d3-73425c62fcad",
   "metadata": {
    "tags": []
   },
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from ema_workbench.analysis import parcoords\n",
    "\n",
    "# Assuming WC_policy_set and model are already defined\n",
    "ref_data = rf_policy_set.loc[:, [o.name for o in model.outcomes]]\n",
    "ref_limits = parcoords.get_limits(ref_data)\n",
    "ref_limits.loc[0, ['Expected Annual Damage A4', 'Expected Annual Damage A5',\n",
    "                   'Expected Number of Deaths in A5', 'Expected Number of Deaths in A4', 'Total Costs']] = 0\n",
    "\n",
    "# Create a ParallelAxes object\n",
    "paraxes = parcoords.ParallelAxes(ref_limits)\n",
    "\n",
    "# Generate a color palette\n",
    "colors = sns.color_palette('husl', len(rf_policy_set))\n",
    "\n",
    "# Plot each policy individually with a corresponding color and label\n",
    "for i, (index, row) in enumerate(rf_policy_set.iterrows()):\n",
    "    outcomes = row.loc[['Expected Annual Damage A4', 'Expected Annual Damage A5',\n",
    "                        'Expected Number of Deaths in A5', 'Expected Number of Deaths in A4', 'Total Costs']]\n",
    "    paraxes.plot(outcomes.to_frame().T, color=colors[i], label=f'Policy {index}')\n",
    "\n",
    "# Add a legend to the plot\n",
    "paraxes.legend()\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "61da1a99-3d64-41f4-bfa6-2c80fbbe3e24",
   "metadata": {
    "tags": []
   },
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Correct way to read a CSV file into a DataFrame\n",
    "WC_policy_set= pd.read_csv('MODRM_WC.csv')\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "4529ddef-b00f-44ff-9602-211eb319f291",
   "metadata": {
    "tags": []
   },
   "source": [
    "WC_policy_set"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "ba14c010-31b4-4fe3-a714-dcd164858ce6",
   "metadata": {
    "tags": []
   },
   "source": [
    "from ema_workbench.analysis import parcoords\n",
    "\n",
    "ref_data = WC_policy_set.loc[:, [o.name for o in model.outcomes]]\n",
    "ref_limits = parcoords.get_limits(ref_data)\n",
    "ref_limits.loc[0, ['Expected Annual Damage A4', 'Expected Annual Damage A5','Expected Number of Deaths in A5', 'Expected Number of Deaths in A4', 'Total Costs']] = 0\n",
    "\n",
    "paraxes = parcoords.ParallelAxes(ref_limits)\n",
    "paraxes.plot(ref_data)\n",
    "plt.title('Trade-offs in Worst case scenario')\n",
    "paraxes.legend()\n",
    "# Set figure size\n",
    "# Run this twice, to get a nice broad view\n",
    "fig_size = plt.rcParams[\"figure.figsize\"]\n",
    "fig_size[0] = 12\n",
    "fig_size[1] = 12\n",
    "plt.rcParams[\"figure.figsize\"] = fig_size\n",
    "plt.show()\n",
    "\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "b2524d00-93f0-4426-98e2-c71693a3c71c",
   "metadata": {
    "tags": []
   },
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from ema_workbench.analysis import parcoords\n",
    "\n",
    "# Assuming WC_policy_set and model are already defined\n",
    "ref_data = WC_policy_set.loc[:, [o.name for o in model.outcomes]]\n",
    "ref_limits = parcoords.get_limits(ref_data)\n",
    "ref_limits.loc[0, ['Expected Annual Damage A4', 'Expected Annual Damage A5',\n",
    "                   'Expected Number of Deaths in A5', 'Expected Number of Deaths in A4', 'Total Costs']] = 0\n",
    "\n",
    "# Create a ParallelAxes object\n",
    "paraxes = parcoords.ParallelAxes(ref_limits)\n",
    "\n",
    "# Generate a color palette\n",
    "colors = sns.color_palette('husl', len(WC_policy_set))\n",
    "\n",
    "# Plot each policy individually with a corresponding color and label\n",
    "for i, (index, row) in enumerate(WC_policy_set.iterrows()):\n",
    "    outcomes = row.loc[['Expected Annual Damage A4', 'Expected Annual Damage A5',\n",
    "                        'Expected Number of Deaths in A5', 'Expected Number of Deaths in A4', 'Total Costs']]\n",
    "    paraxes.plot(outcomes.to_frame().T, color=colors[i], label=f'Policy {index}')\n",
    "\n",
    "# Add a legend to the plot\n",
    "paraxes.legend()\n",
    "\n",
    "# Set the figure size\n",
    "plt.figure(figsize=(12, 12))\n",
    "\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "0741ec9b-975f-49f0-9ed6-e6164761a9c5",
   "metadata": {},
   "source": [
    "# PRIM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "ddfffbd3-ab8c-48a2-8ba7-1209975bb60d",
   "metadata": {
    "tags": []
   },
   "source": [
    "rf_em = load_results('Week23_reference_case_2000_6.tar.gz')"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "8a3585d9-7a1d-4089-a42d-88bc84184c45",
   "metadata": {
    "tags": []
   },
   "source": [
    "experiments_rfem, outcomes_rfem = rf_em"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "b50dd6f0-165f-4319-86b9-bc6353378e70",
   "metadata": {
    "tags": []
   },
   "source": [
    "experiments_rfem[:, "
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "c239158e-0c86-40fb-9e5e-ab3bfc7d45e9",
   "metadata": {
    "tags": []
   },
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming outcomes_rfem is a tuple containing a DataFrame and a dictionary\n",
    "experiments_df, outcomes_dict = rf_em\n",
    "\n",
    "# Extract the policy data\n",
    "policies = experiments_df['policy']\n",
    "\n",
    "# Create a DataFrame from the outcomes dictionary and add the policy column\n",
    "outcomes_df = pd.DataFrame(outcomes_dict)\n",
    "outcomes_df['policy'] = policies.values\n",
    "\n",
    "# Calculate the mean of each outcome for each policy\n",
    "mean_outcomes = outcomes_df.groupby('policy').mean()\n",
    "\n",
    "# Plot the mean outcomes against the policies\n",
    "mean_outcomes.plot(kind='bar', figsize=(12, 8))\n",
    "plt.title('Mean Outcomes by Policy')\n",
    "plt.xlabel('Policy')\n",
    "plt.ylabel('Mean Value')\n",
    "plt.legend(title='Outcomes')\n",
    "plt.show()\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "880610ea-9c9d-427c-b1be-fce4f52dba3b",
   "metadata": {
    "tags": []
   },
   "source": [
    "policiess = experiments_rfem.iloc[:,19:]\n",
    "policiess"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "dc8a374b-77bc-4be9-81de-dca169403d35",
   "metadata": {
    "tags": []
   },
   "source": [
    "scenaaa =experiments_rfem.iloc[:,:19]\n",
    "scenaaa"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "397eaf35-d9d7-4f74-8fd7-ee22b51b10ba",
   "metadata": {
    "tags": []
   },
   "source": [
    "outcomes_rfem['Expected Annual Damage A4']"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "3976c2c6-033c-4ce2-8753-878d8c04bb94",
   "metadata": {
    "tags": []
   },
   "source": [
    "outcomes_rfem"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "cb5666c4-a939-4c55-8e99-4b3e5a6690f2",
   "metadata": {
    "tags": []
   },
   "source": [
    "from ema_workbench.analysis import prim\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data = outcomes_rfem['Total Costs']\n",
    "\n",
    "# With continious outcomes, probably the only way to prim is throufh percentile??\n",
    "\n",
    "y = data < np.percentile(data, 10)\n",
    "\n",
    "# Initialize PRIM algorithm with the appropriate mode\n",
    "prim_alg = prim.Prim(experiments_rfem, y, threshold=0.7)\n",
    "box1 = prim_alg.find_box()\n",
    "\n",
    "box1.show_tradeoff(annotated=True)\n",
    "plt.show()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "c3780d39-819d-4d73-8be4-7da57896f42e",
   "metadata": {
    "tags": []
   },
   "source": [
    "point = 52\n",
    "box1.inspect(point)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "3fc89567-f7c2-449f-a689-07cfe934c82c",
   "metadata": {
    "tags": []
   },
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Assuming outcomes_rfem is a tuple containing a DataFrame and a dictionary\n",
    "experiments_df, outcomes_dict = rf_em\n",
    "\n",
    "# Extract the policy data\n",
    "policies = experiments_df['policy']\n",
    "\n",
    "# Create a DataFrame from the outcomes dictionary and add the policy column\n",
    "outcomes_df = pd.DataFrame(outcomes_dict)\n",
    "outcomes_df['policy'] = policies.values\n",
    "\n",
    "# Calculate the mean and standard deviation of each outcome for each policy\n",
    "mean_outcomes = outcomes_df.groupby('policy').mean()\n",
    "std_outcomes = outcomes_df.groupby('policy').std()\n",
    "\n",
    "# Plot the mean outcomes against the policies\n",
    "mean_outcomes.plot(kind='bar', figsize=(14, 8))\n",
    "plt.title('Mean Outcomes by Policy')\n",
    "plt.xlabel('Policy')\n",
    "plt.ylabel('Mean Value')\n",
    "plt.legend(title='Outcomes')\n",
    "plt.show()\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "3fc77e0e-66c2-4483-91c0-302302bf78e3",
   "metadata": {
    "tags": []
   },
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Assuming outcomes_rfem is a tuple containing a DataFrame and a dictionary\n",
    "experiments_df, outcomes_dict = rf_em\n",
    "\n",
    "# Extract the policy data\n",
    "policies = experiments_df['policy']\n",
    "\n",
    "# Create a DataFrame from the outcomes dictionary and add the policy column\n",
    "outcomes_df = pd.DataFrame(outcomes_dict)\n",
    "outcomes_df['policy'] = policies.values\n",
    "\n",
    "# Calculate the mean and standard deviation of each outcome for each policy\n",
    "mean_outcomes = outcomes_df.groupby('policy').mean()\n",
    "std_outcomes = outcomes_df.groupby('policy').std()\n",
    "\n",
    "# Plot the mean outcomes for each policy separately\n",
    "for outcome in mean_outcomes.columns:\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    mean_outcomes[outcome].plot(kind='bar')\n",
    "    plt.title(f'Mean {outcome} by Policy')\n",
    "    plt.xlabel('Policy')\n",
    "    plt.ylabel(f'Mean {outcome}')\n",
    "    plt.show()\n",
    "\n",
    "# Plot the standard deviation outcomes for each policy separately\n",
    "for outcome in std_outcomes.columns:\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    std_outcomes[outcome].plot(kind='bar')\n",
    "    plt.title(f'Standard Deviation of {outcome} by Policy')\n",
    "    plt.xlabel('Policy')\n",
    "    plt.ylabel(f'Standard Deviation of {outcome}')\n",
    "    plt.show()\n",
    "\n",
    "# Plot boxplots for each outcome grouped by policy\n",
    "for outcome in outcomes_df.columns[:-1]:  # Exclude the 'policy' column\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.boxplot(x='policy', y=outcome, data=outcomes_df)\n",
    "    plt.title(f'Boxplot of {outcome} by Policy')\n",
    "    plt.xlabel('Policy')\n",
    "    plt.ylabel(outcome)\n",
    "    plt.show()\n",
    "\n",
    "# Plot histograms for each outcome grouped by policy\n",
    "for outcome in outcomes_df.columns[:-1]:  # Exclude the 'policy' column\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    for policy in outcomes_df['policy'].unique():\n",
    "        subset = outcomes_df[outcome][outcomes_df['policy'] == policy]\n",
    "        sns.histplot(subset, kde=True, label=f'Policy\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a308637f-c19d-469b-8fe8-3b205482e45b",
   "metadata": {},
   "source": [],
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
