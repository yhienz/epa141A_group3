{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-14T07:34:12.880377Z",
     "start_time": "2024-06-14T07:34:12.859115Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Import general python packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import copy\n",
    "\n",
    "# Import functions\n",
    "from dike_model_function import DikeNetwork  # @UnresolvedImport\n",
    "from problem_formulation import get_model_for_problem_formulation\n",
    "from problem_formulation import sum_over, sum_over_time\n",
    "\n",
    "# Loading in the necessary modules for EMA workbench and functions\n",
    "from ema_workbench import (Model, MultiprocessingEvaluator, Scenario,\n",
    "                           Constraint, ScalarOutcome)\n",
    "from ema_workbench.util import ema_logging\n",
    "from ema_workbench import save_results, load_results\n",
    "from ema_workbench.em_framework.optimization import (EpsilonProgress)"
   ],
   "id": "90edb89410247c0a",
   "outputs": [],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-14T07:34:13.615569Z",
     "start_time": "2024-06-14T07:34:13.546292Z"
    }
   },
   "cell_type": "code",
   "source": "experiments, outcomes = load_results('Experiments/try_DisagT_PD7_1_1.tar.gz')",
   "id": "a46531f98ea36d1a",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[MainProcess/INFO] results loaded successfully from C:\\Users\\Gebruiker\\OneDrive - Delft University of Technology\\EPA\\Q4 Model based decision making\\epa141A_open\\final_ass_time_changed\\Experiments\\try_DisagT_PD7_1_1.tar.gz\n"
     ]
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-14T07:34:14.817460Z",
     "start_time": "2024-06-14T07:34:14.800807Z"
    }
   },
   "cell_type": "code",
   "source": "outcomes",
   "id": "613ec4ec2abdb90c",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Expected Number of Deaths': array([[0.00062459, 0.        , 0.        , 0.        , 0.        ]]),\n",
       " 'A.1_Expected Annual Damage': array([[0., 0., 0., 0., 0.]]),\n",
       " 'A.2_Expected Annual Damage': array([[3558948.76099897,       0.        ,       0.        ,\n",
       "               0.        ,       0.        ]]),\n",
       " 'A.3_Expected Annual Damage': array([[0., 0., 0., 0., 0.]]),\n",
       " 'A.4_Expected Annual Damage': array([[0., 0., 0., 0., 0.]]),\n",
       " 'A.5_Expected Annual Damage': array([[0., 0., 0., 0., 0.]]),\n",
       " 'Total_period_Costs': array([[7.49191029e+08, 2.91567221e+08, 3.97296929e+08, 2.26396419e+08,\n",
       "         8.45652241e+08]])}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-14T07:34:18.464072Z",
     "start_time": "2024-06-14T07:34:18.421207Z"
    }
   },
   "cell_type": "code",
   "source": "experiments",
   "id": "b2258c11651af17",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   A.0_ID flood wave shape   A.1_Bmax A.1_Brate  A.1_pfail    A.2_Bmax  \\\n",
       "0                       87  339.18835       1.0   0.954041  266.819102   \n",
       "\n",
       "  A.2_Brate  A.2_pfail   A.3_Bmax A.3_Brate  A.3_pfail  ...  \\\n",
       "0       1.0   0.230765  86.963423       1.0   0.221302  ...   \n",
       "\n",
       "   A.4_DikeIncrease 4 A.5_DikeIncrease 0  A.5_DikeIncrease 1  \\\n",
       "0                   6                  2                   2   \n",
       "\n",
       "   A.5_DikeIncrease 2 A.5_DikeIncrease 3  A.5_DikeIncrease 4 EWS_DaysToThreat  \\\n",
       "0                   1                  8                   7                2   \n",
       "\n",
       "  scenario policy     model  \n",
       "0        1      0  dikesnet  \n",
       "\n",
       "[1 rows x 75 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A.0_ID flood wave shape</th>\n",
       "      <th>A.1_Bmax</th>\n",
       "      <th>A.1_Brate</th>\n",
       "      <th>A.1_pfail</th>\n",
       "      <th>A.2_Bmax</th>\n",
       "      <th>A.2_Brate</th>\n",
       "      <th>A.2_pfail</th>\n",
       "      <th>A.3_Bmax</th>\n",
       "      <th>A.3_Brate</th>\n",
       "      <th>A.3_pfail</th>\n",
       "      <th>...</th>\n",
       "      <th>A.4_DikeIncrease 4</th>\n",
       "      <th>A.5_DikeIncrease 0</th>\n",
       "      <th>A.5_DikeIncrease 1</th>\n",
       "      <th>A.5_DikeIncrease 2</th>\n",
       "      <th>A.5_DikeIncrease 3</th>\n",
       "      <th>A.5_DikeIncrease 4</th>\n",
       "      <th>EWS_DaysToThreat</th>\n",
       "      <th>scenario</th>\n",
       "      <th>policy</th>\n",
       "      <th>model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>87</td>\n",
       "      <td>339.18835</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.954041</td>\n",
       "      <td>266.819102</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.230765</td>\n",
       "      <td>86.963423</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.221302</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>dikesnet</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 75 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# MORDM",
   "id": "b9f48a3d3a0555c4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-14T07:22:02.115426Z",
     "start_time": "2024-06-14T07:21:59.514460Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Loading in all the 17 objectives via predefined problem formulation 3\n",
    "if __name__ == '__main__':\n",
    "    ema_logging.log_to_stderr(ema_logging.INFO)\n",
    "    dike_model, planning_steps = get_model_for_problem_formulation(7)"
   ],
   "id": "24f4013befc6d19a",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-14T07:22:03.383433Z",
     "start_time": "2024-06-14T07:22:03.364094Z"
    }
   },
   "cell_type": "code",
   "source": "print(planning_steps)",
   "id": "53f3bf3ef5cb4b02",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4]\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "id": "b6b301ac7683c5ee",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-06-14T07:22:04.766276Z",
     "start_time": "2024-06-14T07:22:04.751919Z"
    }
   },
   "source": [
    "# Replicate the objectives\n",
    "for outcome in dike_model.outcomes:\n",
    "    print(repr(outcome))\n",
    "    "
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ArrayOutcome('Expected Number of Deaths', variable_name=('A.1_Expected Number of Deaths', 'A.2_Expected Number of Deaths', 'A.3_Expected Number of Deaths', 'A.4_Expected Number of Deaths', 'A.5_Expected Number of Deaths'), function=<function sum_over_time at 0x00000199F5707BA0>)\n",
      "ArrayOutcome('A.1_Expected Annual Damage')\n",
      "ArrayOutcome('A.2_Expected Annual Damage')\n",
      "ArrayOutcome('A.3_Expected Annual Damage')\n",
      "ArrayOutcome('A.4_Expected Annual Damage')\n",
      "ArrayOutcome('A.5_Expected Annual Damage')\n",
      "ArrayOutcome('Total_period_Costs', variable_name=('A.1_Dike Investment Costs', 'A.2_Dike Investment Costs', 'A.3_Dike Investment Costs', 'A.4_Dike Investment Costs', 'A.5_Dike Investment Costs', 'RfR Total Costs', 'Expected Evacuation Costs'), function=<function sum_over_time at 0x00000199F5707BA0>)\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "id": "277a36e0-e5d8-4d34-9f17-3118ef97a1e3",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-06-14T07:24:39.645034Z",
     "start_time": "2024-06-14T07:24:39.593394Z"
    }
   },
   "source": [
    "# Writing a function to create actor specific problem formulations\n",
    "def problem_formulation_actor(problem_formulation_actor):\n",
    "   \n",
    "    # Load the model:\n",
    "    function = DikeNetwork()\n",
    "    # workbench model:\n",
    "    model = Model('dikesnet', function=function)\n",
    "    # Outcomes are all costs, thus they have to minimized:\n",
    "    direction = ScalarOutcome.MINIMIZE\n",
    "    \n",
    "    model.uncertainties = uncertainties\n",
    "    model.levers = levers\n",
    "    \n",
    "    cost_variables = []\n",
    "    cost_variables.extend(\n",
    "    [\n",
    "        f\"{dike}_{e}\"\n",
    "        for e in [\"Expected Annual Damage\", \"Dike Investment Costs\"]\n",
    "        for dike in function.dikelist\n",
    "    ])\n",
    "    cost_variables.extend([f\"RfR Total Costs\"])\n",
    "    cost_variables.extend([f\"Expected Evacuation Costs\"])\n",
    "\n",
    "\n",
    "    if problem_formulation_actor == 4: #RWS\n",
    "        model.outcomes.clear()\n",
    "        model.outcomes = [\n",
    "            ScalarOutcome('Expected Annual Damage',\n",
    "                            variable_name=['{}_Expected Annual Damage'.format(dike)\n",
    "                                                for dike in function.dikelist],\n",
    "                            function=sum_over, kind=direction),\n",
    "\n",
    "            ScalarOutcome('Total Investment Costs',\n",
    "                            variable_name=['{}_Dike Investment Costs'.format(dike)\n",
    "                                                for dike in function.dikelist] + ['RfR Total Costs'\n",
    "                                                                                ] + ['Expected Evacuation Costs'],\n",
    "                            function=sum_over, kind=direction),\n",
    "\n",
    "            ScalarOutcome('Expected Number of Deaths',\n",
    "                            variable_name=['{}_Expected Number of Deaths'.format(dike)\n",
    "                                                for dike in function.dikelist],\n",
    "                            function=sum_over, kind=direction)] \n",
    "    \n",
    "    elif problem_formulation_actor == 5: # GELDERLAND\n",
    "        model.outcomes.clear()\n",
    "        model.outcomes = [\n",
    "            ScalarOutcome('Expected Annual Damage A1-4',\n",
    "                            variable_name=['A.1_Expected Annual Damage' ,'A.2_Expected Annual Damage', 'A.3_Expected Annual Damage', 'A.4_Expected Annual Damage'], function=sum_over, kind=direction),\n",
    "\n",
    "            ScalarOutcome('Investment Costs A1-4',\n",
    "                            variable_name=['A.1_Dike Investment Costs', 'A.2_Dike Investment Costs', 'A.3_Dike Investment Costs', 'A.4_Dike Investment Costs'], function=sum_over, kind=direction),\n",
    "\n",
    "            ScalarOutcome('Expected Number of Deaths in A1-4',\n",
    "                            variable_name=['A.1_Expected Number of Deaths', 'A.2_Expected Number of Deaths', 'A.3_Expected Number of Deaths', 'A.4_Expected Number of Deaths'], function=sum_over, kind=direction)]\n",
    "    \n",
    "    elif problem_formulation_actor == 6: # OVERIJSSEL\n",
    "        model.outcomes.clear()\n",
    "        model.outcomes = [\n",
    "            ScalarOutcome('Expected Annual Damage A4', variable_name='A.4_Expected Annual Damage', function = sum_over, kind=direction),\n",
    "            ScalarOutcome('Expected Annual Damage A5', variable_name='A.5_Expected Annual Damage', function = sum_over, kind=direction),            \n",
    "            ScalarOutcome('Expected Number of Deaths in A4', variable_name='A.4_Expected Number of Deaths',function = sum_over, kind=direction),\n",
    "            ScalarOutcome('Expected Number of Deaths in A5', variable_name='A.5_Expected Number of Deaths',function = sum_over, kind=direction),\n",
    "            ScalarOutcome('Total Costs', variable_name=cost_variables, function = sum_over, kind=direction),\n",
    "            ScalarOutcome('Aggregated Expected Number of Deaths A1-A3', variable_name =\n",
    "            ['A.1_Expected Number of Deaths', 'A.2_Expected Number of Deaths', \n",
    "             'A.3_Expected Number of Deaths'], function = sum_over, kind=direction)]\n",
    "    elif problem_formulation_actor == 7: \n",
    "\n",
    "    \n",
    "    else:\n",
    "        raise TypeError('unknown identifier')\n",
    "    return model"
   ],
   "outputs": [],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "id": "1bfd2ae6-5f22-4449-a17a-d82042a02813",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-06-14T07:24:40.462747Z",
     "start_time": "2024-06-14T07:24:40.417513Z"
    }
   },
   "source": [
    "# Replicate the uncertainties\n",
    "uncertainties = dike_model.uncertainties\n",
    "uncertainties = copy.deepcopy(dike_model.uncertainties)"
   ],
   "outputs": [],
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "id": "d2c96536-35ba-4172-b925-62abbc885eaa",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-06-14T07:24:41.036134Z",
     "start_time": "2024-06-14T07:24:40.981519Z"
    }
   },
   "source": [
    "levers = dike_model.levers \n",
    "levers = copy.deepcopy(dike_model.levers)"
   ],
   "outputs": [],
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "id": "a91639a2468a9adc",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-06-14T07:24:43.291034Z",
     "start_time": "2024-06-14T07:24:41.795679Z"
    }
   },
   "source": [
    "model = problem_formulation_actor(7)\n",
    "for outcome in model.outcomes:\n",
    "    print(repr((outcome)))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ArrayOutcome('Expected Number of Deaths', variable_name=('A.1_Expected Number of Deaths', 'A.2_Expected Number of Deaths', 'A.3_Expected Number of Deaths', 'A.4_Expected Number of Deaths', 'A.5_Expected Number of Deaths'), function=<function sum_over_time at 0x00000199F5707BA0>)\n",
      "ArrayOutcome('A.1_Expected Annual Damage')\n",
      "ArrayOutcome('A.2_Expected Annual Damage')\n",
      "ArrayOutcome('A.3_Expected Annual Damage')\n",
      "ArrayOutcome('A.4_Expected Annual Damage')\n",
      "ArrayOutcome('A.5_Expected Annual Damage')\n",
      "ArrayOutcome('Total_period_Costs', variable_name=('A.1_Dike Investment Costs', 'A.2_Dike Investment Costs', 'A.3_Dike Investment Costs', 'A.4_Dike Investment Costs', 'A.5_Dike Investment Costs', 'RfR Total Costs', 'Expected Evacuation Costs'), function=<function sum_over_time at 0x00000199F5707BA0>)\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "cell_type": "markdown",
   "id": "adac028e40648723",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "id": "8dc875ff-0e3b-4e4c-81bf-050b8ee99b44",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-06-14T07:24:47.362173Z",
     "start_time": "2024-06-14T07:24:47.346801Z"
    }
   },
   "source": [
    "print(len(model.outcomes))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "id": "3b5e260bcd0a1bc3",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-06-14T07:24:58.132027Z",
     "start_time": "2024-06-14T07:24:58.115897Z"
    }
   },
   "source": [
    "reference_values = {\n",
    "    \"Bmax\": 175,\n",
    "    \"Brate\": 1.5,\n",
    "    \"pfail\": 0.5,\n",
    "    \"ID flood wave shape\": 4,\n",
    "    \"planning steps\": 2,\n",
    "}\n",
    "reference_values.update({f\"discount rate {n}\": 3.5 for n in planning_steps})\n",
    "refcase_scen = {}\n",
    "\n",
    "for key in dike_model.uncertainties:\n",
    "    name_split = key.name.split('_')\n",
    "    if len(name_split) == 1:\n",
    "\n",
    "        refcase_scen.update({key.name: reference_values[key.name]})\n",
    "    else:\n",
    "        refcase_scen.update({key.name: reference_values[name_split[1]]})\n",
    "            \n",
    "ref_scenario = Scenario('reference', **refcase_scen)"
   ],
   "outputs": [],
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "id": "51aeba8593a9ed87",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-06-14T07:25:41.167007Z",
     "start_time": "2024-06-14T07:25:17.787607Z"
    }
   },
   "source": [
    "convergence_metrics = {EpsilonProgress()}\n",
    "#constraint = [Constraint(\"Total Costs\", outcome_names=\"Total Costs\", function=lambda x: max(0, x - 7700000000))]\n",
    "\n",
    "with MultiprocessingEvaluator(model,n_processes=-1) as evaluator:\n",
    "   results2 = evaluator.optimize(nfe=1, searchover='levers',\n",
    "                                 convergence=convergence_metrics,\n",
    "                                 epsilons=[1]*len(model.outcomes), reference=ref_scenario)\n",
    "\n",
    "save_results(results2, 'Experiments/Week23_MORDM_Reference_1000_PD6.tar.gz')\n"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[MainProcess/INFO] pool started with 3 workers\n",
      "[MainProcess/INFO] terminating pool\n"
     ]
    },
    {
     "ename": "EMAError",
     "evalue": "No outcomes specified to optimize over, all outcomes are of kind=INFO",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mEMAError\u001B[0m                                  Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[16], line 5\u001B[0m\n\u001B[0;32m      2\u001B[0m \u001B[38;5;66;03m#constraint = [Constraint(\"Total Costs\", outcome_names=\"Total Costs\", function=lambda x: max(0, x - 7700000000))]\u001B[39;00m\n\u001B[0;32m      4\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m MultiprocessingEvaluator(model,n_processes\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m) \u001B[38;5;28;01mas\u001B[39;00m evaluator:\n\u001B[1;32m----> 5\u001B[0m    results2 \u001B[38;5;241m=\u001B[39m evaluator\u001B[38;5;241m.\u001B[39moptimize(nfe\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m, searchover\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mlevers\u001B[39m\u001B[38;5;124m'\u001B[39m,\n\u001B[0;32m      6\u001B[0m                                  convergence\u001B[38;5;241m=\u001B[39mconvergence_metrics,\n\u001B[0;32m      7\u001B[0m                                  epsilons\u001B[38;5;241m=\u001B[39m[\u001B[38;5;241m1\u001B[39m]\u001B[38;5;241m*\u001B[39m\u001B[38;5;28mlen\u001B[39m(model\u001B[38;5;241m.\u001B[39moutcomes), reference\u001B[38;5;241m=\u001B[39mref_scenario)\n\u001B[0;32m      9\u001B[0m save_results(results2, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mExperiments/Week23_MORDM_Reference_1000_PD6.tar.gz\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\ema_workbench\\em_framework\\evaluators.py:228\u001B[0m, in \u001B[0;36mBaseEvaluator.optimize\u001B[1;34m(self, algorithm, nfe, searchover, reference, constraints, convergence_freq, logging_freq, variator, **kwargs)\u001B[0m\n\u001B[0;32m    210\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21moptimize\u001B[39m(\n\u001B[0;32m    211\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m    212\u001B[0m     algorithm\u001B[38;5;241m=\u001B[39mEpsNSGAII,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    220\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs,\n\u001B[0;32m    221\u001B[0m ):\n\u001B[0;32m    222\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"convenience method for outcome optimization.\u001B[39;00m\n\u001B[0;32m    223\u001B[0m \n\u001B[0;32m    224\u001B[0m \u001B[38;5;124;03m    is forwarded to :func:optimize, with evaluator and models\u001B[39;00m\n\u001B[0;32m    225\u001B[0m \u001B[38;5;124;03m    arguments added in.\u001B[39;00m\n\u001B[0;32m    226\u001B[0m \n\u001B[0;32m    227\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m--> 228\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m optimize(\n\u001B[0;32m    229\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_msis,\n\u001B[0;32m    230\u001B[0m         algorithm\u001B[38;5;241m=\u001B[39malgorithm,\n\u001B[0;32m    231\u001B[0m         nfe\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mint\u001B[39m(nfe),\n\u001B[0;32m    232\u001B[0m         searchover\u001B[38;5;241m=\u001B[39msearchover,\n\u001B[0;32m    233\u001B[0m         evaluator\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m    234\u001B[0m         reference\u001B[38;5;241m=\u001B[39mreference,\n\u001B[0;32m    235\u001B[0m         constraints\u001B[38;5;241m=\u001B[39mconstraints,\n\u001B[0;32m    236\u001B[0m         convergence_freq\u001B[38;5;241m=\u001B[39mconvergence_freq,\n\u001B[0;32m    237\u001B[0m         logging_freq\u001B[38;5;241m=\u001B[39mlogging_freq,\n\u001B[0;32m    238\u001B[0m         variator\u001B[38;5;241m=\u001B[39mvariator,\n\u001B[0;32m    239\u001B[0m         \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs,\n\u001B[0;32m    240\u001B[0m     )\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\ema_workbench\\em_framework\\evaluators.py:570\u001B[0m, in \u001B[0;36moptimize\u001B[1;34m(models, algorithm, nfe, searchover, evaluator, reference, convergence, constraints, convergence_freq, logging_freq, variator, **kwargs)\u001B[0m\n\u001B[0;32m    567\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m:\n\u001B[0;32m    568\u001B[0m     \u001B[38;5;28;01mpass\u001B[39;00m\n\u001B[1;32m--> 570\u001B[0m problem \u001B[38;5;241m=\u001B[39m to_problem(models, searchover, constraints\u001B[38;5;241m=\u001B[39mconstraints, reference\u001B[38;5;241m=\u001B[39mreference)\n\u001B[0;32m    572\u001B[0m \u001B[38;5;66;03m# solve the optimization problem\u001B[39;00m\n\u001B[0;32m    573\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m evaluator:\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\ema_workbench\\em_framework\\optimization.py:187\u001B[0m, in \u001B[0;36mto_problem\u001B[1;34m(model, searchover, reference, constraints)\u001B[0m\n\u001B[0;32m    184\u001B[0m outcome_names \u001B[38;5;241m=\u001B[39m [outcome\u001B[38;5;241m.\u001B[39mname \u001B[38;5;28;01mfor\u001B[39;00m outcome \u001B[38;5;129;01min\u001B[39;00m outcomes]\n\u001B[0;32m    186\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m outcomes:\n\u001B[1;32m--> 187\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m EMAError(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mNo outcomes specified to optimize over, all outcomes are of kind=INFO\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m    189\u001B[0m problem \u001B[38;5;241m=\u001B[39m Problem(\n\u001B[0;32m    190\u001B[0m     searchover, decision_variables, outcome_names, constraints, reference\u001B[38;5;241m=\u001B[39mreference\n\u001B[0;32m    191\u001B[0m )\n\u001B[0;32m    192\u001B[0m problem\u001B[38;5;241m.\u001B[39mtypes \u001B[38;5;241m=\u001B[39m to_platypus_types(decision_variables)\n",
      "\u001B[1;31mEMAError\u001B[0m: No outcomes specified to optimize over, all outcomes are of kind=INFO"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "id": "27ba29de-d899-4ebf-8874-02558697fab7",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-06-10T19:40:14.569304Z",
     "start_time": "2024-06-10T19:40:14.562126Z"
    }
   },
   "source": "y,t = results2",
   "execution_count": 106,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T19:40:16.006897Z",
     "start_time": "2024-06-10T19:40:15.971981Z"
    }
   },
   "cell_type": "code",
   "source": "y",
   "id": "9dc0e263c5b34ee3",
   "execution_count": 107,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "b8152c46-e1d4-4eac-84be-cb06bdeb7e22",
   "metadata": {},
   "source": [
    "### Worst Case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a02d93cb-e5c4-4858-a172-1262f4a5eea3",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Worst case specification\n",
    "worstcase_values ={\n",
    "    \"Bmax\": 175,\n",
    "    \"Brate\": 1.5,\n",
    "    \"pfail\": 0.9,\n",
    "    \"ID flood wave shape\": 4,\n",
    "    \"planning steps\": 2,\n",
    "}\n",
    "worstcase_values.update({f\"discount rate {n}\": 3.5 for n in planning_steps})\n",
    "\n",
    "worstcase_scen = {}\n",
    "\n",
    "for key in dike_model.uncertainties:\n",
    "    name_split = key.name.split('_')\n",
    "    if len(name_split) == 1:\n",
    "\n",
    "        worstcase_scen.update({key.name: worstcase_values[key.name]})\n",
    "    else:\n",
    "        worstcase_scen.update({key.name: worstcase_values[name_split[1]]})\n",
    "            \n",
    "worst_scenario = Scenario('reference', **worstcase_scen)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3eee8846-13bc-45bf-8f70-0afd4d6a12db",
   "metadata": {
    "tags": []
   },
   "source": [
    "#convergence_metrics = {EpsilonProgress()}\n",
    "\n",
    "#with MultiprocessingEvaluator(model,n_processes=-1) as evaluator:\n",
    "  #  results3 = evaluator.optimize(nfe=4000, searchover='levers',\n",
    "     #                            convergence=convergence_metrics,\n",
    "      #                           epsilons=[0.01]*len(model.outcomes), reference=worst_scenario)\n",
    "\n",
    "#save_results(results2, 'Experiments/Week23_MORDM_Reference_1000_PD6.tar.gz')\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9392a969-675b-4798-aaae-2c20e9dabdf8",
   "metadata": {
    "tags": []
   },
   "source": [
    "worst_case.to_csv('MODRM_WC.csv')"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7ac27e4f-3a71-4f33-aba7-bfe8c980bf6b",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Selecting the policies that are proposed as solutions for further robustness tests\n",
    "from ema_workbench import Policy\n",
    "\n",
    "worstcase_policies_to_evaluate = []\n",
    "\n",
    "for i, policy in import_worst_case.iterrows():\n",
    "    worstcase_policies_to_evaluate.append(Policy(str(i), **policy.to_dict()))"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3065333a-f7f9-4489-8910-65ce256bec4a",
   "metadata": {
    "tags": []
   },
   "source": [
    "n_scenarios = 2000\n",
    "#with MultiprocessingEvaluator(model) as evaluator:\n",
    " #   worst_results = evaluator.perform_experiments(n_scenarios,\n",
    "  #                                          worstcase_policies_to_evaluate)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "238143e8-e9fe-4eb2-a9f4-6c6352a31829",
   "metadata": {
    "tags": []
   },
   "source": [
    "save_results(worst_results, 'Week23_worst_case_2000_4.tar.gz')"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "dccaaf26-6045-404a-bcf5-2de52622cca5",
   "metadata": {},
   "source": "### Reference case"
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "79f610a9-0759-4267-988f-6b6efcd7f219",
   "metadata": {
    "tags": []
   },
   "source": [
    "reference_case_re = pd.read_csv('MODRM_DF.csv')"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cc27b2e1-3694-4e30-8a98-f5be13968a7b",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Selecting the policies that are proposed as solutions for further robustness tests\n",
    "from ema_workbench import Policy\n",
    "\n",
    "refercase_policies_to_evaluate = []\n",
    "\n",
    "for i, policy in reference_case_re.iterrows():\n",
    "    refercase_policies_to_evaluate.append(Policy(str(i), **policy.to_dict()))"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2c5d3fdb-a091-40c8-9fb1-57027005e6e6",
   "metadata": {
    "tags": []
   },
   "source": [
    "n_scenarios = 2000\n",
    "with MultiprocessingEvaluator(model) as evaluator:\n",
    "    reference_policies_results = evaluator.perform_experiments(n_scenarios,\n",
    "                                            refercase_policies_to_evaluate)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fd8b8755-6ff4-4cfc-bb55-b39b518f2efe",
   "metadata": {
    "tags": []
   },
   "source": [
    "save_results(reference_policies_results, 'Week23_reference_case_2000_6.tar.gz')"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19e77fe7-4e5d-45be-b719-844a5ca4c3eb",
   "metadata": {},
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "c71d4857-f0d9-4d15-b528-0aabc7fe0bf8",
   "metadata": {},
   "source": [
    "# MODRM GRAPHS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "13831fcf-71a2-487d-9a18-534d8c869b6f",
   "metadata": {
    "tags": []
   },
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Correct way to read a CSV file into a DataFrame\n",
    "rf_policy_set= pd.read_csv('MODRM_DF.csv')\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "f88610e9-8cf1-4fb3-91c4-f5b0089630b8",
   "metadata": {
    "tags": []
   },
   "source": [
    "rf_policy_set"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "2e0c9d0e-05e1-4413-985f-f4487d757c2e",
   "metadata": {
    "tags": []
   },
   "source": [
    "from ema_workbench.analysis import parcoords\n",
    "\n",
    "ref_data = rf_policy_set.loc[:, [o.name for o in model.outcomes]]\n",
    "ref_limits = parcoords.get_limits(ref_data)\n",
    "ref_limits.loc[0, ['Expected Annual Damage A4', 'Expected Annual Damage A5','Expected Number of Deaths in A5', 'Expected Number of Deaths in A4', 'Total Costs']] = 0\n",
    "\n",
    "paraxes = parcoords.ParallelAxes(ref_limits)\n",
    "paraxes.plot(ref_data)\n",
    "plt.title('Trade-offs in Reference case scenario')\n",
    "\n",
    "# Set figure size\n",
    "# Run this twice, to get a nice broad view\n",
    "fig_size = plt.rcParams[\"figure.figsize\"]\n",
    "\n",
    "fig_size[0] = 12\n",
    "fig_size[1] = 12\n",
    "plt.rcParams[\"figure.figsize\"] = fig_size\n",
    "plt.show()\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "b7aa963f-5691-4aa4-97d3-73425c62fcad",
   "metadata": {
    "tags": []
   },
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from ema_workbench.analysis import parcoords\n",
    "\n",
    "# Assuming WC_policy_set and model are already defined\n",
    "ref_data = rf_policy_set.loc[:, [o.name for o in model.outcomes]]\n",
    "ref_limits = parcoords.get_limits(ref_data)\n",
    "ref_limits.loc[0, ['Expected Annual Damage A4', 'Expected Annual Damage A5',\n",
    "                   'Expected Number of Deaths in A5', 'Expected Number of Deaths in A4', 'Total Costs']] = 0\n",
    "\n",
    "# Create a ParallelAxes object\n",
    "paraxes = parcoords.ParallelAxes(ref_limits)\n",
    "\n",
    "# Generate a color palette\n",
    "colors = sns.color_palette('husl', len(rf_policy_set))\n",
    "\n",
    "# Plot each policy individually with a corresponding color and label\n",
    "for i, (index, row) in enumerate(rf_policy_set.iterrows()):\n",
    "    outcomes = row.loc[['Expected Annual Damage A4', 'Expected Annual Damage A5',\n",
    "                        'Expected Number of Deaths in A5', 'Expected Number of Deaths in A4', 'Total Costs']]\n",
    "    paraxes.plot(outcomes.to_frame().T, color=colors[i], label=f'Policy {index}')\n",
    "\n",
    "# Add a legend to the plot\n",
    "paraxes.legend()\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "61da1a99-3d64-41f4-bfa6-2c80fbbe3e24",
   "metadata": {
    "tags": []
   },
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Correct way to read a CSV file into a DataFrame\n",
    "WC_policy_set= pd.read_csv('MODRM_WC.csv')\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "4529ddef-b00f-44ff-9602-211eb319f291",
   "metadata": {
    "tags": []
   },
   "source": [
    "WC_policy_set"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "ba14c010-31b4-4fe3-a714-dcd164858ce6",
   "metadata": {
    "tags": []
   },
   "source": [
    "from ema_workbench.analysis import parcoords\n",
    "\n",
    "ref_data = WC_policy_set.loc[:, [o.name for o in model.outcomes]]\n",
    "ref_limits = parcoords.get_limits(ref_data)\n",
    "ref_limits.loc[0, ['Expected Annual Damage A4', 'Expected Annual Damage A5','Expected Number of Deaths in A5', 'Expected Number of Deaths in A4', 'Total Costs']] = 0\n",
    "\n",
    "paraxes = parcoords.ParallelAxes(ref_limits)\n",
    "paraxes.plot(ref_data)\n",
    "plt.title('Trade-offs in Worst case scenario')\n",
    "paraxes.legend()\n",
    "# Set figure size\n",
    "# Run this twice, to get a nice broad view\n",
    "fig_size = plt.rcParams[\"figure.figsize\"]\n",
    "fig_size[0] = 12\n",
    "fig_size[1] = 12\n",
    "plt.rcParams[\"figure.figsize\"] = fig_size\n",
    "plt.show()\n",
    "\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "b2524d00-93f0-4426-98e2-c71693a3c71c",
   "metadata": {
    "tags": []
   },
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from ema_workbench.analysis import parcoords\n",
    "\n",
    "# Assuming WC_policy_set and model are already defined\n",
    "ref_data = WC_policy_set.loc[:, [o.name for o in model.outcomes]]\n",
    "ref_limits = parcoords.get_limits(ref_data)\n",
    "ref_limits.loc[0, ['Expected Annual Damage A4', 'Expected Annual Damage A5',\n",
    "                   'Expected Number of Deaths in A5', 'Expected Number of Deaths in A4', 'Total Costs']] = 0\n",
    "\n",
    "# Create a ParallelAxes object\n",
    "paraxes = parcoords.ParallelAxes(ref_limits)\n",
    "\n",
    "# Generate a color palette\n",
    "colors = sns.color_palette('husl', len(WC_policy_set))\n",
    "\n",
    "# Plot each policy individually with a corresponding color and label\n",
    "for i, (index, row) in enumerate(WC_policy_set.iterrows()):\n",
    "    outcomes = row.loc[['Expected Annual Damage A4', 'Expected Annual Damage A5',\n",
    "                        'Expected Number of Deaths in A5', 'Expected Number of Deaths in A4', 'Total Costs']]\n",
    "    paraxes.plot(outcomes.to_frame().T, color=colors[i], label=f'Policy {index}')\n",
    "\n",
    "# Add a legend to the plot\n",
    "paraxes.legend()\n",
    "\n",
    "# Set the figure size\n",
    "plt.figure(figsize=(12, 12))\n",
    "\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "0741ec9b-975f-49f0-9ed6-e6164761a9c5",
   "metadata": {},
   "source": [
    "# PRIM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "ddfffbd3-ab8c-48a2-8ba7-1209975bb60d",
   "metadata": {
    "tags": []
   },
   "source": [
    "rf_em = load_results('Week23_reference_case_2000_6.tar.gz')"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "8a3585d9-7a1d-4089-a42d-88bc84184c45",
   "metadata": {
    "tags": []
   },
   "source": [
    "experiments_rfem, outcomes_rfem = rf_em"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "b50dd6f0-165f-4319-86b9-bc6353378e70",
   "metadata": {
    "tags": []
   },
   "source": [
    "experiments_rfem[:, "
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "c239158e-0c86-40fb-9e5e-ab3bfc7d45e9",
   "metadata": {
    "tags": []
   },
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming outcomes_rfem is a tuple containing a DataFrame and a dictionary\n",
    "experiments_df, outcomes_dict = rf_em\n",
    "\n",
    "# Extract the policy data\n",
    "policies = experiments_df['policy']\n",
    "\n",
    "# Create a DataFrame from the outcomes dictionary and add the policy column\n",
    "outcomes_df = pd.DataFrame(outcomes_dict)\n",
    "outcomes_df['policy'] = policies.values\n",
    "\n",
    "# Calculate the mean of each outcome for each policy\n",
    "mean_outcomes = outcomes_df.groupby('policy').mean()\n",
    "\n",
    "# Plot the mean outcomes against the policies\n",
    "mean_outcomes.plot(kind='bar', figsize=(12, 8))\n",
    "plt.title('Mean Outcomes by Policy')\n",
    "plt.xlabel('Policy')\n",
    "plt.ylabel('Mean Value')\n",
    "plt.legend(title='Outcomes')\n",
    "plt.show()\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "880610ea-9c9d-427c-b1be-fce4f52dba3b",
   "metadata": {
    "tags": []
   },
   "source": [
    "policiess = experiments_rfem.iloc[:,19:]\n",
    "policiess"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "dc8a374b-77bc-4be9-81de-dca169403d35",
   "metadata": {
    "tags": []
   },
   "source": [
    "scenaaa =experiments_rfem.iloc[:,:19]\n",
    "scenaaa"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "397eaf35-d9d7-4f74-8fd7-ee22b51b10ba",
   "metadata": {
    "tags": []
   },
   "source": [
    "outcomes_rfem['Expected Annual Damage A4']"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "3976c2c6-033c-4ce2-8753-878d8c04bb94",
   "metadata": {
    "tags": []
   },
   "source": [
    "outcomes_rfem"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "cb5666c4-a939-4c55-8e99-4b3e5a6690f2",
   "metadata": {
    "tags": []
   },
   "source": [
    "from ema_workbench.analysis import prim\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data = outcomes_rfem['Total Costs']\n",
    "\n",
    "# With continious outcomes, probably the only way to prim is throufh percentile??\n",
    "\n",
    "y = data < np.percentile(data, 10)\n",
    "\n",
    "# Initialize PRIM algorithm with the appropriate mode\n",
    "prim_alg = prim.Prim(experiments_rfem, y, threshold=0.7)\n",
    "box1 = prim_alg.find_box()\n",
    "\n",
    "box1.show_tradeoff(annotated=True)\n",
    "plt.show()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "c3780d39-819d-4d73-8be4-7da57896f42e",
   "metadata": {
    "tags": []
   },
   "source": [
    "point = 52\n",
    "box1.inspect(point)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "3fc89567-f7c2-449f-a689-07cfe934c82c",
   "metadata": {
    "tags": []
   },
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Assuming outcomes_rfem is a tuple containing a DataFrame and a dictionary\n",
    "experiments_df, outcomes_dict = rf_em\n",
    "\n",
    "# Extract the policy data\n",
    "policies = experiments_df['policy']\n",
    "\n",
    "# Create a DataFrame from the outcomes dictionary and add the policy column\n",
    "outcomes_df = pd.DataFrame(outcomes_dict)\n",
    "outcomes_df['policy'] = policies.values\n",
    "\n",
    "# Calculate the mean and standard deviation of each outcome for each policy\n",
    "mean_outcomes = outcomes_df.groupby('policy').mean()\n",
    "std_outcomes = outcomes_df.groupby('policy').std()\n",
    "\n",
    "# Plot the mean outcomes against the policies\n",
    "mean_outcomes.plot(kind='bar', figsize=(14, 8))\n",
    "plt.title('Mean Outcomes by Policy')\n",
    "plt.xlabel('Policy')\n",
    "plt.ylabel('Mean Value')\n",
    "plt.legend(title='Outcomes')\n",
    "plt.show()\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "3fc77e0e-66c2-4483-91c0-302302bf78e3",
   "metadata": {
    "tags": []
   },
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Assuming outcomes_rfem is a tuple containing a DataFrame and a dictionary\n",
    "experiments_df, outcomes_dict = rf_em\n",
    "\n",
    "# Extract the policy data\n",
    "policies = experiments_df['policy']\n",
    "\n",
    "# Create a DataFrame from the outcomes dictionary and add the policy column\n",
    "outcomes_df = pd.DataFrame(outcomes_dict)\n",
    "outcomes_df['policy'] = policies.values\n",
    "\n",
    "# Calculate the mean and standard deviation of each outcome for each policy\n",
    "mean_outcomes = outcomes_df.groupby('policy').mean()\n",
    "std_outcomes = outcomes_df.groupby('policy').std()\n",
    "\n",
    "# Plot the mean outcomes for each policy separately\n",
    "for outcome in mean_outcomes.columns:\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    mean_outcomes[outcome].plot(kind='bar')\n",
    "    plt.title(f'Mean {outcome} by Policy')\n",
    "    plt.xlabel('Policy')\n",
    "    plt.ylabel(f'Mean {outcome}')\n",
    "    plt.show()\n",
    "\n",
    "# Plot the standard deviation outcomes for each policy separately\n",
    "for outcome in std_outcomes.columns:\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    std_outcomes[outcome].plot(kind='bar')\n",
    "    plt.title(f'Standard Deviation of {outcome} by Policy')\n",
    "    plt.xlabel('Policy')\n",
    "    plt.ylabel(f'Standard Deviation of {outcome}')\n",
    "    plt.show()\n",
    "\n",
    "# Plot boxplots for each outcome grouped by policy\n",
    "for outcome in outcomes_df.columns[:-1]:  # Exclude the 'policy' column\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.boxplot(x='policy', y=outcome, data=outcomes_df)\n",
    "    plt.title(f'Boxplot of {outcome} by Policy')\n",
    "    plt.xlabel('Policy')\n",
    "    plt.ylabel(outcome)\n",
    "    plt.show()\n",
    "\n",
    "# Plot histograms for each outcome grouped by policy\n",
    "for outcome in outcomes_df.columns[:-1]:  # Exclude the 'policy' column\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    for policy in outcomes_df['policy'].unique():\n",
    "        subset = outcomes_df[outcome][outcomes_df['policy'] == policy]\n",
    "        sns.histplot(subset, kde=True, label=f'Policy\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a308637f-c19d-469b-8fe8-3b205482e45b",
   "metadata": {},
   "source": [],
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
