{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lake model continued - subspace partitioning\n",
    "\n",
    "In the previous week you used the lake problem as a means of getting acquainted with the workbench. In this assignment we will continue with the lake problem, focussing explicitly on using it for open exploration. You can use the second part of the [open exploration tutorial](https://emaworkbench.readthedocs.io/en/latest/indepth_tutorial/open-exploration.html) for help.\n",
    "\n",
    "**It is paramount that you are using the lake problem with 100 decision variables, rather than the one found on the website with the seperate anthropogenic release decision**"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1. Apply scenario discovery\n",
    "\n",
    "**1.** Instanciate the model and define its parameters. Use the same parameters as in Assignment 2."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "from lakemodel_function import lake_problem\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-20T10:27:38.465406Z",
     "end_time": "2023-04-20T10:27:38.507784Z"
    }
   },
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-20T10:27:38.471802Z",
     "end_time": "2023-04-20T10:27:40.027960Z"
    }
   },
   "source": [
    "from ema_workbench import (Model, RealParameter, ScalarOutcome)\n",
    "\n",
    "#instantiate the model\n",
    "lake_model = Model('lakeproblem', function=lake_problem)\n",
    "lake_model.time_horizon = 100 # used to specify the number of timesteps\n",
    "\n",
    "#specify uncertainties\n",
    "lake_model.uncertainties = [RealParameter('mean', 0.01, 0.05),\n",
    "                            RealParameter('stdev', 0.001, 0.005),\n",
    "                            RealParameter('b', 0.1, 0.45),\n",
    "                            RealParameter('q', 2.0, 4.5),\n",
    "                            RealParameter('delta', 0.93, 0.99)]\n",
    "\n",
    "# set levers, one for each time step\n",
    "lake_model.levers = [RealParameter(f\"l{i}\", 0, 0.1) for i in\n",
    "                     range(lake_model.time_horizon)] # we use time_horizon here\n",
    "\n",
    "#specify outcomes \n",
    "lake_model.outcomes = [ScalarOutcome('max_P'),\n",
    "                       ScalarOutcome('utility'),\n",
    "                       ScalarOutcome('inertia'),\n",
    "                       ScalarOutcome('reliability')]"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "**2.** Generate 10 policies and 1000 scenarios and evaluate them."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-20T10:27:40.028960Z",
     "end_time": "2023-04-20T10:28:02.827468Z"
    }
   },
   "source": [
    "from ema_workbench import MultiprocessingEvaluator, ema_logging\n",
    "\n",
    "ema_logging.log_to_stderr(ema_logging.INFO)\n",
    "\n",
    "n_scenarios = 1000\n",
    "n_policies = 10\n",
    "\n",
    "with MultiprocessingEvaluator(lake_model, n_processes=-1) as evaluator:\n",
    "    results = evaluator.perform_experiments(n_scenarios, n_policies)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.** The experiments array contains the values for each of the 100 decision levers. This might easily mess up the analysis. Remove these columns from the experiment array. *hint: use `experiments.drop`*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-20T10:28:02.828468Z",
     "end_time": "2023-04-20T10:28:02.833606Z"
    }
   },
   "source": [
    "experiments, outcomes = results"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-20T10:28:02.833606Z",
     "end_time": "2023-04-20T10:28:02.839110Z"
    }
   },
   "source": [
    "cleaned_experiments = experiments.drop(labels=[l.name for l in lake_model.levers], axis=1)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.** Apply scenario discovery, focussing on the 10 percent of worst outcomes for reliability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-20T10:28:02.839110Z",
     "end_time": "2023-04-20T10:28:04.877802Z"
    }
   },
   "source": [
    "from ema_workbench.analysis import prim\n",
    "\n",
    "data = outcomes['reliability']\n",
    "\n",
    "y = data < np.percentile(data, 10)\n",
    "\n",
    "prim_alg = prim.Prim(cleaned_experiments,y, threshold=0.8)\n",
    "box1 = prim_alg.find_box()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-20T10:28:04.875804Z",
     "end_time": "2023-04-20T10:28:05.176479Z"
    }
   },
   "source": [
    "box1.show_tradeoff()\n",
    "plt.show()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "This figure shows the trade-off between coverage, density, and the number of restricted dimensions (i.e., a proxy for interpretability). Each dot corresponds to one candidate box. As an analyst, it is up to you to choose which box you want to inspect in more detail. Here you have to balance the three objectives. There is no hard rule that is used here. Note, however, that a density of lower than 0.5 means that less than half of the cases within the box of interest are of interest. So ideally, you start with higher density boxes. Moreover, you want boxes for which the box limits are statistically significant according to the quasi p-values. This means that the last box for a given number of restricted dimensions is also a good candidate box to inspect (here, for example, the last box with 2 dimensions and the last box with 3 dimensions)."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-20T10:28:05.176046Z",
     "end_time": "2023-04-20T10:28:05.390509Z"
    }
   },
   "source": [
    "box1.inspect(style='graph')\n",
    "plt.show()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "This figure shows in gray the complete interval for each parameter. A blue line is used in the case of RealParameters to show the interval of the box identified by PRIM. For CategoricalParameters, a dot is used instead. The blue numbers give the specific limit. The numbers behind the y-labels indicate the quasi p-values. In the top right-hand corner, you can see the coverage and density of the identified box. So, what do we see in this case. First, both delta and stdev are not significant and should be ignored in the interpretation. This leaves b, q, and some of the policies as the key determinants. So, our top 10% worst performance for reliability occurs if b and q are low and for 6 out of the 10 policies. This covers 56% of the cases of interest, with a precision (i.e. density) of 80%. Now, you would go back to the model and try to understand why you get low reliability if b and q are low."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Visualize the results using Dimensional Stacking\n",
    "Take the classification of outcomes as used in step 3 of scenario discovery, and instead visualize the results using dimensional stacking. How do these results compare to the insights from scenario discovery?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-20T10:28:05.368984Z",
     "end_time": "2023-04-20T10:28:05.390509Z"
    }
   },
   "source": [
    "from ema_workbench.analysis import dimensional_stacking"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-20T10:28:05.372515Z",
     "end_time": "2023-04-20T10:28:06.727060Z"
    }
   },
   "source": [
    "dimensional_stacking.create_pivot_plot(cleaned_experiments, y)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "looking at this graph, we have a few white spaces, so there is an argument to be made that we should run quite a bit more than 1000 runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-20T10:28:06.724061Z",
     "end_time": "2023-04-20T10:30:22.722454Z"
    }
   },
   "source": [
    "n_scenarios = 10000\n",
    "n_policies = 10\n",
    "\n",
    "with MultiprocessingEvaluator(lake_model, n_processes=-1) as evaluator:\n",
    "    results = evaluator.perform_experiments(n_scenarios, n_policies)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-20T10:30:22.722454Z",
     "end_time": "2023-04-20T10:30:26.721160Z"
    }
   },
   "source": [
    "experiments, outcomes = results\n",
    "cleaned_experiments = experiments.drop(labels=[l.name for l in lake_model.levers], axis=1)\n",
    "\n",
    "data = outcomes['reliability']\n",
    "y = data < np.percentile(data, 10)\n",
    "\n",
    "dimensional_stacking.create_pivot_plot(cleaned_experiments, y)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "As you can see, with the additional runs there are at least no white spaces left anymore. This is a good indication that we have a good coverage of the space."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Concluding remarks\n",
    "In this notebook, we have applied several techniques for scenario discovery to the inter temporal version of the lake problem (i.e., the one with 100 decision variables). Both dimensional stacking and PRIM point to the importance of low values for the b and q parameters in driving low reliability. The last, qualitative, step is to go back to the model and offer a structural explanation (remember from system dynamics: structure explains behavior) for this behavior. So why do you get low reliability of b and q are low?"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
