{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lake model\n",
    "\n",
    "see also [this general introduction to the workbench](https://waterprogramming.wordpress.com/2017/11/01/using-the-exploratory-modelling-workbench/) as a source of inspiration for completing the assignment below\n",
    "\n",
    "## the lake model\n",
    "The exploratory modeling workbench includes an example folder. This folder contains a variety of examples that demonstrate the functionality of the workbench. Many of these examples have been drawn from published cases. Here, we use the Lake Problem as an example for demonstrating some of the key functionality of the workbench. \n",
    "\n",
    "We demonstrate some of the key capabilities of the exploratory modeling workbench using the Lake problem. The lake problem is a stylized and hypothetical decision problem where the population of a city has to decide on the amount of annual pollution it will put into a lake. It the pollution in the lake passes a threshold, it will suffer irreversible eutrophication. \n",
    "\n",
    "\\begin{equation}\n",
    "    X_{(t+1)}=X_t+a_t+\\frac{(X_t^q)}{(1+X_t^q )}- bX_t+\\epsilon_t\n",
    "\\end{equation}\n",
    "\n",
    "where $X_t$ is the pollution at time $t$, $a_t$ is the rate of anthropogenic pollution at time $t$, $b$ is the lake’s natural removal rate, $q$ is the lake's natural recycling rate, $\\epsilon_t$ is the rate of natural pollution at time $t$. The rate of anthropogenic pollution $a_t$ is the decision variable and is somewhere between 0, and 0.1. So $a_t \\in [0,0.1]$. The natural pollution $\\epsilon_t$ is modeled, following Singh et al. (2015), as a log normal distribution with mean $\\mu$ and standard deviation $\\sigma$. \n",
    "There are four outcomes of interest. The first is the average concentration of phosphor in the lake. \n",
    "\n",
    "\\begin{equation}\n",
    "    f_{phosphorus}=  \\frac{1}{\\left\\vert{T}\\right\\vert} \\sum\\limits_{t\\in{T}} X_t \n",
    "\\end{equation}\n",
    "\n",
    "where $\\left\\vert{T}\\right\\vert$ is the cardinality of the set of points in time. \n",
    "The second objective is the economic benefit derived from polluting the lake. Following Singh et al. (2015), this is defined as the discounted benefit of pollution mines the costs of having a polluted lake\n",
    "\n",
    "\\begin{equation}\n",
    "    f_{economic} = \\sum\\limits_{t \\in {T}}\\alpha a_t \\delta^t \n",
    "\\end{equation}\n",
    "\n",
    "where $\\alpha$ is the utility derived from polluting and $\\delta$ is the discount rate. By default, $\\alpha$ is 0.04.\n",
    "The third objective is related to the year over year change in the anthropogenic pollution rate. \n",
    "\n",
    "\\begin{equation}\n",
    "    f_{inertia} =\\frac{1}{\\left\\vert{T}\\right\\vert-1} \\sum\\limits_{t=1}^{\\left\\vert{T}\\right\\vert} I(|a_{t}-a_{t-1} |>\\tau)   \n",
    "\\end{equation}\n",
    "\n",
    "where $I$ is an indicator function that is 0 if the statement is false, and 1 if the statement is true, $\\tau$ is the threshold that is deemed undesirable, and is for illustrative purposes et to 0.2. Effectively, f_{inertia} is the fraction of years where the absolute value of the change in anthropogenic pollution is larger then $\\tau$.\n",
    "The fourth objective is the fraction of years where the pollution in the lake is below the critical threshold.\n",
    "\n",
    "\\begin{equation}\n",
    "    f_{reliability} =  \\frac{1}{\\left\\vert{T}\\right\\vert} \\sum\\limits_{t \\in T}I(X_{t}<X_{crit} ) \n",
    "\\end{equation}\n",
    "\n",
    "where $I$ is an indicator function that is 0 if the statement is false, and 1 if the statement is true, $X_{crit}$ is the critical threshold of pollution and is a function of both $b$ and $q$.\n",
    "\n",
    "The lake problem is characterized by both stochastic uncertainty and deep uncertainty. The stochastic uncertainty arises from the natural inflow. To reduce this stochastic uncertainty, multiple replications are performed and the average over the replication is taken. Deep uncertainty is presented by uncertainty about the mean $\\mu$ and standard deviation $sigma$ of the lognormal distribution characterizing the natural inflow, the natural removal rate of the lake $\\beta$, the natural recycling rate of the lake $q$, and the discount rate $\\delta$. The table below specifies the ranges for the deeply uncertain factors, as well as their best estimate or default values. \n",
    "\n",
    "\n",
    "## Assignment\n",
    "1. Given the Python implementation of the lake problem in lakemodel_function.py, adapt this code and connect it to the workbench\n",
    "\n",
    "for the uncertainties, use the following table\n",
    "\n",
    "|Parameter\t|Range\t        |Default value|\n",
    "|-----------|--------------:|------------:|\n",
    "|$\\mu$    \t|0.01 – 0.05\t|0.02         |\n",
    "|$\\sigma$\t|0.001 – 0.005 \t|0.0017       |\n",
    "|$b$      \t|0.1 – 0.45\t    |0.42         |\n",
    "|$q$\t    |2 – 4.5\t    |2            |\n",
    "|$\\delta$\t|0.93 – 0.99\t|0.98         |\n",
    "\n",
    "For now, assume that for each year a release decision is made. The release is between 0 and 0.1. Carefully look at line 23 in lake_model.py to identify the name to use for each lever.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-07T13:56:59.899714Z",
     "end_time": "2023-04-07T13:56:59.904126Z"
    }
   },
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-07T13:56:59.906629Z",
     "end_time": "2023-04-07T13:57:00.838854Z"
    }
   },
   "source": [
    "from lakemodel_function import lake_problem\n",
    "from ema_workbench import (Model, RealParameter, ScalarOutcome)\n",
    "\n",
    "#instantiate the model\n",
    "lake_model = Model('lakeproblem', function=lake_problem)\n",
    "lake_model.time_horizon = 100 # used to specify the number of timesteps\n",
    "\n",
    "#specify uncertainties\n",
    "lake_model.uncertainties = [RealParameter('mean', 0.01, 0.05),\n",
    "                            RealParameter('stdev', 0.001, 0.005),\n",
    "                            RealParameter('b', 0.1, 0.45),\n",
    "                            RealParameter('q', 2.0, 4.5),\n",
    "                            RealParameter('delta', 0.93, 0.99)]\n",
    "\n",
    "# set levers, one for each time step\n",
    "lake_model.levers = [RealParameter(f\"l{i}\", 0, 0.1) for i in \n",
    "                     range(lake_model.time_horizon)] # we use time_horizon here\n",
    "\n",
    "#specify outcomes \n",
    "lake_model.outcomes = [ScalarOutcome('max_P'),\n",
    "                       ScalarOutcome('utility'),\n",
    "                       ScalarOutcome('inertia'),\n",
    "                       ScalarOutcome('reliability')]"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Explore the behavior of the system in the absence of any release using 1000 scenarios, and the default sampling approach.\n",
    "    * visualize the outcomes of interest, are there any apparent trade-offs?\n",
    "    * can you visually identify the uncertainties that drive system behavior?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-07T13:57:00.838854Z",
     "end_time": "2023-04-07T13:57:17.843725Z"
    }
   },
   "source": [
    "from ema_workbench import Policy, perform_experiments\n",
    "from ema_workbench import ema_logging\n",
    "\n",
    "ema_logging.log_to_stderr(ema_logging.INFO)\n",
    "\n",
    "policy = Policy(\"no release\", **{l.name:0 for l in lake_model.levers})\n",
    "n_scenarios = 1000\n",
    "results = perform_experiments(lake_model, n_scenarios, policy)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-07T13:57:17.845731Z",
     "end_time": "2023-04-07T13:57:20.183763Z"
    }
   },
   "source": [
    "experiments, outcomes = results\n",
    "\n",
    "sns.pairplot(pd.DataFrame.from_dict(outcomes))\n",
    "plt.show()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-07T13:57:20.183763Z",
     "end_time": "2023-04-07T13:57:21.476566Z"
    }
   },
   "source": [
    "from ema_workbench.analysis import pairs_plotting\n",
    "\n",
    "pairs_plotting.pairs_scatter(experiments, outcomes)\n",
    "\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(8,8)\n",
    "\n",
    "plt.show()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Explore the behavior of the system over 1000 scenarios for 4 randomly sampled candidate strategies.\n",
    "    * visualize the outcomes of interest\n",
    "    * what can you say about how the release decision influences the system?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-07T13:57:21.473545Z",
     "end_time": "2023-04-07T13:58:16.669271Z"
    }
   },
   "source": [
    "n_scenarios = 1000\n",
    "n_policies = 4\n",
    "results = perform_experiments(lake_model, n_scenarios, n_policies)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-07T13:58:16.669271Z",
     "end_time": "2023-04-07T13:58:20.704121Z"
    }
   },
   "source": [
    "experiments, outcomes = results\n",
    "policies = experiments['policy']\n",
    "\n",
    "data = pd.DataFrame.from_dict(outcomes)\n",
    "data['policy'] = policies\n",
    "\n",
    "sns.pairplot(data, hue='policy',  vars=outcomes.keys(), )\n",
    "plt.show()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. If you have not used parallelization in the foregoing, try to adapt your code to use parallelization. The workbench comes with two evaluators for parallelization. The `MultiProcessingingEvaluator` and the `IpyparallelEvaluator`. When can you use each?\n",
    "    * for windows users, carefully read [the python documentation](https://docs.python.org/3.6/library/multiprocessing.html). Can you use multiprocessing from within the notebook if the lake_model function is defined within the notebook?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-07T13:58:20.704121Z",
     "end_time": "2023-04-07T13:58:58.420720Z"
    }
   },
   "source": [
    "from ema_workbench import MultiprocessingEvaluator\n",
    "\n",
    "n_scenarios = 1000\n",
    "n_policies = 4\n",
    "\n",
    "with MultiprocessingEvaluator(lake_model) as evaluator:\n",
    "    results = evaluator.perform_experiments(n_scenarios, n_policies)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The ipyparallel Evaluator uses the ipyparallel library to suport multiprocessing. Working with this is a bit more involved than using multiprocessing. You first need to start ipcluster in cmd or a terminal:\n",
    "\n",
    "    ipcluster start\n",
    "\n",
    "next, you need a client to interact with this cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "source": [
    "import ipyparallel\n",
    "\n",
    "client = ipyparallel.Client()\n",
    "client.ids"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Next, we can define the lake model function. The %%px -local is known as a cell magic. This line means that the entire code block needs to be executed on all ipyarallel ipython engines, as well as in the ipython engine associated with the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "%%px --local\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "from scipy.optimize import brentq\n",
    "\n",
    "def lake_problem(b=0.42, q=2.0, mean=0.02, stdev=0.0017, delta=0.98,      \n",
    "                 alpha=0.4, nsamples=100, steps=100, l0=0, l1=0, l2=0, l3=0,\n",
    "                 l4=0, l5=0, l6=0, l7=0, l8=0, l9=0, l10=0, l11=0, l12=0, l13=0,\n",
    "                 l14=0, l15=0, l16=0, l17=0, l18=0, l19=0, l20=0, l21=0, l22=0,\n",
    "                 l23=0, l24=0, l25=0, l26=0, l27=0, l28=0, l29=0, l30=0, l31=0,\n",
    "                 l32=0, l33=0, l34=0, l35=0, l36=0, l37=0, l38=0, l39=0, l40=0,\n",
    "                 l41=0, l42=0, l43=0, l44=0, l45=0, l46=0, l47=0, l48=0, l49=0,\n",
    "                 l50=0, l51=0, l52=0, l53=0, l54=0, l55=0, l56=0, l57=0, l58=0,\n",
    "                 l59=0, l60=0, l61=0, l62=0, l63=0, l64=0, l65=0, l66=0, l67=0,\n",
    "                 l68=0, l69=0, l70=0, l71=0, l72=0, l73=0, l74=0, l75=0, l76=0,\n",
    "                 l77=0, l78=0, l79=0, l80=0, l81=0, l82=0, l83=0, l84=0, l85=0,\n",
    "                 l86=0, l87=0, l88=0, l89=0, l90=0, l91=0, l92=0, l93=0, l94=0,\n",
    "                 l95=0, l96=0, l97=0, l98=0, l99=0,):   \n",
    "    decisions = np.array([l0, l1, l2, l3, l4, l5, l6, l7, l8, l9, l10, l11, l12, l13,\n",
    "                          l14, l15, l16, l17, l18, l19, l20, l21, l22, l23, l24, l25,\n",
    "                          l26, l27, l28, l29, l30, l31, l32, l33, l34, l35, l36, l37,\n",
    "                          l38, l39, l40, l41, l42, l43, l44, l45, l46, l47, l48, l49,\n",
    "                          l50, l51, l52, l53, l54, l55, l56, l57, l58, l59, l60, l61,\n",
    "                          l62, l63, l64, l65, l66, l67, l68, l69, l70, l71, l72, l73,\n",
    "                          l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85,\n",
    "                          l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97,\n",
    "                          l98, l99])\n",
    "    \n",
    "    Pcrit = brentq(lambda x: x**q/(1+x**q) - b*x, 0.01, 1.5)\n",
    "    nvars = len(decisions)\n",
    "    X = np.zeros((nvars,))\n",
    "    average_daily_P = np.zeros((nvars,))\n",
    "    decisions = np.array(decisions)\n",
    "    reliability = 0.0\n",
    "\n",
    "    for _ in range(nsamples):\n",
    "        X[0] = 0.0\n",
    "        \n",
    "        natural_inflows = np.random.lognormal(\n",
    "                math.log(mean**2 / math.sqrt(stdev**2 + mean**2)),\n",
    "                math.sqrt(math.log(1.0 + stdev**2 / mean**2)),\n",
    "                size = nvars)\n",
    "        \n",
    "        for t in range(1,nvars):\n",
    "            X[t] = (1-b)*X[t-1] + X[t-1]**q/(1+X[t-1]**q) + decisions[t-1] +\\\n",
    "                    natural_inflows[t-1]\n",
    "            average_daily_P[t] += X[t]/float(nsamples)\n",
    "    \n",
    "        reliability += np.sum(X < Pcrit)/float(nsamples*nvars)\n",
    "      \n",
    "    max_P = np.max(average_daily_P)\n",
    "    utility = np.sum(alpha*decisions*np.power(delta,np.arange(nvars)))\n",
    "    inertia = np.sum(np.abs(np.diff(decisions)) > 0.02)/float(nvars-1)\n",
    "\n",
    "    return max_P, utility, inertia, reliability\n",
    "\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can define our model as we did before. If you remove --local the code below will fail, can you explain why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "#instantiate the model\n",
    "lake_model = Model('lakeproblem', function=lake_problem)\n",
    "lake_model.time_horizon = 100 # used to specify the number of timesteps\n",
    "\n",
    "#specify uncertainties\n",
    "lake_model.uncertainties = [RealParameter('mean', 0.01, 0.05),\n",
    "                            RealParameter('stdev', 0.001, 0.005),\n",
    "                            RealParameter('b', 0.1, 0.45),\n",
    "                            RealParameter('q', 2.0, 4.5),\n",
    "                            RealParameter('delta', 0.93, 0.99)]\n",
    "\n",
    "# set levers, one for each time step\n",
    "lake_model.levers = [RealParameter(f\"l{i}\", 0, 0.1) for i in \n",
    "                     range(lake_model.time_horizon)] # we use time_horizon here\n",
    "\n",
    "#specify outcomes \n",
    "lake_model.outcomes = [ScalarOutcome('max_P'),\n",
    "                       ScalarOutcome('utility'),\n",
    "                       ScalarOutcome('inertia'),\n",
    "                       ScalarOutcome('reliability')]"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "And now we are ready to execute our code, note that IpyparallelEvaluator requires the client as interface to the cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "from ema_workbench import  IpyparallelEvaluator\n",
    "\n",
    "n_scenarios = 1000\n",
    "n_policies = 4\n",
    "\n",
    "with IpyparallelEvaluator(lake_model, client=client) as evaluator:\n",
    "    results = evaluator.perform_experiments(n_scenarios, n_policies)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [],
   "outputs": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
