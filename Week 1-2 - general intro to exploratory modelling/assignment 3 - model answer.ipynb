{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EPA1361 - Model-Based Decision Making\n",
    "\n",
    "## Multi-model analysis\n",
    "\n",
    "This exercise uses a simple version of the [Lotka-Volterra predator-prey equations](https://en.wikipedia.org/wiki/Lotka%E2%80%93Volterra_equations) to show how the EMA Workbench can be used for a\n",
    "multi-model analysis, in addition to typical parametric/structural uncertainties. This will let you test the connectors provided in the Workbench for Excel, NetLogo, and Vensim / PySD; we'll also use the models for the sensitivity analysis exercise in week 3.\n",
    "\n",
    "**Assignment**\n",
    "Using the three model files provided and the Python function below, define model objects for each implementation (Excel, NetLogo, Vensim/PySD, and Python), and test them using a single ensemble. Use 50 experiments sampled from the parameters below (so that each experiment will be executed for the 4 models, for a total of 200), and retrieve outputs for the _TIME_, _predators_, and _prey_ variables.\n",
    "   * Excel and Vensim are only supported on Windows\n",
    "   * Vensim requires the DSS version of Vensim\n",
    "   * Netlogo supoprt depends on [jpype](http://jpype.readthedocs.io/en/latest/install.html) and [pynetlogo](https://pynetlogo.readthedocs.io/en/latest/). Also, if you don't have NetLogo installed, please get it from [NetLogo 6.1.1](https://ccl.northwestern.edu/netlogo/download.shtml)\n",
    "   * for pysd, see [its documentation](http://pysd.readthedocs.io/en/master/installation.html)\n",
    "   * If possible try to work with all model versions, but even 2 or 3 (pure python and something else should be sufficient).\n",
    "    \n",
    "\n",
    "|Parameter\t|Range or value\t        |\n",
    "|-----------|--------------:|\n",
    "|prey_birth_rate    \t|0.015 – 0.035\t|\n",
    "|predation_rate|0.0005 – 0.003 \t|\n",
    "|predator_efficiency     \t|0.001 – 0.004\t    |\n",
    "|predator_loss_rate\t    |0.04 – 0.08\t    |\n",
    "|Final time\t    |365\t    |\n",
    "|dt\t    |0.25\t    |\n",
    "\n",
    "* Note that your EMA Workbench installation includes [example scripts](https://github.com/quaquel/EMAworkbench/tree/master/ema_workbench/examples) for the different connectors. The different model objects follow a similar syntax but will need to be slightly adjusted depending on the software (e.g. to specify the NetLogo run length or the sheet name in Excel).\n",
    "  * This [tutorial](https://emaworkbench.readthedocs.io/en/latest/basic_tutorial.html) also shows a simple model in Python, Vensim and Excel connected to the workbench.\n",
    "\n",
    "* These model objects can be used with a replication functionality (for instance to test the effect of stochastic uncertainty in a NetLogo model), which repeats a given experiment over multiple replications. You can use a single replication in this exercise as the models are not stochastic. By default, each outcome array will then have a shape of (# experiments, # replications, # time steps). Try adapting the outcome arrays so that they can be used with the _lines_ plotting function of the Workbench, and plot the results grouped by model.\n",
    "\n",
    "* To check the graphical results, find the maximum absolute error of the time series you obtained for the _prey_ variable in the Excel, NetLogo, and Vensim/PySD models, relative to the Python function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "ExecuteTime": {
     "start_time": "2023-04-07T13:54:49.939856Z",
     "end_time": "2023-04-07T13:54:51.752186Z"
    }
   },
   "source": [
    "# Some imports you may need\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from ema_workbench import (Model, RealParameter, TimeSeriesOutcome, perform_experiments, ema_logging)\n",
    "\n",
    "from ema_workbench.connectors.netlogo import NetLogoModel\n",
    "from ema_workbench.connectors.excel import ExcelModel\n",
    "from ema_workbench.connectors.pysd_connector import PysdModel\n",
    "\n",
    "from ema_workbench import Samplers\n",
    "\n",
    "from ema_workbench.analysis.plotting import lines, Density"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the code given above returs a 2D array of shape (reps, timesteps). This means that the outcomes over a series of experiments will become 3D (n_experiments, n_reps, timesteps). Since replication is 1 in this case, we want to get rid of the middle dimension. There are various ways to do this. The easiest given the code above is to use a function as an optional keyword argument on the outcome class to do this. The ```np.squeeze``` function does exactly this.\n",
    "\n",
    "A more elegant solution would be to remove reps as an argument in the above code and use SingleReplicationNetLogoModel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "# Import the Python function\n",
    "from model.pred_prey import PredPrey"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-07T13:54:51.752186Z",
     "end_time": "2023-04-07T13:54:51.756796Z"
    }
   },
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "# Add as a system variable\n",
    "import os\n",
    "os.environ[\"JAVA_HOME\"] = 'C:/Program Files/NetLogo 6.3.0/runtime/bin/server/'"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-07T13:54:51.756796Z",
     "end_time": "2023-04-07T13:54:51.759511Z"
    }
   },
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "ExecuteTime": {
     "start_time": "2023-04-07T13:54:51.759511Z",
     "end_time": "2023-04-07T13:55:42.948839Z"
    }
   },
   "source": [
    "ema_logging.log_to_stderr(ema_logging.INFO)\n",
    "\n",
    "#We can define common uncertainties and outcomes for each model:\n",
    "uncertainties = [RealParameter('prey_birth_rate', 0.015, 0.035),\n",
    "                 RealParameter('predation_rate', 0.0005, 0.003),\n",
    "                 RealParameter('predator_efficiency', 0.001, 0.004),\n",
    "                 RealParameter('predator_loss_rate', 0.04, 0.08)] \n",
    "\n",
    "outcomes = [TimeSeriesOutcome('TIME', function=np.squeeze),\n",
    "            TimeSeriesOutcome('predators', function=np.squeeze),\n",
    "            TimeSeriesOutcome('prey', function=np.squeeze)]\n",
    "\n",
    "\n",
    "#Define the Python model\n",
    "py_model = Model('Python', function=PredPrey)\n",
    "py_model.uncertainties = uncertainties\n",
    "py_model.outcomes = outcomes\n",
    "\n",
    "#Define the NetLogo model\n",
    "nl_model = NetLogoModel('NetLogo', wd='./model/', model_file=\"PredPrey.nlogo\")\n",
    "nl_model.run_length = int(365 / 0.25)\n",
    "nl_model.replications = 1\n",
    "nl_model.uncertainties = uncertainties\n",
    "nl_model.outcomes = outcomes\n",
    "\n",
    "#Define the Excel model\n",
    "excel_model = ExcelModel('Excel', wd='./model/', model_file='PredPrey.xlsx')\n",
    "excel_model.default_sheet = 'Sheet1'\n",
    "excel_model.uncertainties = uncertainties\n",
    "excel_model.outcomes = outcomes\n",
    "\n",
    "#Define the PySD (Vensim) model\n",
    "pysd_model = PysdModel('PySD', mdl_file='./model/PredPrey.mdl')\n",
    "pysd_model.uncertainties = uncertainties\n",
    "pysd_model.outcomes = outcomes\n",
    "    \n",
    "nr_experiments = 50\n",
    "\n",
    "#Using Latin Hypercube sampling\n",
    "experiments, outcomes = perform_experiments([py_model, nl_model, excel_model, pysd_model],\n",
    "                                  nr_experiments, uncertainty_sampling=Samplers.LHS)\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can split the results tuple into experiments and outcomes, and check the dimensions of each. The dimensions of each outcome array correspond to 200 experiments (50 unique combinations of uncertainties * 4 models), 1 replication, and 1461 time steps (or 365/0.25)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "ExecuteTime": {
     "start_time": "2023-04-07T13:55:52.975821Z",
     "end_time": "2023-04-07T13:55:53.006827Z"
    }
   },
   "source": [
    "print(experiments.shape)\n",
    "print(outcomes['prey'].shape)\n",
    "\n",
    "#The experiments are grouped sequentially by model: indices 0-49 are the Python function, 50-99 the NetLogo model, etc.\n",
    "experiments.iloc[[0, 50, 100, 150], :]"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The lines graph shows that although the models behave quite differently depending on the experiments, the results are graphically identical across the 4 models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-07T13:55:55.838733Z",
     "end_time": "2023-04-07T13:55:55.854493Z"
    }
   },
   "source": [
    "for k, v in outcomes.items():\n",
    "    print(k, v.shape)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "ExecuteTime": {
     "start_time": "2023-04-07T13:55:56.808539Z",
     "end_time": "2023-04-07T13:55:57.043268Z"
    }
   },
   "source": [
    "experiments_to_show = np.arange(0, experiments.shape[0], 1)\n",
    "\n",
    "lines(experiments, outcomes, outcomes_to_show='prey', group_by='model',\n",
    "      show_envelope=True, density=Density.KDE, titles=None, \n",
    "      experiments_to_show=experiments_to_show)\n",
    "plt.show()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can check any differences between the model implementations and the Python function, by using logical indexing to select the outcome indices corresponding to each model, and subtracting the arrays from each other:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "ExecuteTime": {
     "start_time": "2023-04-07T13:55:58.235352Z",
     "end_time": "2023-04-07T13:55:58.238900Z"
    }
   },
   "source": [
    "#Find the model implementations that were sampled in the experiments\n",
    "models = [i for i in experiments.model.unique() if i != 'Python']\n",
    "\n",
    "for model in models:\n",
    "    logical = experiments.model==model\n",
    "    \n",
    "    print('Max absolute error with {}:'.format(model))\n",
    "    print(np.max(abs(outcomes['prey'][logical] - outcomes['prey'][logical])))"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
